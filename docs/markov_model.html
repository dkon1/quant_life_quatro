<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Quantifying Life - 13&nbsp; Markov models with discrete states</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./markov_evol.html" rel="next">
<link href="./ode_sols.html" rel="prev">
<link href="./Kondrashov_Comp.jpeg" rel="icon" type="image/jpeg">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Quantifying Life - 13&nbsp; Markov models with discrete states">
<meta name="twitter:description" content="Life is complex and often unpredictable. Molecules bump into each randomly due to thermal motion; entire organisms either find food or become food themselves due to chance.">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Markov models with discrete states</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Quantifying Life</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/dkon1/quant_life_quatro" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Download" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-download"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="./Quantifying-Life.pdf">
            <i class="bi bi-bi-file-pdf pe-1"></i>
          Download PDF
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="./Quantifying-Life.epub">
            <i class="bi bi-bi-journal pe-1"></i>
          Download ePub
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./counting.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Arithmetic and variables</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./functions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Functions and their graphs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./descriptive.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Describing data sets</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probdist.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Random variables and distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linreg.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./independence.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Independence</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hypo_test.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Hypothesis testing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Prior knowledge and Bayesian thinking</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sampling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Sampling distribution and estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lindiff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Linear difference equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./graph_odes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Graphical analysis of ordinary differential equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ode_sols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Solutions of ordinary differential equations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./markov_model.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Markov models with discrete states</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./markov_evol.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Probability distributions of Markov chains</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./markov_stat.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Stationary distributions of Markov chains</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./markov_eigen.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Dynamics of Markov models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#building-markov-models" id="toc-building-markov-models" class="nav-link active" data-scroll-target="#building-markov-models"><span class="toc-section-number">13.1</span>  Building Markov models</a></li>
  <li><a href="#markov-property" id="toc-markov-property" class="nav-link" data-scroll-target="#markov-property"><span class="toc-section-number">13.2</span>  Markov property</a>
  <ul class="collapse">
  <li><a href="#transition-matrices" id="toc-transition-matrices" class="nav-link" data-scroll-target="#transition-matrices"><span class="toc-section-number">13.2.1</span>  transition matrices</a></li>
  <li><a href="#probability-of-a-string-of-states" id="toc-probability-of-a-string-of-states" class="nav-link" data-scroll-target="#probability-of-a-string-of-states"><span class="toc-section-number">13.2.2</span>  probability of a string of states</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">13.2.3</span>  Exercises</a></li>
  </ul></li>
  <li><a href="#markov-models-of-medical-treatment" id="toc-markov-models-of-medical-treatment" class="nav-link" data-scroll-target="#markov-models-of-medical-treatment"><span class="toc-section-number">13.3</span>  Markov models of medical treatment</a>
  <ul class="collapse">
  <li><a href="#discussion-questions" id="toc-discussion-questions" class="nav-link" data-scroll-target="#discussion-questions"><span class="toc-section-number">13.3.1</span>  Discussion questions</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Markov models with discrete states</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<blockquote class="blockquote">
<p>True, man is mortal, but that’s not the half of it. What’s worse is that he’s sometimes suddenly mortal, that’s the trick!<br>
– Mikhail Bulgakov, <em>The Master and Margarita</em></p>
</blockquote>
<p>Life is complex and often unpredictable. Molecules bump into each randomly due to thermal motion; entire organisms either find food or become food themselves due to chance. Mathematical probability supplies tools to model, analyze, and even predict the behavior of these random processes. In this part of the book we will focus on living systems that can be described as being in different categories called discrete states. Similar to the categorical random variables that were described in chapters 8 and 10, these systems are not measured on a numerical scale, but can be described by words. For example, ion channels are trans-membrane proteins which can change their shape to allow or not allow the passage of ions. Thus, an ion channel can be described as being in an open or a closed state, with transitions taking places between those states with certain probabilities. These models with a few discrete states and random transitions with specified probabilities are called <em>Markov models</em>. They are easy to build and they provide a powerful framework for mathematical analysis. In this chapter you will learn to do the following:</p>
<ul>
<li>write down the transition diagram and transition matrix of a discrete-state Markov models</li>
<li>understand the Markov property and its implications</li>
<li>calculate the probability of a string of states based on transition probabilities</li>
<li>simulate a Markov model by generating multiple state strings based on the transition probabilities</li>
</ul>
<section id="building-markov-models" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="building-markov-models"><span class="header-section-number">13.1</span> Building Markov models</h2>
<p></p>
<p>Consider the life cycle of a cell, which is illustrated in figure <span class="math inline">\(\ref{fig:ch10_cell_cycle}\)</span>a. Cells are known to go through phases in the cell cycle, which correspond to different molecules being synthesized and different actions performed. The <span class="math inline">\(M\)</span> phase stands for mitosis, or cell division, which itself can be divided into stages, and in between cell divisions, cells go through gap phases (<span class="math inline">\(G_1\)</span> and <span class="math inline">\(G_2\)</span>) and the <span class="math inline">\(S\)</span> phase, during which DNA replication occurs. Some cells, depending on their environmental conditions, or type in multicellular organisms, can also get off the treadmill of the cell cycle, and go into what is called ``quiescence’’, or <span class="math inline">\(G_0\)</span> phase, during which the cell leads a quiet life. It can also come out of quiescence and replicate again. This suggests a simplified description of the cell that exists either in state <span class="math inline">\(R\)</span> (actively replicating) or state <span class="math inline">\(Q\)</span> (quiescent), with transitions between the two states occurring randomly with some probabilities. These kinds of models can be summarized graphically using <em>transition diagrams</em>. For example, the QR model of the cell cycle with probability of transition from Q to R of 0.05 (per hour), and the transition probability from R to Q of 0.1 (per hour) is described by the diagram shown in figure <span class="math inline">\(\ref{fig:ch10_cell_cycle}\)</span>b.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch10/2000px-Cell_Cycle.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Diagram of the cell cycle showing the replicating phases (<span class="math inline">\(M\)</span>, <span class="math inline">\(G_1\)</span>, <span class="math inline">\(S\)</span>, and <span class="math inline">\(G_2\)</span>) and the quiescent phase <span class="math inline">\(G_0\)</span> (“Cell Cycle” by Zephyris with modifications by Beao and Histidine under CC-BY-SA-3.0 via Wikimedia commons)</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch10/QR_trans_diag.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Diagram of a model of the cell cycle with two states (Q and R) with transitions between states shown as arrows labeled with transition probabilities.</figcaption><p></p>
</figure>
</div>
<p>A very different example of a biological systems that can be naturally divided into states are ion channels, mentioned above. For some of them the opening or closing is activated by the binding of other molecules, like in the case of the nicotinic acetylcholine receptor (nAChR). When not bound to acetylcholine (a small molecule that serves as a neurotransmitter) it remains closed, but binding of acetylcholine enables it to change conformation and open, though it can also be closed when bound to Ach. Figure <span class="math inline">\(\ref{fig:ch10_ion_channel}\)</span> illustrates the three states of nAChR, along with a transition diagram that depicts possible transitions. Notice the absence of any arrows between states R and O, which reflects the fact that the ion channel cannot transition directly from the resting (unbound) state to the open state, it must go through the bound-but-closed state C.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch10/ChemicallyGatedChannel.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Nicotinic acetylcholine receptor (nAChR) an ion channel which opens only when bound to acetylcholine; conformation of the ion channel can be divided into three states: resting (R), closed with Ach bound (C) and open (O) (“Chemically Gated Channel” by Blausen.com under CC BY 3.0 via Wikimedia Commons)</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch10/channel_trans_diag.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Transition diagram for the nAchR ion channel illustrates possible transitions with transition probabilities as parameters</figcaption><p></p>
</figure>
</div>
</section>
<section id="markov-property" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="markov-property"><span class="header-section-number">13.2</span> Markov property</h2>
<p></p>
<p>In <em>finite-state</em> Markov models like those introduced above, the independent variable (e.g.&nbsp;time) advances in discrete steps, the length of which is defined by the problem. For example, in the cell cycle model, an appropriate time step may be an hour, while for the ion channel mode, a reasonable time step is a fraction of a second. In some bioinformatics models describing a string of letters, the independence variable is position in the sequence and the step is one letter. Changes from one state to another are called <em>transitions</em>, and they may only happen over a step of the independent variable. The transitions occur randomly, so they cannot be predicted, but we can describe the probability of transitions.</p>
<p>For example, we may state that the probability of transition from state Q to R in the cell cycle model is 0.05 for each time step, and the probability of transition from R to Q is 0.1. This means that 5 times of 100 (out of many trials) a quiescent cell will switch to replicating over one time step, and 1 time out of 10 (out of many trials) a replicating cell will switch to the quiescent state. Let us define these parameters properly:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">\(X(t)\)</span> be the random variable in a discrete-time Markov model with finitely many states at an arbitrary time <span class="math inline">\(t\)</span>. The <em>transition probability</em> from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> is denoted <span class="math inline">\(p_{ji}\)</span> and is defined as the conditional probability: <span class="math display">\[ p_{ji} = P \{X(t+1) = j | X(t) = i \}\]</span></p>
</div>
</div>
<p>Let us unpack this definition. The transition probability is conditional on knowing the state of the model (<span class="math inline">\(i\)</span>) is at the present time (<span class="math inline">\(t\)</span>) and gives us the probability of the model switching to another state (<span class="math inline">\(j\)</span>, which can be the same as <span class="math inline">\(i\)</span>) one time step later (<span class="math inline">\(t+1\)</span>). The transition probability in this definition has no explicit dependence on time <span class="math inline">\(t\)</span>, which is not necessarily the case for all Markov models; I just chose to make this additional assumption, called <em>time-homogeneity</em>, for simplicity. There are Markov models which are not time-homogeneous, but we will not see them in this course.</p>
<p>Note that the transition from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> is written as <span class="math inline">\(p_{ji}\)</span>. This is the convention that I will use to conform to the conditional probability notation, and for another reason that will be apparent in the next chapter. Unfortunately, there is no agreement in the field as to which convention to use, and some textbooks and papers denote the same transition probability <span class="math inline">\(p_{ij}\)</span>. I will strive to avoid confusion and remind you what <span class="math inline">\(p_{ji}\)</span> stands for.</p>
<p>One funny thing that you might have noticed in that definition is that the transition probability makes no mention of times before the present. We just brazenly assumed that the history of the random variable before the present time <span class="math inline">\(t\)</span> does not matter! This is called the <em>Markov property</em> and was first postulated by A.A. Markov in 1905. Here is the proper definition :</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>A time-dependent random variable <span class="math inline">\(X(t)\)</span> has the <em>Markov property</em> if for all times <span class="math inline">\(t\)</span> and for all <span class="math inline">\(n&lt;t\)</span>, the following is true:</p>
<p><span class="math display">\[P\{ X(t+1)| X(t) ; X(n) \} = P\{ X(t+1)| X(t) \}\]</span></p>
</div>
</div>
<p>I did not specify the state of the random variable in the definition because it must be true for all states in the model. Stated in words, this says that the probability distribution of the random variable at the next time step, given its distribution at the current time is the same whether any of its past states are known or not. Another way of stating it is that the state of the random variable at the next time, given the state at the present time, is <em>independent</em> of the past states.</p>
<p>If this seems like a really big assumption, you are right! The reason we assume this property is because it makes calculations with these models much easier. As with any assumption, it must be viewed critically for any given application. Does the cell really forget what state it was in an hour ago? Does it matter whether an ion channel was open a microsecond ago for its probability to open again? The answer to these questions is not always clear cut - there is almost always some residual memory of past states in a real system. If that memory is not very strong, then we can proceed with our Markov modeling. Otherwise, the models must be made more sophisticated.</p>
<section id="transition-matrices" class="level3" data-number="13.2.1">
<h3 data-number="13.2.1" class="anchored" data-anchor-id="transition-matrices"><span class="header-section-number">13.2.1</span> transition matrices</h3>
<p>Let us return to our example of the cell cycle model with two transition probabilities given: transition from Q to R <span class="math inline">\(p_{RQ} = 0.05\)</span> and transition from R to Q <span class="math inline">\(p_{QR} = 0.1\)</span>. We can calculate the probability of a replicating cell remaining in the same state, and the probability of a quiescent cell remaining in the same state, because they are complementary events:</p>
<p><span class="math display">\[
p_{QQ} = 1 - p_{RQ} = 0.95; \; p_{RR} = 1 - p_{QR} = 0.9
\]</span></p>
<p>In other words, a quiescent cell either becomes replicating over one time step or remains quiescent, so the two probabilities must add up to 1. The same reasoning applies to the replicating cell. We now have all of the parameters of the model, and there is a convenient way of organizing them in one object.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <em>transition matrix</em> for a discrete-time Markov model with <span class="math inline">\(N\)</span> states is an <span class="math inline">\(N\)</span> by <span class="math inline">\(N\)</span> matrix, which has the transition probabilities <span class="math inline">\(p_{ij}\)</span> as its elements in the <span class="math inline">\(i\)</span>-th row and <span class="math inline">\(j\)</span>-th column.</p>
</div>
</div>
<p>By convention, the rows in matrices are counted from top to bottom, while the columns are counted left to right. The transition matrix is a square matrix consisting of all of the transition probabilities of a given Markov model. It is, in essence, what defines a Markov model because the transition probabilities are its parameters.</p>
<p><strong>Example.</strong> For the cell cycle model in figure <span class="math inline">\(\ref{fig:ch10_cell_cycle}\)</span> the transition matrix is: <span class="math display">\[
M = \left(\begin{array}{cc}0.95 &amp; 0.1 \\0.05 &amp; 0.9\end{array}\right)
\]</span></p>
<p>In order to write it down, we have to put the states in order; in this case I chose Q to be state number 1, and R to be state number 2. This is entirely arbitrary, but must be specified in order for the matrix to have meaning. Notice that the probabilities of staying in a state are on the diagonal of the matrix, where the row and the column number are the same. The probability of transition from state 1 (Q) to state 2 (R) is in column 1, row 2, and the probability of transition from state 2 (R) to state 1 (Q) is in column 2, row 1.</p>
<p><strong>Example.</strong> For the three-state model of the nAChR ion channel in figure <span class="math inline">\(\ref{fig:ch10_ion_channel}\)</span> the transition matrix is:</p>
<p><span class="math display">\[
M = \left(\begin{array}{ccc} 1-\alpha &amp; \beta &amp; 0  \\ \alpha &amp; 1-\beta-\gamma &amp; \delta \\ 0 &amp; \gamma &amp; 1-\delta \end{array}\right)
\]</span></p>
<p>The matrix is for states R, C, and O placed in that order. Notice that the transition probability between R and O and vice versa is zero, in accordance with the transition diagram. The probability of remaining in each state is 1 minus the sum of all the transition probabilities of exiting that state; for example for state 2 (C) the probability of remaining is <span class="math inline">\(1-\beta-\gamma\)</span>.</p>
</section>
<section id="probability-of-a-string-of-states" class="level3" data-number="13.2.2">
<h3 data-number="13.2.2" class="anchored" data-anchor-id="probability-of-a-string-of-states"><span class="header-section-number">13.2.2</span> probability of a string of states</h3>
<p>Knowing the parameters of the model gives us the tools to make probabilistic calculations. The simplest task is to find the probability of occurrence of a given string of states. For instance, for the cell cycle model, suppose we know that a cell is initially quiescent, what is the probability that it remains quiescent for two hours? The probability of the cell remaining quiescent for one time step is <span class="math inline">\(p_{QQ} = 0.95\)</span>, and the probability of it remaining quiescent for one more time step is also <span class="math inline">\(p_{QQ}\)</span>. Due to the Markov property, the two transitions are independent of each other, so the probabilities can be multiplied, due to the multiplicative property of independent events, to give the answer: <span class="math inline">\(P\{QQQ\} = 0.95\times0.95 = 0.9025\)</span>.</p>
<p>The magic of Markov property allows us to calculate the probability of any string of states, given the initial state, as the product of transition probabilities. We can write this formally as follows: for a string of states <span class="math inline">\(S = \{x_1, x_2, x_3, ... , x_{T-1}, x_T\}\)</span>, where <span class="math inline">\(x_t\)</span> represents the state at time <span class="math inline">\(t\)</span>, the probability of this string, given that <span class="math inline">\(P(x_1) = 1\)</span> is</p>
<p><span class="math display">\[
P(S) =  p_{x_2x_1} p_{x_3x_2} ... p_{x_Tx_{T-1}} =  p_{x_Tx_{T-1}} ... p_{x_3x_2}p_{x_2x_1}
\]</span></p>
<p>The ellipsis represents all the intermediate transitions from state <span class="math inline">\(x_3\)</span> to state <span class="math inline">\(x_{T-1}\)</span>. I also showed that by reversing the order of multiplication, which is allowed because of commutativity, makes the order of states proceed more clearly.</p>
<p><strong>Example.</strong> Let us calculate the probability of another string of states based on the the cell cycle model in figure <span class="math inline">\(\ref{fig:ch10_cell_cycle}\)</span>. The probability that a cell is initially in state R, then transitions to state Q and remains in state Q is a product of the transition probability from R to Q and the transition probability from Q to Q:</p>
<p><span class="math display">\[
P\{RQQ\} = 0.1 \times 0.95=0.095
\]</span></p>
<p>Notice that there is no transition probability for the first state, since it must be specified as an initial condition, just like in the dynamic models we saw in chapters 5 through 7.</p>
<p><strong>Example.</strong> Let us calculate the probability of a string of states based the three-state model of the nAChR ion channel in figure <span class="math inline">\(\ref{fig:ch10_ion_channel}\)</span>. The probability that an ion channel is initially in state R, remains in that state for 5 steps, then transitions to state C, remains there for 3 steps, then transitions to state O is:</p>
<p><span class="math display">\[
P\{RRRRRRCCCCO\} =  (1-\alpha)^5 \alpha (1-\beta-\gamma)^3 \gamma
\]</span></p>
</section>
<section id="exercises" class="level3" data-number="13.2.3">
<h3 data-number="13.2.3" class="anchored" data-anchor-id="exercises"><span class="header-section-number">13.2.3</span> Exercises</h3>
<p>For the following Markov models a) draw the transition diagram, if one is not provided; b) put the states in (some) order and write down the transition matrix; c) calculate the probability of the given strings of states, taking the first state as given (e.g.&nbsp;for a string of 3 states, there are only 2 transitions.)</p>
<p><img src="ch10/AB_trans_diag.png" class="img-fluid" alt="Model 1"> <img src="ch10/CD_trans_diag.png" class="img-fluid" alt="Model 2"> <img src="ch10/EF_trans_diag.png" class="img-fluid" alt="Model 3"> <img src="ch10/GH_trans_diag.png" class="img-fluid" alt="Model 4"></p>
<ol type="1">
<li><p>Use the transition diagram in figure <span class="math inline">\(\ref{fig:ch10_trans_diags}\)</span>a (Model 1) to calculate the probability of the string of states BAB.</p></li>
<li><p>Use the transition diagram in figure <span class="math inline">\(\ref{fig:ch10_trans_diags}\)</span>b (Model 2) to calculate the probability of the string of states CCD.</p></li>
<li><p>Use the transition diagram in figure <span class="math inline">\(\ref{fig:ch10_trans_diags}\)</span>c (Model 3) to calculate the probability of the string of states EEF.</p></li>
<li><p>Use the transition diagram in figure <span class="math inline">\(\ref{fig:ch10_trans_diags}\)</span>d (Model 4) to calculate the probability of the string of states GGG.</p></li>
<li><p>An ion channel can be in either open (O) or closed (C) states. If it is open, then it has probability 0.1 of closing in 1 microsecond; if closed, it has probability 0.3 of opening in 1 microsecond. Calculate the probability of the ion channel going through the following sequence of states: COO.</p></li>
<li><p>An individual can be either susceptible (S) or infected (I), the probability of infection for a susceptible person is 0.05 per day, and the probability an infected person becoming susceptible is 0.12 per day. Calculate the probability of a person going through the following string of states: SISI.</p></li>
<li><p>The genotype of an organism can be either normal (wild type, W) or mutant (M). Each generation, a wild type individual has probability 0.03 of having a mutant offspring, and a mutant has probability 0.005 of having a wild type offspring. Calculate the probability of a string of the following genotypes in successive generations: WWWW.</p></li>
<li><p>There are three kinds of vegetation in an ecosystem: grass (G), shrubs (S), and trees (T) . Every year, 25% of grassland plots are converted to shrubs, 20% of shrub plots are converted to trees, 8% of trees are converted to shrubs, and 1% of trees are converted to grass; the other transition probabilities are 0. Calculate the probability of a plot of land have the following succession of vegetation from year to year: GSGG.</p></li>
<li><p>The nAChR ion channel can be in one of three states: resting (R), closed with Ach bound (C), and open (O) with transition probabilities (per one microsecond): 0.04 (from R to C), 0.07 (from C to R), 0.12 (from C to O) and 0.02 (from O to C); the other transition probabilities are 0. Calculate the probability of the following string of states: OCCR.</p></li>
<li><p>(Challenging) We considered a sequence of Bernoulli trials in chapter 4, for example a string of coin tosses where each time heads and tails come up with probability 0.5. Describe this experiment as a Markov model, draw its transition diagram and write its transition matrix.</p></li>
<li><p>(Challenging) Now do the same for a sequence of Bernoulli trials where success has probability 0.9 (and failure has probability 0.1).</p></li>
<li><p>(Challenging) Can you formulate a test, based on a transition matrix of a Markov model, to tell whether it’s generating a string of independent random variables as opposed to a string of random variables that depend on the previous one?</p></li>
</ol>
</section>
</section>
<section id="markov-models-of-medical-treatment" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="markov-models-of-medical-treatment"><span class="header-section-number">13.3</span> Markov models of medical treatment</h2>
<p></p>
<p>Markov models are used across many biological fields. One example is the representation of disease and patient treatment using discrete states with random transitions. The states may describe the progression of the disease, the prior health and socioeconomic status of the patient, the treatment the patient is undergoing, anything that is relevant for the medical situation. Some models are very simple, for example a model of stroke patients that describes them either as well, experiencing stroke, disables, or dead . Others use tens or hundreds of states, to better capture all the details without. One can then ask the question: what course of treatment is likely to lead to the best outcome? Notice that there can be no certainty in this answer, since the model is fundamentally random. In order to evaluate different treatments, one can run simulations of the different models and compare the statistics generated by multiple simulations of each model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch10/simple_medical_markov.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Simple Markov model of the states of patients at risk for stroke; figure from </figcaption><p></p>
</figure>
</div>
<p>For example, figure <span class="math inline">\(\ref{fig:simple_medical_markov}\)</span> from shows a four-state Markov model used to represent patients at risk for stroke. Three of the four states (well, disabled, and dead) have nonzero probability of remaining in the same state for more than one time step, and in particular the death state is permanent, so no transitions out of it are allowed. On the other hand, the stroke state does not allow for “self-transition” since it is a fast event, either resulting in full recovery, disability, or death. In order for such models to be useful, one needs to obtain data on numerous patients documenting all possible transition events, and to estimate the transition probabilities based on the observed frequencies of their respective occurrences.</p>
<p>A more realistic example comes from a recent study of the cost-effectiveness of different treatment protocols for HIV patients in South Africa . Physicians and public health officials have to consider both the costs and the efficacy of medical procedures, and it is a difficult challenge to balance the two, with human health and lives at stake. The authors built a model that includes stages of the disease, determined by viral loads and treatment options. The authors used data from two different clinics, a public and a private one, to estimate the transition probabilities and outcomes of treatments, and the costs of clinic visits and the therapies. They then simulated the models to compare the predicted costs and outcomes, and found that while the outcomes in the two treatment protocols were similar, the costs in the private clinics were considerably lower.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch10/hiv_treatment_model.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Transition diagram for a model of HIV disease and treatment from (under CC-BY license)</figcaption><p></p>
</figure>
</div>
<section id="discussion-questions" class="level3" data-number="13.3.1">
<h3 data-number="13.3.1" class="anchored" data-anchor-id="discussion-questions"><span class="header-section-number">13.3.1</span> Discussion questions</h3>
<p>You are invited to read the paper <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0053570">“A Novel Markov Model Projecting Costs and Outcomes of Providing Antiretroviral Therapy to Public Patients in Private Practices versus Public Clinics in South Africa”</a> and then use the following questions for discussion with your colleagues and friends.</p>
<ol type="1">
<li><p>What does the Markov property mean for this model? How realistic do you think it is for actual patients?</p></li>
<li><p>What are some other assumptions the authors make? Are they reasonable from a medical standpoint?</p></li>
<li><p>The model predicts that private clinics which save costs are equally effective to private clinics with greater numbers of visits. Would you be comfortable recommending patients use only use private clinics based on this prediction?</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ode_sols.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Solutions of ordinary differential equations</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./markov_evol.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Probability distributions of Markov chains</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>