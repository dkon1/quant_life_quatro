[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantifying Life",
    "section": "",
    "text": "Preface\nThis is an online book to help biologists and biology-adjacent folks learn quantitative skills through the practice of programming in R. These skills can be roughly sorted into four types:\nThese skills interface, intertwine, and reinforce each other in the practice of biological research and are thus presented concurrently in this book, instead of being corralled into separate courses taught by different departments, like mathematics, statistics, and computer science. Here I combine ideas and skills from all of these disciplines into an educational narrative organized by increasing exposure to programming concepts."
  },
  {
    "objectID": "index.html#a-brief-motivation-of-mathematical-modeling",
    "href": "index.html#a-brief-motivation-of-mathematical-modeling",
    "title": "Quantifying Life",
    "section": "A brief motivation of mathematical modeling",
    "text": "A brief motivation of mathematical modeling\nA mathematical model is a representation of some real object or phenomenon in terms of quantities (numbers). The goal of modeling is to create a description of the object in question that may be used to pose and answer questions about it, without doing hard experimental work. A good analogy for a mathematical model is a map of a geographic area: a map cannot record all of the complexity of the actual piece of land, because then the map would need to be size of the piece of land, and then it wouldn’t be very useful! Maps, and mathematical models, need to sacrifice the details and provide a birds-eye view of reality in order to guide the traveler or the scientist. The representation of reality in the model must be simple enough to be useful, yet complex enough to capture the essential features of what it is trying to represent.\nMathematical modeling has long been essential in physics: for instance, it is well known that distance traveled by an object traveling at constant speed \\(v\\) is proportional to the time traveled (called \\(t\\)). This mathematical model can be expressed as an equation:\n\\[d = vt\\]\nSince the time of Newton, physicists have been very successful at using mathematics to describe the behavior of matter of all sizes, ranging from subatomic particles to galaxies. However, mathematical modeling is a new arrow in a biologist’s quiver. Many biologists would argue that living systems are much more complex than either atoms or galaxies, since even a single cell is made up of a mind-boggling number of highly dynamic, interacting entities. That is true, but new advances in experimental biology are producing data that make quantitative methods indispensable for biology.\nThe advent of genetic sequencing in the 1970s and 80s has allowed us to determine the genomes of different species, and in the last few years next-generation sequencing has reduced sequencing costs for an individual human genome to a few thousand dollars. The resulting deluge of quantitative data has answered many outstanding questions, and also led to entirely new ones. We now understand that knowledge of genomic sequences is not enough for understanding how living things work, so the burgeoning field of systems biology investigates the interactions between genes, proteins, or other entities. The central question is to understand how a network of interactions between individual molecules can lead to large-scale results, such as the development of a fertilized egg into a complex organism. The human mind is not suited for making correct intuitive judgements about networks comprised of thousands of actors. Addressing questions of this complexity requires quantitative modeling."
  },
  {
    "objectID": "index.html#purpose-of-this-book",
    "href": "index.html#purpose-of-this-book",
    "title": "Quantifying Life",
    "section": "Purpose of this book",
    "text": "Purpose of this book\nThis textbook is intended for a college-level course for biology and pre-medicine majors, or more established scientists interested in learning the applications of mathematical methods to biology. The book brings together concepts found in mathematics, computer science, and statistics courses to provide the student a collection of skills that are commonly used in biological research. The book has two overarching goals: one is to explain the quantitative language that often is a formidable barrier to understanding and critically evaluating research results in biological and medical sciences. The second is to teach students computational skills that they can use in their future research endeavors. The main premise of this approach is that computation is critical for understanding abstract mathematical ideas.\nThese goals are distinct from those of traditional mathematics courses that emphasize rigor and abstraction. I strongly believe that understanding of mathematical concepts is not contingent on being able to prove all of the underlying theorems. Instead, premature focus on abstraction obscures the ideas for most students; it is putting the theoretical cart before the experiential horse. I find that students can grasp deep concepts when they are allowed to experience them tangibly as numbers or pictures, and those with an abstract mindset can generalize and add rigor later. As I demonstrate in part 3 of the book, Markov chains can be explained without relying on the machinery of measure theory and stochastic processes, which require graduate level mathematical skills. The idea of a system randomly hopping between a few discrete states is far more accessible than sigma algebras and martingales. Of course, some abstraction is necessary when presenting mathematical ideas, and I provide correct definitions of terms and supply derivations when I find them to be illuminating. But I avoid rigorous proofs, and always favor understanding over mathematical precision.\nThe book is structured to facilitate learning computational skills. Over the course of the text students accumulate programming experience, progressing from assigning values to variables in the first chapter to solving nonlinear ODEs numerically by the end of the book. Learning to program for the first time is a challenging task, and I facilitate it by providing sample scripts for students to copy and modify to perform the requisite calculations. Programming requires careful, methodical thinking, which facilitates deeper understanding of the models being simulated. In my experience of teaching this course, students consistently report that learning basic scientific programming is a rewarding experience, which opens doors for them in future research and learning.\nIt is of course impossible to span the breadth of mathematics and computation used for modeling biological scenarios. This did not stop me from trying. The book is broad but selective, sticking to a few key concepts and examples which should provide enough of a basis for a student to go and explore a topic in more depth. For instance, I do not go through the usual menagerie of probability distributions in chapter 4, but only analyze the uniform and the binomial distributions. If one understands the concepts of distributions and their means and variances, it is not difficult to read up on the geometric or gamma distribution if one encounters it. Still, I omitted numerous topics and entire fields, some because they require greater mathematical sophistication, and others because they are too difficult for beginning programmers, e.g. sequence alignment and optimization algorithms. I hope that you do not end your quantitative journey with this book!\nI take an even more selective approach to the biological topics that I present in every chapter. The book is not intended to teach biology, but I do introduce biological questions I find interesting, refer the reader to current research papers, and provide discussion questions for you to wrestle with. This requires a basic explanation of terms and ideas, so most chapters contain a broad brushstrokes summary of a biological field, e.g. measuring mutation rates, epidemiology modeling, hidden Markov models for gene structure, and limitations of medical testing. I hope the experts in these fields forgive my omitting the interesting details that they spend their lives investigating, and trust that I managed to get the basic ideas across without gross distortion."
  },
  {
    "objectID": "index.html#organization-of-the-book",
    "href": "index.html#organization-of-the-book",
    "title": "Quantifying Life",
    "section": "Organization of the book",
    "text": "Organization of the book\nA course based on this textbook can be tailored to fit the quantitative needs of a biological sciences curriculum. At the University of Chicago the course I teach has replaced the last quarter of calculus as a first-year requirement for biology majors. This material could be used for a course without a calculus pre-requisite that a student takes before more rigorous statistics, mathematics, or computer science courses. It may also be taught as an upper-level elective course for students with greater maturity who may be ready to tackle the eigenvalues and differential equations chapters. My hope is that it may also prove useful for graduate students or established scientists who need an elementary but comprehensive introduction to the concepts they encounter in the literature or that they can use in their own research. Whatever path you traveled to get here, I wish you a fruitful journey through biomathematics and computation!"
  },
  {
    "objectID": "counting.html#sec:bio1",
    "href": "counting.html#sec:bio1",
    "title": "1  Arithmetic and variables",
    "section": "1.1 Blood circulation and mathematical modeling",
    "text": "1.1 Blood circulation and mathematical modeling\nGalen was one of the great physicians of antiquity. He studied how the body works by performing experiments on humans and animals. Among other things, he was famous for a careful study of the heart and how blood traveled through the body. Galen observed that there were different types of blood: arterial blood that flowed out of the heart, which was bright red, and venous blood that flowed in the opposite direction, which was a darker color. This naturally led to questions: what is the difference between venous and arterial blood? where does each one come from and where does it go?\nYou, a reader of the 21st century, likely already know the answer: blood circulates through the body, bringing oxygen and nutrients to the tissues through the arteries, and returns back through the veins carrying carbon dioxide and waste products, as shown in figure \\(\\ref{fig:circulation}\\). Arterial blood contains a lot of oxygen while venous blood carries more carbon dioxide, but otherwise they are the same fluid. The heart does the physical work of pushing arterial blood out of the heart, to the tissues and organs, as well as pushing venous blood through the second circulatory loop that goes through the lungs, where it picks up oxygen and releases carbon dioxide, becoming arterial blood again. This may seem like a very natural picture to you, but it is far from easy to deduce by simple observation.\n\n\n\nHuman blood circulates throughout the body and returns to the heart, veins shown in blue and arteries in red. Circulatory System en by LadyofHats in public domain via Wikimedia Commons.\n\n\n\n1.1.1 Galen’s theory of blood\nGalen came up with a different explanation based on the notion of humors, or fluids, that was fundamental to the Greek conception of the body. He proposed that the venous and arterial blood were different humors: venous blood, or natural spirits, was produced by the liver, while arterial blood, or vital spirits, was produced by the heart and carried by the arteries, as shown in figure \\(\\ref{fig:galen_blood}\\). The heart consisted of two halves, and it warmed the blood and pushed both the natural and vital spirits out to the organs; the two spirits could mix through pores in the septum separating its right and left halves. The vital and natural spirits were both consumed by the organs, and regenerated by the liver and the heart. The purpose of the lungs was to serve as bellows, cooling the blood after it was heated by the heart.\n\n\n\nIllustration of Galen’s conception of the blood system, showing different spirits traveling in one direction, but not circulating. Reproduced by permission of Barbara Becker.\n\n\nIs this a good theory of how the heart, lungs, and blood work? Doctors in Europe thought so for over one thousand years! Galen’s textbook on physiology was the standard for medical students through the 17th century. The theory seemed to make sense, and explain what was observable. Many great scientists and physicians, including Leonardo DaVinci and Avicenna, did not challenge the inaccuracies such as the porous septum in the heart, even though they could not see the pores themselves. It took both better observations and a quantitative testing of the hypothesis to challenge the orthodoxy.\n\n\n1.1.2 Mathematical testing of the theory\nWilliam Harvey was born in England and studied medicine in Padua under the great physician Hieronymus Fabricius. He became famous, and would perform public demonstrations of physiology, using live animals for experiments that would not be approved today. He also studied the heart and the blood vessels, and measured the volume of the blood that can be contained in the human heart. He was quite accurate in estimating the correct volume, which we now know to be about 70 ml (1.5 oz). What is even more impressive is that he used this quantitative information to test Galen’s theory.\nLet us assume that all of the blood that is pumped out by the heart is consumed by the tissues, as Galen proposed; let us further assume that the heart beats at constant rate of 60 beats per minute, with a constant ejection volume of 70 ml. Then over the course of a day, the human body would consume about \\[\\mathrm{Volume} = 70 \\ \\mathrm {mL} \\times 60 \\ \\mathrm {(beats \\ per \\ minute)} \\times 60 \\ \\mathrm {(minutes \\ per \\ hour)}  \\times 24 \\ \\mathrm {(hours \\ per \\ day)}\\]\nor over 6,000 liters of blood! You may quibble over the exact numbers (some hearts beat faster or slower, some hearts may be larger or smaller) but the impact of the calculation remains the same: it is an absurd conclusion. Galen’s theory would require the human being to consume and produce a quantity of fluid many times the volume of the human body (about 100 liters) in a day! This is a physical impossibility, so the only possible conclusion in that Galen’s model is wrong.\nThis led Harvey to propose the model that we know today: that blood is not consumed by the tissues, but instead returns to the heart and is re-used again . This is why we call the heart and blood vessels part of the circulatory system of the body. This model was controversial at the time - some people proclaimed they would “rather be wrong with Galen, than right with Harvey” - but eventually became accepted as the standard model. What is remarkable is that Harvey’s argument, despite being grounded in empirical data, was strictly mathematical. He adopted the assumptions of Galen, made the calculations, and got a result which was inconsistent with reality. This is an excellent example of how mathematical modeling can be useful, because it can provide clear evidence against a wrong hypothesis."
  },
  {
    "objectID": "counting.html#sec:math1",
    "href": "counting.html#sec:math1",
    "title": "1  Arithmetic and variables",
    "section": "1.2 Parameters and variables in models",
    "text": "1.2 Parameters and variables in models\nMany biologists remain skeptical of mathematical modeling. The criticism can be summarized like this: a theoretical model either agrees with experiment, or it does not. In the former case, it is useless, because the data are already known; in the latter case, it is wrong! As I indicated above, the goal of mathematical modeling is not to reproduce experimental data; otherwise, indeed, it would only be of interest to theoreticians. The correct question to ask is, does a theoretical model help us understand the real thing? There are at least three ways in which a model can be useful:\n\nA model can help a scientist make sense of complex data, by testing whether a particular mechanism explains the observations. Thus, a model can help clarify our understanding by throwing away the non-essential features and focusing on the most important ones.\nA mathematical model makes predictions for situations that have not been observed. It is easy to change parameters in a mathematical model and calculate the effects. This can lead to new hypotheses that can be tested by experiments.\nModel predictions can lead to better experimental design. Instead of trying a whole bunch of conditions, the theoretical model can suggest which ones will produce big effects, and thus can save a lot of work for the lab scientist.\n\nIn order to make a useful model of a complex living system, you have to simplify it. Even if you are only interested in a part of it, for instance a cell or a single molecule, you have to make simplifying choices. A small protein has thousands of atoms, a cell consists of millions of molecules, which all interact with each other; keeping track mathematically of every single component is daunting if not impossible. To build a useful mathematical model one must choose a few quantities which describe the system sufficiently to answer the questions of interest. For instance, if the positions of a couple of atoms in the protein you are studying determine its activity, those positions would make natural quantities to include in your model. You will find more specific examples of models later in this chapter.\nOnce you have decided on the essential quantities to be included in the model, these are divided into variables and parameters. As suggested by the name, a variable typically varies over time and the model tracks the changes in its value, while parameters usually stay constant, or change more slowly. However, that is not always the case. The most important difference is that variables describe quantities within the system being modeled, while parameters usually refer to quantities which are controlled by something outside the system.\nAs you can see from this definition, the same quantity can be a variable or a parameter depending on the scope of the model. Let’s go back to our example of modeling a protein: usually the activity (and the structure) of a protein is influenced by external conditions such as pH and temperature; these would be natural parameters for a model of the molecule. However, if we model an entire organism, the pH (e.g. of the blood plasma) and temperature are controlled by physiological processes within the organism, and thus these quantities will now be considered variables.\nPerhaps the clearest way to differentiate between variables and parameters is to think about how you would present a data set visually. We will discuss plotting graphs of functions in chapter 2, and plotting data sets in chapter 3, but the reader has likely seen many such plots before. Consider which of the quantities you would to plot to describe the system you are modeling. If the quantity belongs on either axis, it is a variable, since it is important to describe how it changes. The rest of the quantities can be called parameters. Of course, depending on the question you ask, the same quantity may be plotted on an axis or not, which is why this classification is not absolute.\nAfter we have specified the essential variables for your model, we can describe a complex and evolving biological system in terms of its state. This is a very general term, but it usually means the values of all the variables that you have chosen for the model, which are often called state variables. For instance, an ion channel can be described with the state variable of conformation, which may be in a open state or in a closed state. The range, or collection of all different states of the system is called the state space of the model. Below you will find examples of models of biological systems with diverse state spaces.\n\n1.2.1 discrete state variables: genetics\nThere are genes which are present in a population as two different versions, called *alleles} - let us use letters \\(A\\) and \\(B\\) to label them. One may describe the genetic state of an individual based on which allele it carries. If this individual is haploid, e.g. a bacterium, then it only carries a single copy of the genome, and its state can be described by a single variable with the state space of \\(A\\) or \\(B\\).\nA diploid organism, like a human, possesses two copies of each gene (unless it is on one of the sex chromosomes, X or Y); each copy may be in either state \\(A\\) or \\(B\\). This may seem to suggest that there are four different values in the genetic state space, but if the order of the copies does not matter (which is usually the case), then \\(AB\\) and \\(BA\\) are effectively the same, so the state space consists of three values: \\(AA\\), \\(BB\\), and \\(AB\\).\n\n\n1.2.2 discrete state variables: population\nConsider the model of a population of individuals, with the variable of number of individuals (populations size) and parameters being the birth and death rates. The state space of this model is all integers between 0 and infinity.\nConsider the model of a population of individuals who may get infected. Assume that the total number of individuals does not change (that is, there are no births and deaths) and that these individuals can be in one of two states: healthy or sick (in epidemiology these are called susceptible or infectious). There are typically two parameters in such models: the probability of infection and the probability of recovery. Since the total population is fixed at some number \\(N\\), the space space of the model is all pairs of integers between 0 and \\(N\\) that add up to \\(N\\).\n\n\n1.2.3 continuous state variables: concentration\nSuppose that a biological molecule is produced with a certain rate and degraded with a different rate, and we would like to describe the quantity of the molecule, usually expressed as concentration. The relevant variables here are concentration and time, and you will see those variables on the axes of many plots in biochemistry. Concentration is a ratio of the number of molecules and the volume, so the state space can be any positive real number (although practically there is a limit as to how many molecules can fit inside a given volume, but for simplicity we can ignore this).\nGoing even further, let us consider an entire cell, which contains a large number of different molecules. We can describe the state of a cell as the collection of all the molecular concentrations, with the parameters being the rates of all the reactions going on between those molecules. The state space for this model with \\(N\\) different molecules is \\(N\\) positive real numbers.\n\n\n1.2.4 multiple variables in medicine\nDoctors take medical history from patients and measure vital signs to get a picture of a patient’s health. These can be all be thought of as variables in a model of a person that physicians construct. Some of these variables are discrete, for instance whether there is family history of hypertension, which has only two values: yes or no. Other variables are numbers with a range, such as weight and blood pressure. The state space of this model is a combination of categorical values (such as yes/no) and numerical values (within a reasonable range).\n\n\n1.2.5 Discussion questions\nSeveral biological models are indicated below. Based on what you know, divide the quantities into variables and parameters and describe the state space of the model. Note that there may be more than one correct interpretation\n\nThe volume of blood pumped by the heart over a certain amount of time, depending on the heart rate and the ejection volume.\nThe number of wolves in a national forest depending on the number of wolves in the previous year, the birth rate, the death rate, and the migration rate.\nThe fraction of hemes in hemoglobin (a transport protein in red blood cells) which are bound to oxygen depending on the partial pressure of oxygen and the binding cooperativity of hemoglobin.\nThe number of mutations that occur in a genome, depending on the mutation rate, the amount of time, and the length of the genome.\nThe concentration of a drug in the blood stream depending on the dose, time after administration, and the rate of metabolism (processing) of the drug.\nDescribing an outbreak of an infectious disease in a city in terms of the fractions of infected, healthy, and recovered people, depending on the rate of infection, rate of recovery, and the mortality rate of the disease."
  },
  {
    "objectID": "counting.html#first-steps-in-r",
    "href": "counting.html#first-steps-in-r",
    "title": "1  Arithmetic and variables",
    "section": "1.3 First steps in R",
    "text": "1.3 First steps in R\n A central goal of this book is to help you, the reader, gain experience with computation, which requires learning some programming (cool kids call it “coding”). Programming is a way of interacting with computers through a symbolic language, unlike the graphic user interfaces that we’re all familiar with. Basically, programming allows you to make a computer do exactly what you want it to do.\nThere is a vast number of computer languages with distinct functionalities and personalities. Some are made to talk directly to the computer’s “brain” (CPU and memory), e.g. Assembly, while others are better suited for human comprehension, e.g. python or Java. Programming in any language involves two parts: 1) writing a program (code) using the commands and the syntax for the language; 2) running the code by using a compiler or interpreter to translate the commands into machine language and then making the computer execute the actions. If your code has a mistake in it, the compiler or interpreter should catch it, and return an error message to you instead of executing the code. Sometimes, though, the code may pass muster with the interpreter/compiler, but it may still have a mistake (bug). This can be manifested in two different ways: either the code execution does not produce the result that you intended, or it hangs up or crashes the computer (the latter is hard to do with the kind of programming we will be doing). We will discuss errors and how to prevent and catch these bugs as you develop your programming skills.\nIn this course, our goal is to compute mathematical models and to analyze data, so we choose a language that is designed specially for these tasks, which is called R. To proceed, you’ll need to download and install R, which is freely available here. In addition to downloading the language (which includes the interpreter that allows you to run R code on your computer) you will need to download a graphic interface for writing, editing, and running R code, called R Studio (coders call this an IDE, or an Integrated Developer Environment), which is also free and available here.\n\n1.3.1 R Markdown and R Studio\nIn this course you will use R using R Studio and R Markdown documents, which are text files with the extension .Rmd. Markdown is a simple formatting syntax for creating reports in HTML, PDF, or Word format by incorporating text with code and its output. More details on using R Markdown are here. In fact, this whole book is written in R Markdown files and then compiled to produce the beautiful (I hope you agree) web book that you are reading.\nIf you open an Rmd file in R Studio, you will see a Knit button on top of the Editor window. Clicking it initiates the processing of the file into an output document (in HTML, PDF, or Word format) that includes the text as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nprint(\"Hello there!\") \n\n[1] \"Hello there!\"\n\n\nTo run the code inside a single R code chunk, click the green arrow in the top right of the chunk. This will produce an output, in this case the text “Hello there!”. Inside the generated output file, for example the web book you may be reading, the output of code chunks is shown below the box with the R code and indicated by two hashtags.\nYou can make text bold or italic like so. You can also use mathematical notation called LaTeX, which you’ll see used below to generate nice-looking equations. LaTeX commands are surrounded by dollar signs, for example $e^x$ generates \\(e^x\\). Mathematical types love LaTeX, but you can use R Markdown without it.\n\n\n1.3.2 numbers and arithmetic operations\nWhen you get down to the brass tacks, all computation rests on performing arithmetic operations: addition, subtraction, multiplication, division, exponentiation, etc. The symbols used for arithmetic operations are what you’d expect: +, -, *, / are the four standard operations, and ^ is the symbol for exponentiation. For example, type 2^3 in any R code chunk and execute it:\n\n2^3\n\n[1] 8\n\n\nYou see that R returns the result by printing it out on the screen. The number in square brackets [1] is not important for now; it is useful when the answer contains many numbers and has to be printed out on many rows. The second number is the result of the calculation.\nFor numbers that are either very large or very small, it’s too cumbersome to write out all the digits, so R, like most computational platforms, uses the scientific notation. For instance, if you want to represent 1.4 billion, you type in the following command; note that 10 to the ninth power is represented as e+09 and the prefix 1.4 is written without any multiplication sign:\n\n1.4*10^9\n\n[1] 1.4e+09\n\n\nThere are also certain numbers built into the R language, most notably \\(\\pi\\) and \\(e\\), which can be accessed as follows:\n\npi\n\n[1] 3.141593\n\nexp(1)\n\n[1] 2.718282\n\n\nThe expression exp() is an example of a function, which we will discuss in section \\(\\ref{sec:comp2}\\); it returns the value of \\(e\\) raised to the power of the number in parenthesis, hence exp(1) returns \\(e\\). Notice that although both numbers are irrational, and thus have infinitely many decimal digits, R only prints out a few of them. This doesn’t mean that it doesn’t have more digits in memory, but it only displays a limited number to avoid clutter. The number of digits to be displayed can be changed, for example to display 10 digits, type in options(digits=10).\nComputers are very good at computation, as their name suggests, but they have limitations. In order to manipulate numbers, they must be stored in computer memory, but computer memory is finite. There is a limit to the length of the number that is feasible to store on a computer. This has implications for both very large numbers and to very small numbers, which are close to zero, because both require many digits for storage.\nAll programming languages have an upper limit on the biggest number it will store and work with. If an arithmetic operation results in a number larger than that limit, the computer will call it an overflow error. Depending on the language, this may stop the execution of the program, or else produce a non-numerical value, such as NaN (not a number) or Inf (infinite). Do exercise \\(\\ref{ex:overflow}\\) to investigate the limitations of R for large numbers.\nOn the other hand, very small numbers present their own challenges. As with very large numbers, a computer cannot store an arbitrary number of digits after the decimal (or binary) point. Therefore, there is also the smallest number that a programming language will accept and use, and storing a smaller number produces an underflow error. This will either cause the program execution to stop, or to return the value 0 instead of the correct answer. Do exercise \\(\\ref{ex:underflow}\\) to investigate the limitations of R for small numbers.\nThis last fact demonstrates that all computer operations are imprecise, as they are limited by what’s called the machine precision, which is illustrated in exercise \\(\\ref{ex:mach_prec}\\). For instance, two similar numbers, if they are within the machine precision of one another, will be considered the same by the computer. Modern computers have large memories, and their machine precision is very good, but sometimes this error presents a problem, e.g. when subtracting two numbers. A detailed discussion of machine error is beyond the scope of this text, but anyone performing computations must be aware of its inherent limitations.\n\n\n1.3.3 R Coding Exercises\n\nCalculate the value of \\(\\pi\\) raised to the 10th power.\nUse the scientific notation to multiply four billion by \\(\\pi\\).\nUse the scientific notation with large exponents (e.g. 1e+100, 1e+500, etc.) to find out what happens when you give R a number that is too large for it to handle. Approximately at what order of magnitude does R produce an overflow error?\nIn the same fashion, find out what happens when you give R a number that is too small for it to handle. Approximately at what order of magnitude does R produce an underflow error?\nHow close can two numbers be before R thinks they are the same? Subtract two numbers which are close to each other, like 24 and 24.001, and keep making them closer to each other, until R returns a difference of zero. Report at what value of the actual difference this happens.\n\n\n\n1.3.4 variable assignment\nVariables in programming languages are used to store and access numerical or other information. After assigning} it a value for the first time (initializing), a variable name can be used to represent the value we assigned to it. Invoking the name of variable recalls the stored value from computer’s memory. There are a few rules about naming variables: a name cannot be a number or an arithmetic operator like +, in fact it cannot contain symbols for operators or spaces inside the name, or else confusion would reign. Variable names may contain numbers, but not as the first character. When writing code it is good practice to give variables informative names, like height or city_pop. \nThe symbol ‘=’ is used to assign a value to a variable in most programming languages, and can be used in R too. However, it is customary for R to use the symbols <- together to indicate assignment, like this:\n\nvar1 <- 5\n\nAfter this command the variable var1 has the value 5, which you can see in the upper right frame in R Studio called Environment. In order to display the value of the variable as an output on the screen, use the special command print() (it’s actually a function, which we will discuss in the next chapter). The following two commands show that the value of a variable can be changed after it has been initialized:\n\nvar1 <- 5\nvar1 <- 6\nprint(var1)\n\n[1] 6\n\n\nWhile seemingly contradictory, the commands are perfectly clear to the computer: first var1 is assigned the value 5 and then it is assigned 6. After the second command, the first value is forgotten, so any operations that use the variable var1 will be using the value of 6.\nEntire expressions can be placed on the right hand side of an assignment command: they could be arithmetic or logical operations as well as functions, which we will discuss later on. For example, the following commands result in the value 6 being assigned to the variable var2:\n\nvar1 <- 5\nvar2 <- var1+1\nprint(var2)\n\n[1] 6\n\n\nEven more mind-blowing is that the same variable can be used on both sides of an assignment operator! The R interpreter first looks on the right hand side to evaluate the expression and then assigns the result to the variable name on the left hand side. So for instance, the following commands increase the value of var1 by 1, and then assign the product of var1 and var2 to the variable var2:\n\nvar1 <- var1 + 1\nprint(var1)\n\n[1] 6\n\nvar2 <- var1-1\nprint(var2)\n\n[1] 5\n\nvar2 <- var1*var2\nprint(var2)\n\n[1] 30\n\n\nWe have seen example of how to assign values to variables, so here is an example of how NOT to assign values, with the resulting error message:\n\nvar1 + 1 <- var1\n\nThe left-hand side of an assignment command should contain only the variable to which you are assigning a value, not an arithmetic expression to be performed.\n\n\n1.3.5 R Coding Exercises\nThe following commands or scripts do not work as intended. Find the errors and correct them, then run them to make sure they do what they are intended to do:\n\n\n1.3.6 Exercises:\nThe following R commands or short scripts contain errors; your job is to fix them so they runs as described. (Remove the # at the start of each line to “uncomment” the code first.)\n\nAssign the value -10 to a variable\n\n\nneg -> -10\n\n\nAssign a variable the value 5 and then increase its value by 3:\n\n\n2pac <- 5\n2pac <- 2pac + 3\n\n\nAssign the values 4 and 7 to two variables, then add them together and assign the sum to a new variable:\n\n\ntotal <- part1 + part2\npart1 <- 4\npart2 <- 7\n\n\nAdd 5 and 3 and save it into variable my.number\n\n\n5 + 3 <- my.number\n\n\nPrint the value of my.number on the screen:\n\n\nprint[my.number]\n\n\nReplace the value of my.number with 5 times its current value\n\n\nmy.number <- 5my.number \n\n\nAssign the values of 7 and 8 to variables a and b, respectively, multiply them and save the results in variable x\n\n\na<-7\nb<-8\nx<-ab\nprint(x)\n\n\nAssign the value 42 to a variable, then increase it by 1\n\n\nage <- 42\nage + 1 <- age\n\n\nAssign the value 10 to variable radius, then calculate the area of the circle with that radius using the formula \\(A = \\pi r^2\\):\n\n\nr <- 10\narea <- pir^2"
  },
  {
    "objectID": "functions.html#sec:model2",
    "href": "functions.html#sec:model2",
    "title": "2  Functions and their graphs",
    "section": "2.1 Dimensions of quantities",
    "text": "2.1 Dimensions of quantities\nWhat distinguishes a mathematical model from a mathematical equation is that the quantities involved have a real-world meaning. Each quantity represents a measurement, and associated with each one are the units of measurement. The number 173 is not enough to describe the height of a person - you are left to wonder 173 what? meters, centimeters, nanometers, light-years? Obviously, only centimeters make sense as a unit of measurement for human height; but if we were measuring the distance between two animals in a habitat, meters would be a reasonable unit, and it were the distance between molecules in a cell, we would use nanometers. Thus, any quantity in a mathematical model must have associated units, and any graphs of these quantities must be labeled accordingly.\nIn addition to units, each variable and parameter has a meaning, which is called the dimension of the quantity. For example, any measurement of length or distance has the same dimension, although the units may vary. The value of a quantity depends on the units of measurement, but its essential dimensionality does not. One can convert a measurement in meters to that in light-years or cubits, but one cannot convert a measurement in number of sheep to seconds - that conversion has no meaning.\nThus leads us to the fundamental rule of mathematical modeling: terms that are added or subtracted must have the same dimension. This gives mathematical modelers a useful tool called dimensional analysis, which involves replacing the quantities in an equation with their dimensions. This serves as a check that all dimensions match, as well as allowing to deduce the dimensions of any parameters for which the dimension was not specified. \nExample. As we saw in chapter 1, the relationship between the amount blood pumped by a heart in a certain amount of time is expressed in the following equation, where \\(V_{tot}\\) and \\(V_s\\) are the total volume and stroke volume, respectively, \\(R\\) is the heart rate, and \\(t\\) is the time: \\[\nV_{tot} = V_sRt\n\\] The dimension of a quantity \\(X\\) is denoted by \\([X]\\); for example, if \\(t\\) has the dimension of time, we write \\([t] = time\\). The dimension of volume is \\([V_{tot}] = length^3\\), the dimension of stroke volume is \\([V_s] = volume/beat\\) and the dimension of time \\(t\\) is time, so we can re-write the equation above in dimensional form:\n\\[length^3 = length^3/ beat \\times R \\times time\\]\nSolving this equation for R, we find that it must have the dimensions of \\([R] = beats/time\\). It can be measured in beats per minute (typical for heart rate), or beats per second, beats per hour, etc. but the dimensionality of the quantity cannot be changed without making the model meaningless.\nThere are also dimensionless quantities, or pure numbers, which are not tied to a physical meaning at all. Fundamental mathematical constants, like \\(\\pi\\) or \\(e\\), are classic examples, as are some important quantities in physics, like the Reynolds number in fluid mechanics. Quantities with a dimension can be made dimensionless by dividing them by another quantity with the same dimension and “canceling” the dimensions. For instance, we can express the height of a person as a fraction of the mean height of the population; then the height of a tall person will become a number greater than 1, and the height of a short one will become less than 1. This new dimensionless height does not have units of length - they have been divided out by the mean height. This is known as rescaling the quantity, by dividing it by a preferred scale. There is a fundamental difference between rescaling and changing the units of a quantity: when changing the units, e.g. from inches to centimeters, the dimension remains the same, but if one divides the quantity by a scale, it loses its dimension.\nExample. The model for a population of bacteria that doubles every hour is described by the equation, where \\(P_0\\) is initial number of bacteria and \\(P\\) is the population after \\(t\\) hours: \\[ P = P_0 2^t \\] Let us define the quantity \\(R=P/P_0\\), so we can say that population increased by a factor of \\(R\\) after \\(t\\) hours. This ratio is a dimensionless quantity because \\(P\\) and \\(P_0\\) have the same dimension of bacterial population, which cancel out. The equation for \\(R\\) can be written as follows: \\[ R= 2^t \\] According to dimensional analysis, both sides of the equation have to be dimensionless, so \\(t\\) must also be a dimensionless variable. This is surprising, because \\(t\\) indicates the number of hours the bacterial colony has been growing. This reveals the subtle fact that \\(t\\) is a rescaled variable obtained by dividing the elapsed time by the length of the reproductive cycle. Because of the assumption that the bacteria divide exactly once an hour, \\(t\\) counts the number of hours, but if they divided once a day, \\(t\\) would denote the number of days. So \\(t\\) doesn’t have units or dimensions, but instead denotes the dimensionless number of cell divisions.\n\n2.1.1 Exercises\nFor each biological model below determine the dimensions of the parameters, based on the given dimensions of the variables.\n\nModel of number of mutations \\(M\\) as a function of time \\(t\\): \\[ M(t) = M_0 + \\mu t\\]\nModel of molecular concentration \\(C\\) as a function of time \\(t\\): \\[ C(t) = C_0 e^{-kt} \\]\nModel of tree height \\(H\\) (length) as a function of age \\(a\\) (time): \\[ H(a) = \\frac{b a}{c + a}\\]\nModel of cooperative binding of ligands, with fraction of bound receptors \\(\\theta\\) as a function of ligand concentration \\(L\\): \\[ \\theta (L) = \\frac{L^n}{L^n + K_d}\\]\nModel of concentration of a gene product \\(G\\) (concentration) as a function of time \\(t\\): \\[ G(t) = G_m (1 - e^{-\\alpha t})\\]\nMichaelis-Menten model of enzyme kinetics, \\(v\\) is reaction rate (1/time) and \\(S\\) is substrate concentration: \\[ v(S) = \\frac{v_{max} S}{K_m + S}\\]\nLogistic model of population growth, \\(P\\) is population size and time \\(t\\): \\[ P(t) = \\frac{A e^{kt}}{1 + B(e^{kt} -1)} \\]"
  },
  {
    "objectID": "functions.html#sec:math2",
    "href": "functions.html#sec:math2",
    "title": "2  Functions and their graphs",
    "section": "2.2 Functions and their graphs",
    "text": "2.2 Functions and their graphs\nA relationship between two variables addresses the basic question: when one variable changes, how does this affect the other? An equation, like the examples in the last section, allows one to calculate the value of one variable based on the other variable and parameter values. In this section we seek to describe more broadly how two variables are related by using the mathematical concept of functions.\n\n\n\n\n\n\nDefinition\n\n\n\nA function is a mathematical rule which has an input and an output. A function returns a well-defined output for every input, that is, for a given input value the function returns a unique output value.\n\n\nIn this abstract definition of a function it doesn’t have to be written as an algebraic equation, it only has to return a unique output for any given input value. In mathematics we usually write them down in terms of algebraic expressions. As in mathematical models, you will see two different kinds of quantities in equations that define functions: variables and parameters. The input and the output of a function are usually variables, with the input called the independent variable and the output called the dependent variable.\nThe relationship between the input and the output can be graphically illustrated in a graph, which is a collection of paired values of the independent and dependent variable drawn as a curve in the plane. Although it shows how the two variables change relative to each other, parameters may change too, which results in a different graph of the function. While graphing calculators and computers can draw graphs for you, it is very helpful to have an intuitive understanding about how a function behaves, and how the behavior depends on the parameters. Here are the three questions to help picture the relationship (assume \\(x\\) is the independent variable and it is a nonnegative real number):\n\nwhat is the value of the function at \\(x=0\\)?\nwhat does the function do when \\(x\\) becomes large (\\(x \\to \\infty\\))?\nwhat does the function do between the two extremes?\n\nBelow you will find examples of fundamental functions used in biological models with descriptions of how their parameters influence their graphs.\n\n2.2.1 linear and exponential functions\nThe reader is probably familiar with linear and exponential functions from algebra courses. However, they are so commonly used that it is worth going over them to refresh your memory and perhaps to see them from another perspective.\n\n\n\n\n\n\nDefinition\n\n\n\nA linear function \\(f(x)\\) is one for which the difference in two function values is the same for a specific difference in the independent variable.\n\n\nIn mathematical terms, this can be written an equation for any two values of the independent variable \\(x_1\\) and \\(x_2\\) and a difference \\(\\Delta x\\):\n\\[ f(x_1 + \\Delta x) - f(x_1) = f(x_2 + \\Delta x) - f(x_2) \\] The general form of the linear function is written as follows:\n\\[\\begin{equation}\nf(x) = ax + b\n\\label{eq:linear_funk}\n\\end{equation}\\]\nThe function contains two parameters: the slope \\(a\\) and the y-intercept \\(b\\). The graph of the linear function is a line (hence the name) and the slope \\(a\\) determines its steepness. A positive slope corresponds to the graph that increases as \\(x\\) increases, and a negative slope corresponds to a declining function. At \\(x=0\\), the function equals \\(b\\), and as \\(x \\to \\infty\\), the function approaches positive infinity if \\(a>0\\), and approaches negative infinity if \\(a<0\\).\n\n\n\n\n\n\nDefinition\n\n\n\nAn exponential function \\(f(x)\\) is one for which the ratio of two function values is the same for a specific difference in the independent variable.\n\n\nMathematically speaking, this can be written as follows for any two values of the independent variable \\(x_1\\) and \\(x_2\\) and a difference \\(\\Delta x\\): \\[ \\frac{f(x_1 + \\Delta x)}{f(x_1)} = \\frac{f(x_2 + \\Delta x)}{f(x_2)}\\]\nExponential functions can be written using different symbolic forms, but they all have a constant base with the variable \\(x\\) in the exponent. I prefer to use the constant \\(e\\) (base of the natural logarithm) as the base of all the exponential functions, for reasons that will become apparent in chapter 15. This does not restrict the range of possible functions, because any exponential function can be expressed using base \\(e\\), using a transformation: \\(a^x = e^{x \\ln(a)}\\). So let us agree to write exponential functions in the following form:\n\\[\\begin{equation}\nf(x) = a e^{rx}\n\\label{eq:exp_funk}\n\\end{equation}\\]\nThe function contains two parameters: the \\(r\\) and the multiplicative constant \\(a\\). The graph of the exponential function is a curve which crosses the y-axis at \\(y=a\\) (plug in \\(x=0\\) to see that this is the case). As \\(x\\) increases, the behavior of the graph depends on the sign of the rate constant \\(r\\). If \\(r>0\\), the function approaches infinity (positive if \\(a>0\\), negative if \\(a<0\\)) as \\(x \\to \\infty\\). If \\(r<0\\), the function decays at an ever-decreasing pace and asymptotically approaches zero as \\(x \\to \\infty\\). Thus the graph of \\(f(x)\\) is a curve either going to infinity or a curve asymptotically approaching 0, and the steepness of the growth or decay is determined by \\(r\\).\n\n\n\n\n\nPlots of two linear functions (left) and two exponential functions (right). Can you identify which linear function has the positive slope and which one negative? Which exponential function has a positive rate constant and which one negative?\n\n\n\n\n\n\n\nPlots of two linear functions (left) and two exponential functions (right). Can you identify which linear function has the positive slope and which one negative? Which exponential function has a positive rate constant and which one negative?\n\n\n\n\n\n\n2.2.2 Exercises\nAnswer the questions below, some of which refer to the function graphs in figure @ref(ch2-funk1).\n\nWhich of the linear graphs in the first figure corresponds to \\(f(x) = 5x\\) and which corresponds to \\(f(x) = 10-x\\)? State which parameter allows you to connect the function with its graph and explain why.\nWhich of the exponential graphs in the second figure corresponds to \\(f(x) = 0.1e^{0.5x}\\) and which corresponds to \\(f(x) = 12e^{-0.2x}\\)? State which parameter allows you to connect the function with its graph and explain why.\nDemonstrate algebraically that a linear function of the form given in equation \\(\\ref{eq:linear_funk}\\) satisfies the property of linear functions from definition .\nDemonstrate algebraically that an exponential function of the form given in equation \\(\\ref{eq:exp_funk}\\) satisfies the property of exponential functions from definition .\nModify the exponential function by adding a constant term to it \\(f(x) = a e^{rx} + b\\). What is is the value of this function at \\(x=0\\)?\nHow does the function defined in the previous exercise, \\(f(x) = a e^{rx} + b\\), how does it behave as \\(x \\to \\infty\\) if \\(r>0\\)?\nHow does the function \\(f(x) = a e^{rx} + b\\) behave as \\(x \\to \\infty\\) if \\(r<0\\)?\n\n\n\n2.2.3 rational and logistic functions\nLet us now turn to more complex functions, made up of simpler components that we understand. Consider a ratio of two polynomials, called a rational function. The general form of such functions can be written down as follows, where ellipsis stands for terms with powers lower than \\(n\\) or \\(m\\): \\[\\begin{equation}\nf(x) = \\frac{a_0 + ... + a_n x^n}{b_0 + ... + b_m x^m}\n\\label{eq:rational_funk}\n\\end{equation}\\] The two polynomials may have different degrees (highest power of the terms, \\(n\\) and \\(m\\)), but they are usually the same in most biological examples. The reason is that if the numerator and the denominator are ``unbalanced’’, one will inevitably overpower the other for large values of \\(x\\), which would lead to the function either increasing without bound to infinity (if \\(n>m\\)) or decaying to zero (if \\(m>n\\)). There’s nothing wrong with that, mathematically, but rational functions are most frequently used to model quantities that approach a nonzero asymptote for large values of the independent variable.\nFor this reason, let us assume \\(m=n\\) and consider what happens as \\(x \\to \\infty\\). All terms other than the highest-order terms become very small in comparison to \\(x^n\\) (this is something you can demonstrate to yourself using R), and thus both the numerator and the denominator approach the terms with power \\(n\\). This can be written using the mathematical limit notation \\(\\lim_{x \\to \\infty}\\) which describes the value that a function approaches when the independent variable increases without bound: \\[  \\lim_{x \\to \\infty} \\frac{a_0 + ... + a_n x^n}{b_0 + ... + b_n x^n} = \\frac{ a_n x^n}{ b_n x^n}  =  \\frac{ a_n}{ b_n}  \\] Therefore, the function approaches the value of \\(a_n /b_n\\) as \\(x\\) grows.\nSimilarly, let us consider what happens when \\(x=0\\). Plugging this into the function results in all of the terms vanishing except for the constant terms, so \\[ f(0) =  \\frac{ a_0}{ b_0} \\] Between 0 and infinity, the function either increases or decreases monotonically, depending on which value (\\(a_n /b_n\\) or \\(a_0/b_0\\)) is greater. Two examples of plots of rational functions are shown in figure \\(\\ref{fig:ch2_sigmoidal_plots}\\), which shows graphs increasing from 0 to 1. Depending on the degree of the polynomials in a rational function, it may increase more gradually (solid line) or more step-like (dashed line).\n The following model, called the Hill equation , describes the fraction of receptor molecules which are bound to a ligand, which is a chemical term for a free molecule that binds to another, typically larger, receptor molecule. \\(\\theta\\) is the fraction of receptors bound to a ligand, \\(L\\) denotes the ligand concentration, \\(K_d\\) is the dissociation constant, and \\(n\\) called the binding cooperativity or Hill coefficient: \\[ \\theta = \\frac{L^n}{ L^n +K_d}\\]\nThe Hill equation is a rational function, and Figure \\(\\ref{fig:ch2_sigmoidal_plots}\\) shows plots of the graphs of two such function in the right panel. This model is further explored in exercise 2.2.10.\nExample. A common model of population over time is the logistic function. There are variations on how it is written down, but here is one general form: \\[\\begin{equation}\nf(x) = \\frac{a e^{rx} }{b+e^{rx}}\n\\label{eq:logistic_funk}\n\\end{equation}\\]\nThe numerator and denominator both contain exponential functions with the same power. If \\(r>0\\) when \\(x \\to \\infty\\), the denominator approaches \\(e^{rx}\\), since it becomes much greater than \\(b\\), and we can calculate: \\[  \\lim_{x \\to \\infty}  =  \\frac{a e^{rx} }{e^{rx}} = a; \\; \\mathrm{if} \\; r>0 \\]\nOn the other hand, if \\(r<0\\), then the numerator approaches zero as \\(x \\to \\infty\\), and so does the function \\[  \\lim_{x \\to \\infty}  =  \\frac{0}{b} = 0; \\; \\mathrm{if} \\; r<0 \\]\nNotice that switching the sign of \\(r\\) has the same effect as switching the sign of \\(x\\), since they are multiplied. Which means that for positive \\(r\\), if \\(x\\) is extended to negative infinity, the function approaches 0. This is illustrated in the second plot in Figure \\(\\ref{fig:ch2_sigmoidal_plots}\\), which shows two logistic functions increasing from 0 to a positive level, one with \\(a=20\\) (solid line) and the second with \\(a=10\\) (dashed line). The graph of logistic functions has a characteristic sigmoidal (S-shaped) shape, and its steepness is determined by the rate \\(r\\): if \\(r\\) is small, the curve is soft, if \\(r\\) is large, the graph resembles a step function.\n\n\n\n\n\nExamples of two graphs of logistic functions (left) and two Hill functions (right).\n\n\n\n\n\n\n\nExamples of two graphs of logistic functions (left) and two Hill functions (right).\n\n\n\n\n\n\n2.2.4 Exercises:\nFor each biological model below answer the following questions in terms of the parameters in the models, assuming all are nonnegative real numbers. 1) what is the value of the function when the independent variable is 0? 2) what value does the function approach when the independent variable goes to infinity? 3) verbally describe the behavior of the functions between 0 and infinity (e.g., function increases, decreases).\n\nModel of number of mutations \\(M\\) as a function of time \\(t\\): \\[ M(t) = M_0 + \\mu t\\]\nModel of molecular concentration \\(C\\) as a function of time \\(t\\): \\[ C(t) = C_0 e^{-kt} \\]\nModel of cooperative binding of ligands, with fraction of bound receptors \\(\\theta\\) as a function of ligand concentration \\(L\\): \\[ \\theta = \\frac{L^n}{L^n + K_d}\\]\nModel of tree height \\(H\\) (length) as a function of age \\(a\\) (time): \\[ H(a) = \\frac{b a }{c + a}\\]\nModel of concentration of a gene product \\(G\\) (concentration) as a function of time \\(t\\): \\[ G(t) = G_m (1 - e^{-\\alpha t})\\]\nMichaelis-Menten model of enzyme kinetics, \\(v\\) is reaction rate (1/time) and \\(S\\) is substrate concentration: \\[ v(S) = \\frac{v_{max} S}{K_m + S}\\]\nLogistic model of population growth, \\(P\\) is population size and time \\(t\\): \\[ P(t) = \\frac{A e^{kt}}{1 + B(e^{kt} -1)} \\]"
  },
  {
    "objectID": "functions.html#vectors-and-plotting-in-r",
    "href": "functions.html#vectors-and-plotting-in-r",
    "title": "2  Functions and their graphs",
    "section": "2.3 Vectors and plotting in R",
    "text": "2.3 Vectors and plotting in R\n\n\n2.3.1 writing scripts and calling functions\nProgramming means arranging a number of commands in a particular order to perform a task. Typing them one at a time into the command line is inefficient and error-prone. Instead, the commands are written into a file called a program or script (the name depends on the type of language; since R is a scripting language you will be writing scripts), which can be edited, saved, copied, etc. To open a new script file, in R Studio, go to File menu, and choose New R Script. This will open an editor window where you can type your commands. To save the script file (do this often!!), click the Save button (with the little floppy disk icon) or select Save from the File menu. You will also see small buttons at the top of the window that say Run, Re-run, and Source. The first two will run either the current line or a selected region of the script, while the Source button will run the entire file. Now that you know how to create a script, you should never type your R code into the command line, unless you’re testing a single command to see what it does, or looking up help.\nR comes equipped with many functions that correspond to standard mathematical functions. As we saw in section \\(\\ref{sec:comp1}\\), exp() is the exponential function that returns \\(e\\) raised to the power of the input value. Other common ones are: sqrt() returns the square root of the input value; sin() and cos() return the sine and the cosine of the input value, respectively. Note that all of these function names are followed by parentheses, which is a hallmark of a function (in R as well as in mathematics). This indicates that the input value has to go there, for example exp(5). To compute the value of \\(e^5\\), save it into a variable called var1 and then print out the value on the screen, you can create the following script:\n\nvar1 <- exp(5)\nprint(var1)\n\n[1] 148.4132\n\n\nIf you run the above code chunk in R Studio you will see two things happen: a variable named var1 appears in the Environment window (top right) with the value 148.41… and the same value is printed out in the command line window (bottom left).\nThe most important principle of the procedural brand of programming (which includes R) is this: the computer (that is, the compiler or interpreter) evaluates the commands from top to bottom, one at a time. The variables are used with the values that they are currently assigned. If one variable (var1) was assigned in terms of another (var2), and then var2 is changed later, this does not change the value of var2. Here is an illustration of how this works:\n\nvar2 <- 20\nvar1 <- var2/20\nprint(var2)\n\n[1] 20\n\nvar2 <- 10\nprint(var1)\n\n[1] 1\n\n\nNotice that var1 doesn’t change, because the R interpreter reads the commands one by one, and does not go back to re-evaluate the assignment for var1 after var2 is changed. Learning to think in this methodical, literal manner is crucial for developing programming skills.\n\n\n2.3.2 vector variables\nVariables may contain more than a single number, they can also store a bunch of numbers, which is then called an array. When numbers in an array are organized as a single ordered list, this is called a vector. There are several ways of producing a vector of numbers in R.\n\n2.3.2.1 c() function\nThe most direct method of making a vector is to put together several values by listing them inside the function c() and assigning the output to a variable, e.g. my.vec:\n\nmy.vec<-c(pi,45,912.8, 0)\nprint(my.vec)\n\n[1]   3.141593  45.000000 912.800000   0.000000\n\n\nThis variable my.vec is now a vector variable that contains four different numbers. Each of those numbers can be accessed individually by referencing its position in the vector, called the index. In the R language the the index for the first number in a vector is 1, the index for the second number is 2, etc. The index is placed in square brackets after the vector name, as follows:\n\nprint(my.vec[1])\n\n[1] 3.141593\n\nprint(my.vec[2])\n\n[1] 45\n\nprint(my.vec[3])\n\n[1] 912.8\n\nprint(my.vec[4])\n\n[1] 0\n\n\n\n\n2.3.2.2 the colon operator\nAnother way to generate a sequence of numbers in a particular order is to use the colon operator, which produces a vector of integers from the first number to the last, inclusive. Here are two examples:\n\nmy.vec1<-1:20\nprint(my.vec1)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\nmy.vec2<-0:-20\nprint(my.vec2)\n\n [1]   0  -1  -2  -3  -4  -5  -6  -7  -8  -9 -10 -11 -12 -13 -14 -15 -16 -17 -18\n[20] -19 -20\n\n\nYou can also access some but not all of the values stored in a vector simultaneously. To do this, enter a vector of positive integers inside the square brackets, either using the colon operator or using the c() function. Here are two examples, the first prints out the 4th through the 10th element of the vector my.vec1, while the second prints out the 1st, 5th, and 11th elements of the vector my.vec2:\n\nprint(my.vec1[4:10])\n\n[1]  4  5  6  7  8  9 10\n\nprint(my.vec2[c(1,5,11)])\n\n[1]   0  -4 -10\n\n\n\n\n2.3.2.3 seq() function\nIf you want to generate a sequence of numbers with a constant difference other than 1, you’re in luck: R provides a function called seq(). It takes three inputs: the starting value, the ending value, and the step (difference between successive elements). For example, to generate a list of numbers starting at 20 up to 50, with a step size of 3, type the first command; to obtain the same sequence in reverse, use the second command:\n\nmy.vec1<-seq(20,50,3)\nprint(my.vec1)\n\n [1] 20 23 26 29 32 35 38 41 44 47 50\n\nmy.vec2<-seq(50,20,-3)\nprint(my.vec2)\n\n [1] 50 47 44 41 38 35 32 29 26 23 20\n\n\n\n\n2.3.2.4 rep() function\nSometimes you want to create a vector of repeated values. For example, you can create a variable with 20 zeros, you can use rep() like this:\n\nzeros <- rep(0,20)\nprint(zeros)\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n\nYou can repeat any value, say create a vector by repeating the number pi:\n\npies <- rep(pi,7)\nprint(pies)\n\n[1] 3.141593 3.141593 3.141593 3.141593 3.141593 3.141593 3.141593\n\n\nYou can even repeat another vector, like the vector my.vec that was assigned above:\n\nmy.vecs <- rep(my.vec, 5)\nprint(my.vecs)\n\n [1]   3.141593  45.000000 912.800000   0.000000   3.141593  45.000000\n [7] 912.800000   0.000000   3.141593  45.000000 912.800000   0.000000\n[13]   3.141593  45.000000 912.800000   0.000000   3.141593  45.000000\n[19] 912.800000   0.000000\n\n\n\n\n\n2.3.3 calculations with vector variables\n\nNewVec <- 2*my.vec\nprint(NewVec)\n\n[1]    6.283185   90.000000 1825.600000    0.000000\n\n\nYou can also perform calculations with multiple vector variables, but this requires extra care. R can perform any arithmetic operation with two vector variables, for instance adding two vectors results in a vector containing the sum of corresponding elements of the two vectors:\n\nmy.vec1<-1:5\nmy.vec2<-0:4\nprint(my.vec1)\n\n[1] 1 2 3 4 5\n\nprint(my.vec2)\n\n[1] 0 1 2 3 4\n\nsum.vec<-my.vec1+my.vec2\nprint(sum.vec)\n\n[1] 1 3 5 7 9\n\n\nOne needs to take care that the two vectors have the same number of elements (length). If you try to operate on (e.g. add) two vectors of different lengths, R will return a warning and the result will not be what you expect:\n\nmy.vec1<-1:2\nmy.vec2<-0:4\nprint(my.vec1)\n\n[1] 1 2\n\nprint(my.vec2)\n\n[1] 0 1 2 3 4\n\nsum.vec<-my.vec1+my.vec2\n\nWarning in my.vec1 + my.vec2: longer object length is not a multiple of shorter\nobject length\n\nprint(sum.vec)\n\n[1] 1 3 3 5 5\n\n\n\n\n2.3.4 Exercises\nThe following R commands or short scripts contain errors; your job is to fix them so they runs as described.\n\nAssign a vector of three numbers to a variable:\n\n\ndate_num <- (3,8,16)\n\n\nAssign a range of values to a vector variable and print out the third one:\n\n\nthe.vals <- 0:10\nprint[the.vals(3)]\n\n\nAssign a range of values to a vector variable and print out the fourtieth and sixty-first values:\n\n\nall.the.vals <- 0:100\nprint(all.the.vals[40,61])\n\n\nTake the two vectors assigned above and assign their product to another vector:\n\n\nproduct <- the.vals*all.the.vals\n\n\nCreate a vector vec1 of ten integers and print the second and the eighth elements:\n\n\nvec1 <- 11:20 \nprint(vec1[2:8])\n\n\nCreate a vector vec1 and then multiply all of its elements by 20 and assign it to another vector:\n\n\nvec1<-seq(-3,2,0.1)\nvec2 <- 20vec1\n\n\nCreate a vector vec1, a vector vec2 and print out all the elements of the first divided by the second:\n\n\nvec1 <- 0:5\nvec2 <- 3:8\nprint[vec1/vec2]\n\n\n\n2.3.5 Plotting with vectors\n\ncurve(x^2,0,10,lwd=3,xlab='x', ylab='quadratic',cex.axis=1.5,cex.lab=1.5)\ncurve(20*exp(-0.5*x),0,5,lwd=3,xlab='x', ylab='exponential',cex.axis=1.5,cex.lab=1.5)\n\n\n\n\nTwo examples of plots using curve: quadratic (\\(y=x^2\\)) and exponential (\\(y=20*e^{-0.5x}\\))\n\n\n\n\n\n\n\nTwo examples of plots using curve: quadratic (\\(y=x^2\\)) and exponential (\\(y=20*e^{-0.5x}\\))\n\n\n\n\nThere are several ways of creating plots of mathematical functions or data R. If you want to plot a mathematical function, the simplest function is curve(). You can tell that this is a function, because it uses parentheses; the first input is an expression for the function, and the next two define the range of the independent variable over which to plot the graph. Two examples of plotting a quadratic function over the range from 0 and 5, and an exponential variation over the range of 0 to 10 are shown in figure \\(\\ref{fig:ch2-plot1}\\).\nOne can change the default look of the plot produced by curve by setting different options, which are optional inputs into the curve function, One is the line width lwd which can be increased from the default value of 1 to produce thicker curves, as demonstrated in the example above. One can add labels on the x and y axes with xlab and ylab options, respectively; note that these are strings of characters, and thus must be put in quotes to differentiate them from a variable name. There is one very important option not shown above: that of overlaying a curve on top of an existing plot, which is done by typing add=TRUE. This option takes logical (Boolean) values TRUE and FALSE, which must be typed in all caps and without quotes.\n\n2.3.5.1 plot() function\nIn addition to curve, one can use the function plot() in R to create two dimensional graphs from two vector-valued variables of the same length, e.g. plot(x,y). The first input variable corresponds to the independent variable (e.g. x), which is plotted on the x-axis, and the second variable corresponds to the dependent variable (e.g. y) which is plotted on the y-axis. In figure \\(\\ref{fig:ch2-plot2}\\) you see graphs of exponential and logistic function plotted using plot().\nThe following chunk creates a vector variable time, then calculates a new variable quad using time in a single operation:\n\ntime <- 0:10\nquad <- (time - 5)^2\nprint(time)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(quad)\n\n [1] 25 16  9  4  1  0  1  4  9 16 25\n\n\nThis chunk plots the two vector variables quad as a function of time, and adds a title to the plot\n\nplot(time,quad, main = 'Quadratic function of time')\n\n\n\n\nThe default plot style in R uses circles to indicate each plotted point. To change it, you need to set the option t (type), for example, setting t='l' (the lowercase letter L) produces a continuous line connecting the individual data points.\n\nplot(time,quad, main = 'Quadratic function of time', type = 'l', xlab='time', ylab = 'y = f(t)' )\n\n\n\n\nplot() is a versatile function that has many options function has many options which can be changed to determine the color, the style, and other attributes of the plot. For a full list type help(plot) in the console or type plot in the search bar of the Help pane in the bottom right window.\n\n\n2.3.5.2 using lines() or points()\nYou may also want to plot multiple graphs on the same figure. The plot() function creates a new plot window, so if you want to add another plot on top of the first one, you have to use another function. There are two ones available: lines() which produces continuous curves connecting the points, and points() which plots individual symbols at every point.\nLet us illustrate this by plotting two different exponential functions on one plot, and two different logistic functions on the second one, which were discussed in section \\(\\ref{sec:math2}\\). When you’ve got multiple plots on the same figure, they need to be distinct and labeled. To distinguish them, below I use the option col to specify the color of the plot, and I add a legend describing the parameters of each plot to the figure \\(\\ref{fig:ch2-plot2}\\). The function has a lot of options, so if you want to understand the details, type help(legend) in the prompt or go to Help tab in the lower right frame of R Studio and type legend.\n\nx<-seq(0,10,0.5)\ny<-10+20*exp(-0.5*x)\nplot(x,y, xlab='x', ylab='exponential',col=1,lwd=3)\ny<-10+20*exp(-2*x)\nlines(x,y,col=2,lwd=3)\nleg.txt=c(\"b=10,a=20,r=-0.5\", \"b=10,a=20,r=-2\")\nlegend(\"topright\", leg.txt, col=1:2, pch=c(1,NA), lty=c(0,1), lwd=3)\nx<-seq(-10,10,1)\ny<-20*exp(0.5*x)/(1+exp(0.5*x))\nplot(x,y,xlab='x',ylab='logistic',col=4,lwd=3)\ny<-20*exp(1.5*x)/(1+exp(1.5*x))\nlines(x,y,col=2,lwd=3)\nleg.txt=c(\"a=20,b=1,r=0.5\", \"a=20,b=1,r=1.5\")\nlegend(\"topleft\", leg.txt, col=c(4,2), pch=c(1,NA), lty=c(0,1), lwd=3)\n\n\n\n\nOverlaying multiple plots in R: two exponential functions of the form \\(y=b+ae^{rx}\\) on the left, two logistic functions of the form \\(y= ae^{rx}/(b+e^{rx})\\) on the right.\n\n\n\n\n\n\n\nOverlaying multiple plots in R: two exponential functions of the form \\(y=b+ae^{rx}\\) on the left, two logistic functions of the form \\(y= ae^{rx}/(b+e^{rx})\\) on the right.\n\n\n\n\n\n\n\n2.3.6 Exercises\nThe following R commands or short scripts contain errors; your job is to fix them so they runs as described.\n\nMultiply a vector by a constant and add another constant and assign the result to a vector:\n\n\nnew.vals <- 5 + 8the.vals\n\n\nAssign range to be a sequence of values from 0 to 100 with step of 0.1, and calculate the vector variable result as the square of the vector variable range:\n\n\nrange <- seq(0,0.1,100)\nresult <- square(range)\n\n\nPlot result as a function of range:\n\n\nplot(result, range)\n\n\nPlot the graph of the function \\(f(x) = (45-x)/(4x+3)\\) over the range of 0 to 100:\n\n\ncurve((45-x)/(4x+3), 0, 100)\n\n\nPlot a quadratic function with specified coefficients \\(a\\), \\(b\\), \\(c\\) over a given range of independent variable \\(x\\):\n\n\na<-10\nb<- -15\nc<- 5\ny<-a*x^2+b*x+c\nx<-seq(-0.5,2,0.01) \nplot(x,y,type='l')\n\n\nOverlay two different plots of the logistic function with different values of the parameter \\(r\\):\n\n\ntime<-0:100\na<-1000\nb<-50 \nr<-0.1\nPopulation<-a*exp(r*time)/(b+exp(r*time)) \nplot(time,Population,type='l') \nr<-10 \nlines(time,Population,col=2)"
  },
  {
    "objectID": "functions.html#rates-of-biochemical-reactions",
    "href": "functions.html#rates-of-biochemical-reactions",
    "title": "2  Functions and their graphs",
    "section": "2.4 Rates of biochemical reactions",
    "text": "2.4 Rates of biochemical reactions\n\nLiving things are dynamic, they change with time, and much of mathematical modeling in biology is interested in describing these changes. Some quantities change fast and others slowly, and every dynamic quantity has a rate of change, or rate for short. Usually, the quantity that we want to track over time is the variable, and in order to describe how it changes we introduce a rate parameter. If we are describing changes over time, all rate parameters have dimensions with time in the denominator. As a simple example, the velocity of a physical object describes the change in distance over time, so its dimension is \\([v] = length/time\\).\nOn the most fundamental level, the work of life is performed by molecules. The protein hemoglobin transports oxygen in the red blood cells, while neurotransmitter molecules like serotonin carry signals between neurons. Enzymes catalyze reactions, like those involved in oxidizing sugar and making ATP, the energy currency of life. Various molecules bind to DNA to turn genes on and off, while myosin proteins walk along actin fibers to create muscle contractions.\nIn order to describe the activity of biological molecules, we must measure and quantify them. However, they are so small and so numerous that it is not usually practical to count individual molecules (although with modern experimental techniques it is sometimes possible). Instead, biologists describe their numbers using concentrations. Concentration has dimensions of number of molecules per volume, and the units are typically molarity, or moles (\\(\\approx 6.022*10^{23}\\) molecules) per liter. Using concentrations to describe molecule rests on the assumption that there are many molecules and they are well-mixed, or homogeneously distributed throughout the volume of interest.\nMolecular reactions are essential for biology, whether they happen inside a bacterial cell or in the bloodstream of a human. Reaction kinetics refers to the description of the rates, or the speed, of chemical reactions. Different reactions occur with different rates, which may be dependent on the concentration of the reactant molecule. Consider a simple reaction of molecule \\(A\\) (called the substrate) turning into molecule \\(B\\) (called the product), which is usually written by chemists with an arrow: \\[\n  A \\xrightarrow{k} B\n\\] But how fast does the reaction take place? To write down a mathematical model, we need to define the quantities involved. First, we have the concentration of the molecule \\(A\\), with dimensions of concentration. Second, we have the rate of reaction, let us call it \\(v\\), which has dimension of concentration per time (just like velocity is length per time). How are the two quantities related?\n\n2.4.1 Constant (zeroth-order) kinetics\n In some circumstances, the reaction rate \\(v\\) does not depend on the concentration of the reactant molecule \\(A\\). In that case, the relationship between the rate constant \\(k\\) and the actual rate \\(v\\) is: \\[\\begin{equation}\nv = k\n\\label{eq:kinetics_0th_order}\n\\end{equation}\\]\nDimensional analysis insists that the dimension of \\(k\\) must be the dimension of \\(v\\), or concentration/time. This is known as constant, or zero-order kinetics, and it is observed at concentrations of \\(A\\) when the reaction is at its maximum velocity: for example, ethanol metabolism by ethanol dehydrogenase in human liver cannot proceed any faster than about 1 drink per hour.\n\n\n2.4.2 First-order kinetics\n. In other conditions, it is easy to imagine that increasing the concentration of the reactant \\(A\\) will speed up the rate of the reaction. A simple relationship of this type is linear: \\[\\begin{equation}\nv = kA\n\\label{eq:kinetics_1st_order}\n\\end{equation}\\]\nIn this case, the dimension of the rate constant \\(k\\) is 1/time. This is called first-order kinetics, and it usually describes reactions when the concentration of \\(A\\) is small, and there are plenty of free enzymes to catalyze more reactions.\n\n\n2.4.3 Michaelis-Menten model of enzyme kinetics \nHowever, if the concentration of the substrate molecule \\(A\\) is neither small nor large, we need to consider a more sophisticated model. An enzyme is a protein which catalyzes a biochemical reaction, and it works in two steps: first it binds the substrate, at which point it can still dissociate and float away, and then it actually catalyzes the reaction, which is usually practically irreversible (at least by this enzyme) and releases the product. The enzyme itself is not affected or spent, so it is free to catalyze more reactions. Let denote the substrate (reactant) molecule by \\(A\\), the product molecule by \\(B\\), the enzyme by \\(E\\), and the complex of substrate and enzyme \\(AE\\). The classic chemical scheme that describes these reactions is this: \\[\nA + E \\underset{k_{-1}}{\\overset{k_1}{\\rightleftharpoons}} AE  \\xrightarrow{k_2} E + B\n\\]\nYou could write three different kinetic equations for the three different arrows in that scheme. Michaelis and Menten used the simplifying assumptions that the binding and dissociation happens much faster than the catalytic reaction, and based on this they were able to write down an approximate, but extremely useful Michaelis-Menten model of an enzymatic reaction: \\[\\begin{equation}\nv = \\frac{v_{max} A}{K_M+A}\n\\label{eq:kinetics_MM_kinetics}\n\\end{equation}\\] Here \\(v\\) refers to the rate of the entire catalytic process, that is, the rate of production of \\(B\\), rather than any intermediate step. Here the reaction rate depends both on the concentration of the substrate \\(A\\) and on the two constants \\(v_{max}\\), called the maximum reaction rate, and the constant \\(K_M\\), called the Michaelis constant. They both depend on the rate constants of the reaction, and \\(v_{max}\\) also depends on the concentration of the enzyme. The details of the derivation are beyond us for now, but you will see in the following exercises how this model behaves for different values of \\(A\\)."
  },
  {
    "objectID": "descriptive.html#mutations-and-their-rates",
    "href": "descriptive.html#mutations-and-their-rates",
    "title": "3  Describing data sets",
    "section": "3.1 Mutations and their rates",
    "text": "3.1 Mutations and their rates\n\nAll Earth-based lifeforms receive an inheritance from their parent(s): a string of deoxyribonucleic acids ( DNA) called the genetic sequence, or genome of an individual. The information to produce all the necessary components to build and run the organism is encoded in the sequence of the four different nucleotides: adenine, thymine, guanine, and cytosine (abbreviated as A, T, G, C). Different parts of the genome play different roles; some discrete chunks called genes contain the instructions to build proteins, the workhorses of biology. To make a protein from a gene, the information is transcribed from DNA into messenger ribonucleic acid ( mRNA), which is then translated into a string of amino acids which constitute the protein. The genetic code determines the translation, using three nucleic acids in DNA and RNA to represent a single amino acid in a protein. Thus, a sequence of DNA results in a specific sequence of amino acids, which determine the structure and function of the protein.\n\n\n\nDifferent types of substitution point mutations are distinguished by their effects on the gene products; image by Jonsta247 in public domain via Wikimedia Commons.\n\n\nThe above processes involve copying and transferring information. As we know from experience, copying information inevitably means introducing errors. This is particularly important when passing information from parent to offspring, because then an entire organism has to develop and live based on a faulty blueprint. Changes introduced in the genome of an organism are called mutations, and they can be caused either by errors in copying DNA when making a new cell (replication) or through damage to DNA through physical means (e.g. ionizing radiation) or chemical mechanisms (e.g. exogenous molecules that react with DNA). The simplest mutation involve a single nucleotide and are called point mutations. A nucleotide may be deleted, an extra nucleotide inserted, or a new one substituted instead: the three different types of substitution mutations are shown in figure \\(\\ref{fig:ch3_mutation}\\). Large-scale mutations may involve whole chunks of the genome that are cut out and pasted in a different location, or copied and inserted in another position, but they are typically much more rare than point mutations.\nMutations can have different effects on the mutant organism, although acquisition of super-powers has not been observed. Usually, point mutations have either little observable effect or a negative effect on the health of the mutant. A classic example is sickle-cell disease, in which the molecules of the protein hemoglobin, responsible for carrying oxygen in the blood from the lungs to the tissues, tends to stick together and clump, resulting in sickle-shaped red blood cells. The disease is caused by a single substitution mutation in the gene that codes for one of the two components of hemoglobin, called \\(\\beta\\)-globin. The substitution of a single nucleotide in the DNA sequence changes one amino acid in the protein from glutamate to valine, which causes the proteins to aggregate. This missense}* mutation (see figure \\(\\ref{fig:ch3_mutation}\\)) is carried by a fraction of the human population, and those who inherit the allele allele from both parents develop the painful and sometimes deadly disease. Such mutations that are present in some but not all of a population are called polymorphisms, to distinguish them from mutations that occurred in evolutionary lineages and differentiate species from each other.\nOne of the central questions of evolutionary biology is how frequently do mutations occur? Since mutations are generally undesirable, most living things have developed ways to minimize the frequency of errors in copying DNA, and to repair DNA damage. But although mutations are rare, they occur spontaneously in all organisms because molecular processes such as copying a DNA molecule are subject to random noise arising from thermal motion. So mutations are fundamentally a random process and we need to use descriptive statistics to analyze data with inherent randomness."
  },
  {
    "objectID": "descriptive.html#describing-data-sets",
    "href": "descriptive.html#describing-data-sets",
    "title": "3  Describing data sets",
    "section": "3.2 Describing data sets",
    "text": "3.2 Describing data sets\n\n\n3.2.1 central value of a data set\nA data set is a collection of measurements. These measurements can come from many kinds of sources, and can represent all sorts of quantities. One big distinction is between numerical and categorical data sets. Numerical data sets contain numbers, either integers or real numbers. Some examples: number of individuals in a population, length, blood pressure, concentration. Categorical data sets may contain numbers, symbols, or words, limited to a discrete, usually small, number of values. The word categorical is used because this kind of data corresponds to categories or states of the subject of the experiment. Some examples: genomic classification of an individual on the basis of one locus (e.g. wild type or mutant), the state of an ion channel (open or closed), the stage of a cell in the cell cycle.\nA data set contains more than one measurement, the number of them is called the size of the data set and is usually denoted by the letter \\(n\\). To describe a data set numerically, one can use numbers called statistics (not to be confused with the branch of science of the same name). The most common statistics aim to describe the central value of the data set to represent a typical measurement. If you order all of the measurements from highest to lowest and then take the the middle value, you have found the median (if there is an even number of values, take the average between the middle two). Precisely half of the data values are less than the median and the other half are greater, so it represents the true “middle” value of the measurement. Note that the median can be calculated either for numerical or categorical data, as long as the categories can be ordered in some fashion.\nThe value that occurs most frequently in the data set is called its . For some data sets, particularly those which are symmetric, the mode coincides with the mean (see next paragraph) and the median, but for many others it is distinct. The mode is the most visual of the three statistics, as it can be picked out from the histogram plot of a data set (which is described in subsection 3.2.3) as the value corresponding to the maximum frequency. The mode can also be used for both categorical and numerical data.\nThe average or mean of a data set is the sum of all the values divided by the number of values. It is also called the expected value (particularly in the context of probability, which we will discuss later) because it allows to simply predict the sum of a large number of measurements with a given mean, by multiplying the mean by the number. The mean can be calculated only for a numerical data set, since we cannot add non-numerical values.\n\n\n\n\n\n\nDefinition\n\n\n\nThe mean of a data set \\(X\\), also known as the average or the arithmetic mean is usually indicated with a bar over the variable symbol, and defined as the sum of the values divided by the number of values:\n\n\n\\[\\begin{equation}\n  \\bar X  = \\frac{1}{n} \\sum_{i=1}^n x_i\n\\label{eq:ch3_mean_def}\n\\end{equation}\\]\nThe mean, unlike the median, is not the middle value of the data set, instead it represents the center of mass of the measured values . Another way of thinking of the mean is as a weighted sum of the values in the data set. The weights represent the frequency of occurrence of each numeric value in the data set, which we will further discuss in subsection 3.2.3.\nThe mean is the most frequently used statistic, but it is not always interpreted correctly. Very commonly the mean is reported as the most representative value of a data set, but that is often misleading. Here are at least two situations in which the mean can be tricky: 1) data sets with a small number of discrete values; 2) data sets with outliers, or isolated numbers very far from the mean.\nExamples of misleading means. Mean quantities for data sets with a few quantities are not the typical value, such as in the number of children born in a year per individual, also known as the birth rate. The birth rate per year in 2013 for both the United States and Russia is 1.3% per person, but you will have to look for a long time to find any individual who gave birth to 1.3% of a child. While this point may be obvious, it is often overlooked when interpreting mean values.\nOutliers are another source of trouble for means. For example, a single individual (let’s call him or her B.G.) with a wealth of $50 billion moves into a town of 1000 households with average wealth of $100,000. Although none of the original residents’ assets have changed, the mean wealth of the town improves dramatically, as you can calculate in one of the exercises at the end of the chapter. One can site the improved per capita (per individual) in the town as evidence of economic growth, but that is obviously misleading. In cases with such dramatic outliers, the median is more informative as representation of a typical value of the data set.\n\n\n3.2.2 Exercises\nFor the (small) data sets given below, calculate the mean and the median (by hand or using a calculator) and compare the two measures of the center.\n\nData set of the population of the city of Chicago (in millions) in the last 4 census years (2010, 2000, 1990, 1980): {2.7, 2.9, 2.8, 3.0}.\nData set of the numbers of the fish blacknose dace (Rhinichthys atratulus) collected in 6 different streams in the Rock Creek watershed in Maryland: {76, 102, 12, 55, 93, 98}.\nData set of tuberculosis incidence rates (per 100,000 people) in the 5 largest metropolitan areas in the US in 2012: {5.2, 6.6, 3.2, 5.5, 4.5}.\nData set of ages of mothers at birth for five individuals: {19, 20, 22, 32, 39}.\nData set of ages of fathers at birth for five individuals: {22, 23, 25, 36, 40}.\nData set of the number of new mutations found on maternal chromosomes for five individuals: {9, 10, 11, 26, 15}.\nData set of the number of new mutations found on paternal chromosomes for five individuals: {39, 43, 51, 53, 91}.\nConsider the hypothetical town with 1000 households with mean and median wealth of $100,000 and one person with assets for $50 billion. Calculate the mean value of the combined data set, and compare it to the new median value.\nSuppose you’d like to add a new observation to a data set; e.g. the 6-th largest metropolitan area (Philadelphia) to the tuberculosis incidence data set, which is 3.0. Calculate the mean of the 6-values data set, without using the 5 values in the original data set, but only using the mean of the 5-value data set and the new value. Generalize this to calculating the sample mean for any \\(n\\)-value data set, given the mean of the \\(n-1\\) values, plus one new value.\n\n\n\n3.2.3 spread of a data set\nThe center of a data set is obviously important, but so is the spread around the center. Sometimes the spread is caused by noise or error, for example in a data set of repeated measurements of the same variable under the same conditions. Other times the variance is due to real changes in the system, or due to inherent randomness of the system, and the size of the spread, as well as the shape of the histogram are important for understanding the mechanism. The simplest way to describe the spread of a numerical data set is to look at the difference between the maximum and minimum values, called the range. However, it is obviously influenced by outliers, since the extreme values are used. To describe the typical spread, we need to use all the values in the data set, and see how far each one is from the center, measured by the mean.\nThere is a problem with the naive approach: if we just add up all the differences of data values from the mean, the positives will cancel the negatives, and we’ll get an artificially low spread. One way to correct this is to take the absolute value of the differences before adding them up. However, for somewhat deep mathematical reasons, the standard measure of spread uses not absolute values, but squares of the differences, and then divides that sum not by the number of data points \\(n\\) but by \\(n-1\\).\n\n\n\n\n\n\nDefinition\n\n\n\nThe variance of a data set \\(X\\) with \\(n\\) values is the sum of the squared differences of each value of the variable from the mean, divided by \\(n-1\\):\n\n\n\\[\\begin{equation}\nVar(X) = \\frac{1}{n-1} \\sum_{i=1}^n (\\bar X - x_i)^2\n\\end{equation}\\]\nThe variance is a sum of square differences, so its dimension is the square of the dimensions of the measurements in \\(X\\). In order to obtain a measure of the spread comparable to the values of \\(X\\), we take the square root of variance and call it the standard deviation of the data set \\(X\\):\n\\[\\begin{equation}\n\\sigma(X) = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (\\bar X - x_i)^2}\n\\end{equation}\\]\nJust as the mean is a weighted average of all of the values in the data set, the variance is a weighted average of all the squared deviations of the data from the mean.\n\n\n3.2.4 Exercises:\nFor the (small) data sets below, calculate the range, variance, and standard deviation (by hand or using a calculator). Compare the range and the standard deviation for each case: which one is larger? by how much?\n\nData set of the population of the city of Chicago (in millions) in the last 4 census years (2010, 2000, 1990, 1980): {2.7, 2.9, 2.8, 3.0}.\nData set of the numbers of the fish blacknose dace (Rhinichthys atratulus) collected in 6 different streams in the Rock Creek watershed in Maryland: {76, 102, 12, 55, 93, 98}.\nData set of tuberculosis incidence rates (per 100,000 people) in the 5 largest metropolitan areas in the US in 2012: {5.2, 6.6, 3.2, 5.5, 4.5}.\nData set of ages of mothers at birth for five individuals: {19, 20, 22, 32, 39}.\nData set of ages of fathers at birth for five individuals: {22, 23, 25, 36, 40}.\nData set of the number of new mutations found on maternal chromosomes for five individuals: {9, 10, 11, 26, 15}.\nData set of the number of new mutations found on paternal chromosomes for five individuals: {39, 43, 51, 53, 91}.\nConsider the hypothetical town with 1000 households with mean and median wealth of $100,000 and one person with assets for $50 billion. Calculate the mean value of the combined data set, and compare it to the new median value.\n(harder) Suppose that a data set has a fixed range (e.g. all values have to lie between 0 and 1). What is the greatest possible standard deviation for any data set within the range? Hint: think about how to place the points as far from the mean as possible. How do the data sets above relate to your prediction?}\n\n\n\n3.2.5 describing data sets in graphs\nData sets can be presented visually to indicate the frequency of different values. This can be done in a number of ways, depending on the kind of data set. For a data set with only a few values, e.g. a categorical data set, a good way to represent it is with a pie chart. Each category is represented by a slice of the pie with the area of the same share of the pie as the fraction of the data set in the category. There is some evidence, however, that pie charts can be misleading to the eye, so R does not recommend using them.\nFor a numerical data set it is useful to plot the frequencies of a range of values, which is called a histogram. Its independent axis has the values of the data variable, and the dependent axis has the frequency of those values. If the data set consists of real numbers that range across an interval, that interval is divided into subintervals (usually of equal size), called bins, and the number of measurements in each bin is indicated on the y-axis. In order to be visually informative, there should be a reasonable number (usually no more than a few dozen, although it varies) of bins. The most frequent measurements are represented as the highest bars or points on the histogram. Histograms can denote either the counts of measurements in each bin, or to show the fraction of the total number of measurements in each bin. The only difference between those two kinds of histogram is the scale of the y-axis, and, confusingly, both can be called frequencies.\n\n\n\n\n\nFigure 3.1: Length of bacteria Bacillus subtilis measured under the microscope as discrete values with step of 0.5; data from citep{watkins-intro-stats}\n\n\n\n\nA histogram of the measured lengths of the bacterium Bacillus subtilis is shown in figure \\(\\ref{fig:ch3_bacillus}\\). The data set was measured in increments in half a micron, with numbers varying between 1.5 and 4.5 microns. The histogram shows that the most common measurement (the mode) is 2 \\(\\mu m\\). Adding up all of the frequencies in the histogram tells us that there are approximately 200 total values in the data set. This allows us to find the median value by counting the frequencies of the first few bins until we get to 100 (the median point), which resides in the bin for 2.5 \\(\\mu m\\). It is a little bit more difficult to estimate the mean, but it should be clear that the center of mass of the histogram is also near 2.5 (it is actually 2.49). Finally, the hardest task is estimating the spread of the data set, such as the the standard deviation, based on the histogram. The range of the data set is \\(4.5-1.5 = 3\\), so we know for sure that it is less than 1.5. The histogram shows that the deviations from the mean value of 2.5 range from 2 (rarely) to 0.5 (most prevalent). This should give you an idea that the weighted average of the deviations is less than 1. Indeed, the correct standard deviation is about 0.67.\nThere are different ways of plotting data sets that have more than one variable. For instance, a data set measured over time is called a time series. If the values are plotted with the corresponding times on the x-axis, then it is called a time plot. This is useful to show the changes of the values of your variable over time. If the data set doesn’t undergo any significant changes over time, it makes more sense to represent it as a pie chart or histogram. More generally, one may plot two variables measured together on a single plot, which is called a scatterplot. We will explore such plots and the relationships between two measured variables in chapter 4.\n\n\n3.2.6 Exercises\nAnswer the following questions, based on the histograms in figure \\(\\ref{fig:ch3_mut}\\) (mutation data) and in figure \\(\\ref{fig:ch3_HR}\\) (heart rate data).\n\nHow many people in the mutation data have fathers either younger than 20 or older than 40? How many have more than 80 new mutations? \nEstimate the median and mean of the two variables in the mutation data set.\nState the range of each data set, and estimate the standard deviation of the two variables in the mutation data set.\nHow many people in the heart rate data have heart rates greater than 80 bpm? How many have body temperature less that 97 F?\nEstimate the median and mean of the two variables in the heart rate data set.\nState the range of each data set, and estimate the standard deviation of the two variables in the heart rate data set.\n\n\nmy_data<-read.table('data/HR_temp.txt', header=TRUE)\nhist(my_data$HR,col='gray',main='Heart rate data', xlab='heart rate (bpm)')\nhist(my_data$Temp,col='gray',main='Body temperature data', xlab= 'temperature (F)')\n\n\n\n\nFigure 3.2: Histograms of heart rates and body temperatures\n\n\n\n\n\n\n\nFigure 3.3: Histograms of heart rates and body temperatures\n\n\n\n\n\n\n\n\n\nFigure 3.4: Histograms of paternal ages and the number of new mutations from 73 families; data from citep{kong_rate_2012}\n\n\n\n\n\n\n\nFigure 3.5: Histograms of paternal ages and the number of new mutations from 73 families; data from citep{kong_rate_2012}"
  },
  {
    "objectID": "descriptive.html#working-with-data-in-r",
    "href": "descriptive.html#working-with-data-in-r",
    "title": "3  Describing data sets",
    "section": "3.3 Working with data in R",
    "text": "3.3 Working with data in R\n\n\n3.3.1 reading in data into data frames\nOne way to input data into R is to read in a text file, where several variables are stored in columns. For instance, the file HR_temp.txt contains three variables: body temperature (in Fahrenheit), sex (1 for male, 2 for female), and heart rate (in beats per minute). The values for the variables are arranged in columns, while first row of the file contains the names of the variables (Temp, Sex, and HR, respectively). Note that the data file has to be saved into the same folder as the .Rmd file week1.Rmd for this to work.\n\nvitals <- read.table(file = \"data/HR_temp.txt\", header = TRUE)\nplot(vitals$HR, vitals$Temp, main = 'Body temp as function of heart rate', xlab= 'heart rate (bpm)', ylab= 'body temperature (F)')\nmTemp <- mean(vitals$Temp)\nsdTemp <- sd(vitals$Temp)\nabline(mTemp,0)\n\n\n\nmean(vitals$HR)\n\n[1] 73.76154\n\nsd(vitals$HR)\n\n[1] 7.062077\n\n\nThe R command read.table() reads this file and and puts it into a data frame called data. The three variables are stored inside the data frame, and can be accessed by appending the dollar sign and variable name to the data frame, so data$HR refers to only the heart rates, and data$Temp refers to the body temperatures. The plot shows the relationship of the two data variables, and the function abline(98.6,0) plots a line with the intercept 98.6a and slope 0 on top of the scatterplot.\nYou can also load data from a package, e.g. HistData, which contains many classic data sets. Got to the Packages tab in the lower right window in R Studio, click Install and type HistData. We will use the data set called Galton that contains the heights of parents (the mean of mother’s and father’s) and their children, in variables parent and child. The script below plots the two variables, with parent as the independent (explanatory) variable and child as the dependent (response) variable.\n\nlibrary(HistData)\nplot(Galton$parent, Galton$child, main = 'Height of child vs average height of parents', xlab= 'parent height (inches)', ylab= 'child height (inches)')\n\n\n\n\n\n\n\nsummary(Galton$parent)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  64.00   67.50   68.50   68.31   69.50   73.00 \n\nsummary(Galton$child)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  61.70   66.20   68.20   68.09   70.20   73.70 \n\n\n\n\n3.3.2 descriptive statistics\nOne can also calculate basic descriptive statistics as follows:\n\npaste(\"The mean parental height is:\", mean(Galton$parent))\n\n[1] \"The mean parental height is: 68.3081896551724\"\n\npaste(\"The mean child height is:\", mean(Galton$child))\n\n[1] \"The mean child height is: 68.0884698275862\"\n\npaste(\"The standard deviation of parental height is:\", sd(Galton$parent))\n\n[1] \"The standard deviation of parental height is: 1.78733340172202\"\n\npaste(\"The standard deviation of  child height is:\", sd(Galton$child))\n\n[1] \"The standard deviation of  child height is: 2.51794136627677\"\n\n\nWhy do you think the standard deviation of parental height is much smaller?\nR has histogram function hist(), which does a passable job of representing the distribution of a variable such as child height or parent height. Compare the width of the two distributions and consider why they are different.\n\nhist(Galton$child)\nhist(Galton$parent)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.3 Exercises:\nThe following code chunks contain errors. Find and fix them so they work as intended.\n\nCalculate the mean and standard deviation of the heart rates of the first 30 individuals in the data frame vitals:\n\n\nmean(vitals$HR[30])\n\n[1] 64\n\nsd(vitals$HR[30])\n\n[1] NA\n\n\n\nCalculate the mean and standard deviation of the ratio of heart rates to body temperatures for the data set vitals:\n\n\nmean(vitals$HR/Temp)\nsd(vitals$HR/Temp)\n\n\nPlot a scatterplot of the child heights as the response variable and the parent heights and the explanatory variable, and overlay the line y=x on top.\n\n\nplot(parent, child, main = 'Height of child vs average height of parents', xlab= 'child height (inches)', ylab= 'parent height (inches)')\nabline(1,0)\n\n\nCalculate the median of both parent and child heights:\n\n\nmedian(Galton)\n\n\nPlot the histogram of parent heights of the first half of the group:\n\n\nhist(Galton$parent/2)\n\n\nPlot the histogram for the ratio of parent and child heights for the entire data set and calculate its mean and variance:\n\n\nhist(Galton$parent/child)\nmean(Galton$parent/child)\nsd(Galton$parent/child)"
  },
  {
    "objectID": "probdist.html#random-variables-and-distributions",
    "href": "probdist.html#random-variables-and-distributions",
    "title": "4  Random variables and distributions",
    "section": "4.1 Random variables and distributions",
    "text": "4.1 Random variables and distributions\n\n\n4.1.1 definition of probability\nIn this section we will develop the terminology used in the mathematical study of randomness called probability. This begins with a random experiment which is a very broad term that can describe any natural or theoretical process whose outcome cannot be predicted with certainty. If the outcomes are numeric, they may be discrete (can be counted by integers) or continuous (corresponding to real numbers); they may also be categorical, meaning that they do not have a numeric meaning, like eye color. We will stick to experiments that have discrete outcomes in this chapter, but many important experiments produce continuous outcomes. The first step for studying a random process is to describe all of the outcomes it can produce:\n\n\n\n\n\n\nDefinition\n\n\n\nThe collection of all possible outcomes of an experiment is called its sample space \\(\\Omega\\). An event is a subset of the sample space, which means an event may contain one or more experimental outcomes.\n\n\n\n\n\nAn illustration of the sample space of all people with two events: tall people and those who like tea.\n\n\nExample. You can ask a person two questions: how tall are you (and classify them either as short or tall) and do you like tea (yes or no), and you’ve performed a random experiment. The randomness comes not from the answers (assuming the person doesn’t randomly lie) but from the selection of the respondent. We will discuss randomly selecting a sample from a population in the next chapter. This random experiment has four outcomes: tall person who likes tea, tall person who does not like tea, short person who likes tea, and short person who does not like tea. This sample space and events is illustrated in figure \\(\\ref{fig:ch4_sample_space}\\) with a Venn diagram, which uses geometric shapes as representations of events as subsets of the entire sample space. These outcomes can be grouped into events by one of the responses: e.g. tall person (\\(A\\)) or person who doesn’t like tea (\\(-B\\)).\nExample. A random experiment with two outcomes, called a Bernoulli trial (after the famous Swiss mathematician), can describe a variety of situations: a coin toss (heads or tails), a competition with two outcomes (win or loss), the allele of a gene (normal or mutant). The sample space for a single Bernoulli trial consists of just two outcomes: \\(\\{H,T\\}\\) (for a coin toss). If the experiment is performed repeatedly, the sample space gets more complicated. For two Bernoulli trials there are four different outcomes \\(\\{HH, HT, TH, TT \\}\\). One can define different events for this sample space: the event of getting two heads in two tosses contains one outcome: \\(\\{HH\\}\\), the event of getting a single head contains two: \\(\\{TH, HT\\}\\).\nIn order to to describe the composition of a sample space, we need to define the word probability . While it is familiar to everyone from everyday usage, it is difficult to define without using other similar words, such as likelihood or plausibility, which are also in need of definition. It is accepted that something with a high probability happens often, while something with a low frequency is seldom observed. The other notion is that probability can range between 0 (meaning something that never occurs) and 1 (something that occurs every time). These notions lead to the commonly accepted definition:\n\n\n\n\n\n\nDefinition\n\n\n\nThe probability of an outcome or event in the sample space of a random experiment is the fraction of experiments with this outcome out of many repeated experiments.\n\n\nThis definition is at the heart of the frequentist view of probability, due to the underlying assumption that the experiment can be repeated as many times as necessary to observe the frequency of outcomes. There is an alternative view that focuses on what is previously known about the experiment (or about systems that produce that kind of experiment) that is called the Bayesian view:\n\n\n\n\n\n\nDefinition\n\n\n\nThe probability of an outcome or event in the sample space of a random experiment is the degree of certainty or belief that this outcome will occur based on prior experience.\n\n\nWe will investigate the Bayesian approach in chapter 12. Most of traditional probability and classical statistics is based on the frequentist view, as it grew out of attempts to understand games of chance, like cards and dice, which can be easily repeated, or simple experiments like those in agriculture, where many plots can be planted and observed. These easily repeatable simple experiments can be described with mathematical distributions that we will describe in this chapter. However, many contemporary research problems are not so easily repeated, and often require a Bayesian approach that does not yield to neat mathematical description and can be addressed using computation.\n\n\n4.1.2 axioms of probability\nOne we have defined the probability of an outcome, one can calculate the probability of a collection of outcomes according to rules that ensure the results are self-consistent. These rules are called the axioms of probability:\n\n\n\n\n\n\nDefinition\n\n\n\nThe probability \\(P(A)\\) of an event \\(A\\) in a sample space \\(\\Omega\\) is a number between 0 and 1, which obeys the following rules, called the axioms of probability:\n\n\\(P(\\Omega) = 1\\)\n\\(P(\\emptyset) = 0\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\n\nLet us define some notation for sets: \\(A \\cup B\\) is called the union of two sets, which contains all outcomes that belong to either \\(A\\) or \\(B\\), this is equivalent to the logical OR operator because it is true if either A or B is true. \\(A\\cap B\\) is called the intersection of two sets, which contains all outcomes that are in both \\(A\\) and \\(B\\), this is is equivalent to the logical AND operator because it is true if both A and B are true. The \\(\\emptyset\\) denotes the empty set. Any event \\(A\\) has its complement, denoted \\(-A\\), which contains all outcomes of \\(\\Omega\\) which are not in \\(A\\).\nApplying them to the sample space and events in figure \\(\\ref{fig:ch4_sample_space}\\), the union of the two sets \\(A \\cup B\\) are all people who are either tall or like tea, the intersection of the two sets \\(A\\cap B\\) are all the tall people who like tea, and the intersection of the first set with the complement of the second \\(A \\cup - B\\) are all tall people who do not like tea.\n\n\n\nAn illustration of the operation of intersection of sets A and B.\n\n\n\n\n\nAn illustration of the operation of the union of sets A and B.\n\n\n\n\n\nAn illustration of the intersection of A with -B\n\n\nThe first two axioms connect easily with our intuition about probability: the first axiom says that the probability of some outcome from the sample space occurring is 1, while the second says that the probability of nothing in the sample space occurring is 0. The intuition behind axiom three is less transparent, but it can be see in a Venn diagram of two subsets \\(A\\) and \\(B\\) of the larger set \\(\\Omega\\), as in figure \\(\\ref{fig:ch4_sample_space}\\). Compare the size of the union of \\(A\\) and \\(B\\) and the sum of the sizes of sets \\(A\\) and \\(B\\) separately, and you will see that the intersection \\(A\\cap B\\) occurs in both \\(A\\) and \\(B\\), but is only counted once in the union. This is why it needs to be subtracted from the sum of \\(P(A)\\) and \\(P(B)\\).\nThere are several useful rules that immediately follow from the axioms. First, if two events are mutually exclusive, meaning their intersection is empty (\\(A\\cap B = \\emptyset\\)), then the probability of either of them happening is the sum of their respective probabilities: \\(P(A \\cup B) = P(A) + P(B)\\) (from axiom 3). Further, since an event \\(A\\) and its complement \\(-A\\) are mutually exclusive, their union is the entire sample space \\(\\Omega\\): \\(P(A) + P(-A) = P(A \\cup -A) = P(\\Omega) = 1\\), therefore \\(P(A) = 1-P(-A)\\).\nExample. Assume one is using a fair coin, so the probability of a single head and a single tail is 1/2. The probability of getting two heads in a row is 1/4, because exactly half of those coins that come up heads once will come up heads again. In fact, the probability of getting any particular sequence of two coin toss results is 1/4. Here are some examples of what we can calculate:\n\nthe probability of getting one head of out of two tosses is \\(1-1/4-1/4=1/2\\) (by the complement rule).\nthe probability of getting two heads is \\(1-1/4 = 3/4\\) (by the complement rule).\n\nthe probability of getting either 0, 1, or 2 heads is 1 (by axiom 1).\nthe probability of getting three heads is 0 (since this event is not in the sample space).\n\nExample. Suppose one is testing people for a mutation which has the probability (prevalence) of 0.2 in the population, so for each person there are two possible outcomes: normal or mutant. The probability of drawing two mutants in a row is \\(0.2*0.2=0.04\\) by the same argument as above; the probability of drawing two normal people is \\(0.8*0.8 =0.64\\). Based on this, we can calculate the following\n\nthe probability of one mutant of out two people is \\(1-0.04-0.64=0.32\\) (by the complement rule).\nthe probability of not having two mutants is \\(1-0.04 = 0.96\\) (by the complement rule).\n\nthe probability of either 0, 1, or 2 mutants is 1 (by axiom 1).\nthe probability of getting three mutants is 0 (since this event is not in the sample space).\n\nExample (from Danny and Gaines Sarcastic fringeheads are a tropical ocea fish that engage in aggressive mouth-wrestling matches for their rocky residences. Let us treat each match as a stochastic experiment with two outcomes: win or loss. Then the sample space is equivalent to our coin-tossing experiment, e.g. for two matches the sample space is \\(\\{ WW, WL, LW, LL \\}\\). However, the probability distribution may different, for example if a particular fringehead wins 3/4 of its matches, then the probability distribution would be: \\(P(\\{ WW \\}) = 9/16\\), \\(P(\\{ LW \\}) = P(\\{ WL \\}) = 3/16\\), and $ P({ LL }) = 1/16$. Thus, the same sample space may have different probability distributions defined on it.\n\n\n4.1.3 random variables\nThe outcomes of experiments may be expressed in numbers or words, but we generally need numbers in order to report and analyze results. One can describe this mathematically as a function (recall its definition form section \\(\\ref{sec:math2}\\)) that assigns numbers to random outcomes . In practice, a random variable describes the measurement that one makes to describe the outcomes of a random experiment.\n\n\n\n\n\n\nDefinition\n\n\n\nA random variable is a number or category associated to each outcome in a sample space \\(\\Omega\\). This association has to follow the rules of a function as defined in chapter 2.\n\n\nExample. Define the random variable to be the number of heads out of two coin tosses. This random variable will return numbers 0, 1, or 2, corresponding to different events. The random variable of the number of mutants out of two people (assuming there are only two outcomes, mutant and normal) has the same set of values. This random variable is a function on the sample space because it returns a unique value for each outcome.\nExample. (Danny and Gaines) Suppose that our sarcastic fringehead, upon losing a wrestling match, has to search for another home for three hours. Then we can define the random variable of time wasted over two wrestling matches, which can be either 0, 3, or 6 hours, depending on the events defined above. Once again, this is a function because there is an unambiguous number associated with each outcome.\nA random variable has a set of possible values, and each of those values may come up more or less frequently in an random experiment. The frequency of each measurement corresponds to the probability of the outcomes in the sample space that produce that particular value of the random variable. One can describe the behavior of the random variable in terms of the collection of the probabilities of its outcomes.\n\n\n\n\n\n\nDefinition\n\n\n\nThe probability of a random variable \\(X\\) taking some value \\(a\\), written as \\(P(X=a)\\), but usually simplified to \\(P(a)\\) is the probability of the event corresponding to the value \\(a\\) of the random variable. This function \\(P(a)\\) is called the probability distribution of the random variable \\(X\\).\n\n\nOne important property of probability distribution functions for a discrete random variable is that all of its values have to add up to 1:\n\\[\\sum_{i=1}^N P(a_i) =1\\] The graph of a probability distribution function lies above zero because all probabilities are between 0 and 1. The graph of a probability distribution is very similar to a histogram, in that it represents the frequency of occurrence of each value of the random variable. A histogram of a variable from a data set can be thought is an approximation of the true probability distribution based on the sample. For a large sample size, the histogram approaches the graph of the probability distribution function, something which we will discuss in chapter 9.\nExample. Assuming that each coin toss has probability 1/2 of resulting in heads, the probability distribution function for the number of heads out of two coin tosses is \\(P(0) = 1/4; \\; P(1) = 1/2; \\; P(2) = 1/4\\) (as we computed in the example in the previous section). Note that the probabilities add up to 1, as they should.\nExample. For the random variable of the number of mutants out of two people, for mutation prevalence of 0.2, the probability distribution function is \\(P(0) = 0.64; \\; P(1) = 0.32; \\; P(2) = 0.04\\) (as we computed in the example in the previous section). Note that the probabilities add up to 1, as they should.\nExample. For the time wasted by a fringehead, the distribution is \\(P(0)= 9/16; \\; P(3) = 3/16; \\; P(6) = 1/16\\). Note that other values of the random variable have probability 0, because they correspond to the empty set in sample space.\n\n\n4.1.4 expectation of random variables\n\n\n\n\n\n\nDefinition\n\n\n\nThe expected value (or mean) of a discrete random variable \\(X\\) with probability distribution \\(P(X)\\) is defined as: \\[ E(X) = \\mu_X = \\sum_{i=1}^N  a_i P(a_i)\\]\n\n\nThis sum is over all values \\(\\{a_i\\}\\) that the random variable \\(X\\) can take, multiplied by the probability of the random variable taking that value (meaning the probability of the event in sample space that corresponds to that value). This corresponds to the definition of the mean of a data set given in section \\(\\ref{sec:math3}\\), if you consider \\(P(a_i)\\) to be the number of times \\(a_i\\) occurs divided by the number of total measurements \\(N\\). As in the case of the histogram and the distribution function, the mean of a sample for a large sample size \\(N\\) approaches the mean of the random variable, which we will discuss in more detail in the next chapter. Sometimes we will use the more concise \\(\\mu_X = E(X)\\) to represent the mean (expected) value. Here are some mathematical properties of the expectation:\n\nExpectation of a random variable which is always constant (\\(c\\)) is equal to \\(c\\), since the probability of \\(c\\) is 1: \\(E(c) = cP(c) = c\\)\nExpectation of a constant multiple of a random variable is:\n\n\\[E(cX) = \\sum_i c x_iP(x_i) = c \\sum_i x_iP(x_i) = c \\mu_X\\]\n\nExpectation of a sum of two random variables is the sum of their expectations. This is a more complicated argument, so let us break it down. First, all possible values of the random variable \\(X+Y\\) come from going through the possible values of \\(X\\) (\\(a_i\\)) and \\(Y\\) (\\(b_i\\)), and each combination of values has its own probability (called the joint probability distribution) \\(P(a_i, b_j)\\):\n\n\\[E(X+Y) = \\sum_i \\sum_j (a_i+b_j) P(a_i, b_j)\\] We can split the sum into two terms by the distributive property of multiplication and then take out the values \\(a_i\\) and \\(b_j\\) out of the sum that they do not depend on:\n\\[E(X+Y) = \\sum_i \\sum_j a_i P(a_i, b_j) + \\sum_i \\sum_j b_j P(a_i, b_j)=\\] \\[=\\sum_i a_i  \\sum_j  P(a_i, b_j) +  \\sum_j b_j \\sum_i P(a_i, b_j) \\] The joint distributions added up over all values of one variable, become single-variable distributions, so this leaves us with two sums which are the two separate expected values:\n\\[E(X+Y) =  \\sum_i a_i P(a_i) +  \\sum_j b_j P(b_j) = E(X) + E(Y) \\]\nExample. The expected value of the number of heads out of two coin tosses can be calculated using the probability distribution function we found above: \\[ E(X) = 0\\times P(0) + 1 \\times P(1) + 2 \\times P(2) = 0+1/2+2 \\times 1/4 = 1\\] The expected number of heads out of 2 is 1, if each head comes up with probability 1/2, which I think you will find intuitive.\nExample. The expected value of the number of mutants out of two people can be calculated using the probability distribution function we found above: \\[ E(X) = 0 \\times P(0) + 1 \\times P(1) + 2 \\times P(2) = 0+1 \\times 0.32+2 \\times 0.04 = 0.4\\] The expected number of mutants in a sample of two people is 0.4, which may seem a bit strange. Recall that mean or expected values do not have to coincide with values that are possible, as we discussed in section \\(\\ref{sec:math3}\\), but are instead a weighted average of values, according to their frequencies or probabilities.\nExample. Find the expected value of the number of wins out of two matches for a fringehead which has the probability of winning of 3/4.\n\\[E(X) = 0 \\times 1/16 + 1 \\times 6/16 + 2 \\times 9/16 = 24/16 = 3/2\\]\n\n\n4.1.5 variance of random variables\nKnowledge of the expected value says nothing about how the random variable actually varies: expectation does not distinguish between a random variable which is constant and one which can deviate far from the mean. In order to quantify this variation, one might be tempted to compute the mean differences from the mean value, but it does not work:\n\\[ E(X-\\mu_X) =  \\sum_i (x_i-\\mu_x)P(x_i) = \\sum_i x_i P(x_i) - \\mu_x \\sum_i P(x_i) = \\mu_x - \\mu_x = 0\\] The problem is, if we add up all the differences from the mean, the positive ones end up canceling the negative ones and the expected value of those deviations is exactly zero. This is why it makes sense to square the differences and add them up:\n\n\n\n\n\n\nDefinition\n\n\n\nThe variance of a discrete random variable \\(X\\) with probability distribution \\(P(x)\\) is \\[ Var(X) = E((X-\\mu_X)^2) = \\sum_{i=1}^N (x_i-\\mu_x)^2P(x_i)\\]\n\n\nOne useful property of the variance is: \\[ Var(X) = \\sum_i (x_i^2 - 2x_i\\mu_x + \\mu_x^2)P(x_i) =\\] \\[= \\sum_i x_i^2 P(x_i) - 2\\mu_x\\sum_i x_i P(x_i) + \\mu_x^2 \\sum_i P(x_i) = E(X^2) - E(X)^2 \\] So variance can be calculated as the difference between the expectation of the variable squared and the squared expectation. Note that the variance is given in units of the variable squared, so in order to measure the spread of the variable in the same units, we take the square root of the variance and call it the standard deviation: \\[\\sigma_x = \\sqrt{Var(X)}\\] While the expectation of a sum of random variables is the sum of their expectations, for any random variables, the same is not true for the variance. However, there is a special condition under which this is true. First, let us write the variance of a sum of two random variables \\(X\\) and \\(Y\\):\n\\[Var(X+Y) = E \\left[ (X+Y)-(\\mu_X+\\mu_Y) \\right]^2 =\\]\n\\[ = E[ (X-\\mu_X)^2 +(Y-\\mu_Y)^2 - 2(X-\\mu_X)(Y-\\mu_Y)] = \\] \\[=E (X-\\mu_X)^2 +  E(Y-\\mu_Y)^2   -2 E[(X-\\mu_X)(Y-\\mu_Y)] = \\]\n\\[ = Var(X) + Var(Y)  -2 E[(X-\\mu_X)(Y-\\mu_Y)] \\] If you write out the last term as a sum, it is none other than the covariance of the two random variables \\(X\\) and \\(Y\\), which we saw in the chapter on linear regression. So for any two random variables that have zero covariance, their variance is additive!\nExample. The variance of the number of heads out of two coin tosses can be calculated using its probability distribution function and the expected value (1) from above: \\[ Var(X) = (0-1)^2 \\times P(0) + (1-1)^2 \\times P(1) + (2-1)^2 \\times P(2) = 1/4+0+1/4 = 1/2\\] Since the variance is 1/2, the standard deviation, or the expected distance from the mean value is \\(\\sigma= \\sqrt{1/2}\\).\nExample. The variance of the number of mutants out of two people can be calculated using its probability distribution function and the expected value (0.4) from above: \\[ E(X) = (0-0.4)^2 \\times P(0) + (1-0.4)^2 \\times P(1) + (2-0.4)^2 \\times P(2) =\\] \\[ = 0.4^2 \\times 0.64+0.6^2 \\times 0.32+1.6^2 \\times 0.04 = 0.32\\] Since the variance is 0.32, the standard deviation, or the expected distance from the mean value is \\(\\sigma= \\sqrt{0.32}\\).\nExample. We have computed the expected value for the number of wins in two fringehead fights, so now let us find the variance and standard deviation. We already know the possible values of \\(X\\), and the associated probabilities, so we calculate: \\[ E(X^2) = 0^2 \\times 1/16 + 1^2 \\times 6/16 + 2^2 \\times 9/16 = 42/16\\] Then the variance is: \\[ Var(X) = E(X^2)  - E(X)^2 = 42/12 - 9/4 = (42-27)/16 = 15/16\\] and the standard deviation is \\(\\sigma = \\sqrt{15}/4\\) or just under 1.\n\n\n4.1.6 Exercises\nCalculate the expected values and variances of the following probability distributions, where the possible values of the random variable are in curly brackets, and the probability of each value is indicated as \\(P(x)\\).\n\n\\(X=\\{0, 1\\}\\) and \\(P(0) = 0.1, P(1) = 0.9\\).\n\\(X=\\{1,2,3\\}\\) and \\(P(1) = P(2) = P(3)=1/3\\).\n\\(X=\\{10, 15, 100\\}\\) and \\(P(10) = 0.5, P(15) = 0.3, P(100)=0.2\\).\n\\(X=\\{0, 1, 2, 3, 4\\}\\) and \\(P(0) = 1/8, P(1) = P(2) = P(3) = 1/4, P(4) = 1/8\\).\n\\(X=\\{-1.5, -0.4, 0.3, 0.9\\}\\) and \\(P(-1.5) = 0.4, P(-0.4) = 0.2, P(0.3) = 0.35, P(0.9) = 0.05\\)."
  },
  {
    "objectID": "probdist.html#examples-of-distributions",
    "href": "probdist.html#examples-of-distributions",
    "title": "4  Random variables and distributions",
    "section": "4.2 Examples of distributions",
    "text": "4.2 Examples of distributions\n\n\n4.2.1 uniform distribution\nPerhaps the simplest random variable (besides a constant, which is not really random) is the uniform random variable, for which every outcome has equal probability. The distribution of a fair coin is uniform with two values, \\(H\\) or \\(T\\), or 0 and 1, each with probability 1/2. More generally, a discrete uniform random variable has \\(N\\) outcomes and each one has probability \\(1/N\\). This is what people often mean when they use the word random - an experiment where each outcome is equally likely.\nWe can calculate the expectation and variance of a uniform random variable \\(U\\):\n\\[\nE(U) = \\sum_{i=1}^n  a_i P(a_i) = \\frac{1}{n}  \\sum_{i=1}^n  a_i\n\\] So the expected value is the mean of all the values of the uniform random variable.\nExample. In the special case of the uniform distribution of \\(n+1\\) integers between 0 and \\(n\\) (\\(a_i = i\\), for \\(i=0,..., n\\)), each value has probability \\(P = 1/(n+1)\\). The expected value is the average of the maximum and minimum values (using the fact that \\(\\sum_{i=0}^n i = n(n+1)/2\\)): \\[ E(U) = \\frac{n(n+1)}{2(n+1)} = \\frac{n}{2} \\]\nGeneralizing, for a random variable on integers between \\(a\\) and \\(b\\), the expectation is \\[ E(U) = \\frac{a+b}{2}\\]\nWe can also write down the expression for the variance of the discrete uniform distribution as follows:\n\\[ Var(U) = E(U^2) - E(U)^2 =  \\frac{1}{n} \\sum_{i=1}^n  a_i^2  -  \\frac{1}{n^2} \\left(\\sum_{i=1}^n  a_i \\right)^2\\] Example. In the special case of the uniform distribution of \\(n+1\\) integers between 0 and \\(n\\) (\\(a_i = i\\), for \\(i=0,..., n\\)), each value has probability \\(P = 1/(n+1)\\). The variance can be calculated using the formula for the sum of squares: \\(\\sum_{i=0}^n i^2 =n(n+1)(2n+1)/6\\).\n\\[ Var(U) = \\frac{(n+1)(2n+1)n}{6(n+1)} - \\frac{n^2}{4} =   \\frac{2n^2+n}{6} - \\frac{n^2}{4} = \\frac{n(n+2)}{12}\n\\]\nThis can be generalize to a uniform random variable on integers between \\(a\\) and \\(b\\) (omitting the algebraic details) so the variance for that uniform random variable is:\n\\[ Var(U) = \\frac{(b-a+1)^2 - 1}{12} = \\frac{(b-a)^2 + 2(b-a)}{12}\n\\]\n\n\n\n\n\nTwo uniform random distributions with integer values with different ranges.\n\n\n\n\n\n\n\nTwo uniform random distributions with integer values with different ranges.\n\n\n\n\n\n\n4.2.2 binomial distribution\nWe have introduced binary or Bernoulli trials in section \\(\\ref{sec:math4_1}\\). Assume that the two values of the random variable \\(X\\) are 0 and 1, with probability \\(1-p\\) and \\(p\\), respectively. Then we can calculate the expectation and variance of a single Bernoulli trial:\n\\[E(X) = 0 \\times (1-p) + 1 \\times p = p\\] \\[ Var(X) = E(X^2) - E(X)^2 = 0^2 \\times (1-p) + 1^2 \\times p - p^2= p(1-p)\\] The first result is likely intuitive, but the second deserves a comment. Note that depending on the probability of 1, the variance, or the spread in outcomes of a Bernoulli trial is different. The highest variance occurs when \\(p=1/2\\), or equal probability of 0 or 1, but when \\(p\\) approaches 0 or 1, the variance approaches 0. Thus, as the probability approaches zero or one the random variable approaches a constant (either always 1 or 0); hence, no variance.\nOne can extend this scenario and ask what happens in a string of Bernoulli trials, for instance, in a string of 10 coin tosses, or in testing 20 randomly selected people for a mutation. The mathematical problem is to calculate the probability distribution of the number of success out of many trials. This is known as the binomial random variable, which is defined as the sum of \\(n\\) independent, identical Bernoulli random variables.\n\n\n\n\n\n\nDefinition\n\n\n\nGiven \\(n\\) independent Bernoulli trials \\(X\\) with the same probability of success \\(p\\), the binomial random variable is defined as: \\[B = \\sum_{i=1}^n X_i\\] where \\(X_i\\) is the random variable from the i-th Bernoulli trial, which takes values of 1 and 0.\n\n\nIn this definition I use the term independence without defining it properly, which will be done in chapter 10. Intuitively, independence between two Bernoulli trials (e.g. coin tosses) means that the outcome of one trial does not change the probability of the outcomes of any other trials. This amounts to the assumption that the probability of an outcome followed by another one is the product of the separate probabilities of the two outcomes. For example, if the two outcomes are wins and losses, then \\(P(\\{WL\\}) = P(W)P(L)\\). This will be used below in the calculation of the variance of the binomial random variable.\nTo find the probability distribution of the binomial random variable, we need to define the event of \\(k\\) wins out of \\(n\\) trials. Consider the case of 4 trials. It is easy to find the event of 4 wins, as it is comprised only of the outcome \\(\\{WWWW\\}\\). Then, \\(P(4) = p^4\\), based on the independence assumption. The event of winning 3 times consists of four strings: \\(\\{LWWW, WLWW, WWLW, WWWL\\}\\) so the probability of obtaining 3 wins is the sum of the four probabilities, each equal to $ p^3(1-p)$ from the independence assumption above, so \\(P(3) = 4p^3(1-p)\\). The event of winning 2 times is even more cumbersome, and consists of six strings: \\(\\{ LLWW, WLLW, WWLL, WLWL, LWLW, LWWL\\}\\), so \\(P(2) = 6p^2(1-p)^2\\) by the same reasoning.\nNow imagine doing this to calculate 50 wins out of 100 trials. The counting gets ugly very fast. We need a general formula to help us count the number of ways of winning \\(k\\) times out of \\(n\\) trials. We denote this number \\(\\binom{n}{k}\\), also known as “\\(n\\) choose \\(k\\)” because it corresponds to the number of ways of choosing \\(k\\) distinct objects out of \\(n\\) without regard to order. The connection is as follows: let us label each trial from 1 to \\(n\\). Then to construct a string with \\(k\\) wins, we need to specify which trials resulted in a win (the rest are of course losses). It does not matter in which order those wins are selected - it still results in the same string. Therefore the number of different strings of \\(n\\) binary trials with \\(k\\) successes is the same as the number of ways of selecting \\(k\\) different objects out of \\(n\\) different ones.\nThe number itself can be derived as follows: there are \\(n\\) possibilities for choosing the number of the first win, then \\(n-1\\) possibilities for choosing the number of the second win, etc, and finally when choosing the \\(k\\)-th win there are \\(n-k+1\\) possibilities (note that \\(k \\leq n\\), and if \\(n=k\\) there is only one option left for the last choice.) Thus, the total number of such selections is: \\(n(n-1)...(n-k+1) = n!/(n-k)!\\)\nBut note that we overcounted, because we considered different strings of wins depending on the order in which a win was selected, even if the resulting strings are the same (example: \\(n=4\\) and \\(k=4\\) gives us \\(4!\\) although there is only one string of 4 wins out of 4). In order to correct for the overcounting, we need to divide by the total number of ways of selecting the same string of \\(k\\) wins out of \\(n\\). This is number of ways of rearranging \\(k\\) wins, or \\(k!\\) Thus, the number we seek is:\n\\[\\binom{n}{k} = \\frac{n!}{k! (n-k)!}\\]\nWe can now calculate the general probability of winning \\(k\\) times out of \\(n\\) trials. First, each string of \\(k\\) wins and \\(n-k\\) losses has the probability \\(p^k (1-p)^{n-k}\\). Since we now know that the number of such strings is \\(C^n_k\\), the probability is:\n\\[\nP(\\mathrm{k \\; wins \\; in \\; n \\; trials}) =  P(B=k)= \\binom{n}{k}  p^k (1-p)^{n-k}\n\\]\nThis is the probability distribution of the binomial random variable \\(B\\).\nThe binomial random variable has much simpler formulas for the mean and the variance. First, we know that the mean of a sum of random variables is the sum of the means and the binomial random variable is a sum of \\(n\\) Bernoulli random variables \\(X\\). Let us say \\(X\\) takes only the values of 0 and 1 with probabilities \\(1-p\\) and \\(p\\), so we can use the additive property of expected value to calculate \\(E(B)\\):\n\\[\nE(B) = E\\left[\\sum_{i=1}^n X\\right] = \\sum_{i=1}^n E(X) = \\sum_{i=1}^n p = np\n\\] This means that the expected number of heads/successes is the product of the probability of 1 head/success and the number of trials, e.g. if the probability of success is 0.3, then the expected number of successes out of 100 is 30.\nNow let us calculate the variance, for which in general the same additive property is not true. But remember that in the section on variance above we showed that the variance of a sum of two random variables is the sum of their two separate variances as long as their covariance is zero. It turns out that for random variables that satisfy the product rule \\(P(x, y) = P(x)P(y)\\) their covariance is 0:\n\\[E((X-\\mu_X)(Y-\\mu_Y))  =  \\sum_i \\sum_j (x_i-\\mu_X) (y_j-\\mu_Y) P(x_i, y_j) =  \\] \\[ = \\sum_i(x_i-\\mu_X)P(x_i) \\sum_j (y_j-\\mu_Y) P(y_j) \\] We saw in section on variance above that the expected value of deviations from the mean is zero, which gives us:\n\\[E((X-\\mu_X)(Y-\\mu_Y))  = E(X-\\mu_X)E(Y-\\mu_Y) = 0\\]\nThe demonstrates that for independent variables the variance of their sum is the sum of the variances and we can use this to compute the variance of the binomial random variable:\n\\[\nVar(B) = Var\\left[\\sum_{i=1}^n X\\right]  = \\sum_{i=1}^n Var(X) =\\sum_{i=1}^n p(1-p) = np(1-p)\n\\]\nFor any given number of Bernoulli trials, the variance has a quadratic dependence on probability of success \\(p\\): if \\(p=1\\) or \\(p=0\\), corresponding to all successes, or all failures, respectively, then the variance is zero, since there is no spread in the outcome. For a fair coin \\(p=1/2\\) the variance is highest. This can be seen in the plots of binomial random variables for \\(n=2\\), \\(n=5\\), and \\(n=50\\), shown in figures below.\n\n\n\n\n\nThe binomial distribution for \\(n=2\\) and \\(p=0.2\\) and \\(p=0.5\\) (you should be able to tell which one is which!)\n\n\n\n\n\n\n\nThe binomial distribution for \\(n=2\\) and \\(p=0.2\\) and \\(p=0.5\\) (you should be able to tell which one is which!)\n\n\n\n\n\n\n\n\n\nThe binomial distribution for \\(n=5\\) and \\(p=0.2\\) and \\(p=0.5\\) (you should be able to tell which one is which!)\n\n\n\n\n\n\n\nThe binomial distribution for \\(n=5\\) and \\(p=0.2\\) and \\(p=0.5\\) (you should be able to tell which one is which!)\n\n\n\n\n\n\n\n\n\nThe binomial distribution for \\(n=50\\) and \\(p=0.2\\) and \\(p=0.5\\) (you should be able to tell which one is which!)\n\n\n\n\n\n\n\nThe binomial distribution for \\(n=50\\) and \\(p=0.2\\) and \\(p=0.5\\) (you should be able to tell which one is which!)\n\n\n\n\n\n\n4.2.3 Exercises\nCalculate the means and variances based on the plotted distributions using the definitions \\(\\ref{def:ch4_mean}\\) and \\(\\ref{def:ch4_var}\\) and compare your calculations against equations \\(\\ref{eq:ch4_mean_unif}\\) and \\(\\ref{eq:ch4_var_unif}\\) (for uniform random variables) and equations \\(\\ref{eq:ch4_binom_mean}\\) and \\(\\ref{eq:ch4_binom_var}\\) (for binomial random variables)\n\nCalculate the mean and the variance for the two uniform distributions plotted in figure @ref(fig:unif-dist).\nCalculate the mean and the variance for the two binomial distributions plotted in figure @ref(fig:bin-dist-1).\nCalculate the mean and the variance for the two binomial distributions plotted figure @ref(fig:bin-dist-2).\nEstimate (approximately) the mean and the variance for the two binomial distributions plotted in figure @ref(fig:bin-dist-3).\n\n\n\n4.2.4 testing for mutants\nSuppose that you’re screening people for a particular genetic abnormality. It is known from prior experience that about 5% of this population carry this mutation. You run your tests on a group of 20 people, and the results indicate that 3 of them are carriers. Clearly, this is higher than you expected - 3/20 is 15%, or 3 times higher than the estimate. One of your colleagues exclaims, What are the odds of this?\nTo answer this question, one must start by stating your assumptions. First, the people tested must be chosen from the same population, so we can assume a priori each had probability 5% of being a carrier. Second, the people must be selected without bias, that is, selection of one must be unlinked or independent of others. As a counter-example, if your selection included an entire biological family, that would be a biased selection - it may be that the whole family has the mutation, or maybe they don’t, but either way probability is no longer determined on a person-by-person basis. If these assumptions are made, then one can calculate the probability of making a selection of 20 people that includes 3 carriers of the mutation, using the binomial distribution.\nThe formula for the binomial distribution in equation \\(\\ref{eq:ch4_binom_dist}\\) provides the answer for any given number of mutants. For example, the probability of 3 people out of 20 being carriers for the mutation is: \\[P(\\mathrm{3 \\ out \\ of  \\ 20}; \\ p=0.05) = \\binom{20}{3} \\times 0.05^3  \\times 0.985^{17} =  \\] \\[ = 1140 \\times 0.05^3 \\times 0.985^{17} \\approx 0.0596\\]\nOne may want to ask a different question: what is the probability that there are at least 3 mutants in the sample of 20 people? To most efficient way to calculate this it is to answer the complementary question first: what is the probability that there are fewer than 3 mutants out of 20 people? This corresponds to three values of the random variable: 0, 1, or 2. We can calculate the total probability by adding up the three separate probabilities, since they represent non-overlapping events (one can’t have 1 and 2 mutants in a sample simultaneously): \\[ P(B < 3; \\  p=0.05) = P(B=0) + P(B=1) + P(B=2) = \\] \\[ = \\binom{20}{2} \\times 0.05^2  \\times 0.985^{18} +\\binom{20}{1} \\times 0.05^1  \\times 0.985^{19} +\\binom{20}{0} \\times 0.05^0  \\times 0.985^{20} \\approx \\] \\[ \\approx 0.925 \\] The answer to the original question is found by taking the complementary probability \\(1-0.925=0.075\\). Thus the probability of finding at least 3 mutants in a sample of 20 with individual probability 0.0015 is approximately 0.075. The answer is close to the probability of having exactly 3 mutants because the probability of finding more than 3 mutants is very low."
  },
  {
    "objectID": "probdist.html#random-number-generators-in-r",
    "href": "probdist.html#random-number-generators-in-r",
    "title": "4  Random variables and distributions",
    "section": "4.3 Random number generators in R",
    "text": "4.3 Random number generators in R\n\nSimulating randomness with a computer is not a simple task. Randomness is contrary to the nature of a computer, which is designed to perform operations exactly. However, there are algorithms that produce a string of numbers that are for all intents and purposes random: there is no obvious connection between one number and the next, and the values don’t form any pattern. Such algorithms are called random number generators, although to be more precise they produce pseudo-random numbers. The reason is that they actually produce a perfectly predictable string of numbers, which eventually repeats itself, but with a humongous period. One can even produce the same random number, or the same string of random numbers, by specifying the seed for the random number generator. This is very useful if one wants to reproduce the results of a code that uses random numbers.\nOf course, random variable are not all the same - they have different distributions. R has a number of functions for producing random numbers from different distributions. For example, to produce random numbers from a set of values with a uniform probability distribution, use the function sample(). For instance, the following command produces a random integer between 1 and 20. Repeating the same command produces a new random number, which (most likely) is not the same as the first. The first input argument (1:20) is the vector of values from which to draw the random number, and the second is the size of the sample:\n\nx <- sample(1:20,1)\ny <- sample(1:20,1)\nprint(x)\n\n[1] 9\n\nprint(y)\n\n[1] 3\n\n\nTo generate 10 randomly chosen integers between 1 and 20, see the following two commands, which differ in setting the value of the option replace. The first command doesn’t specify the value for replace, and by default it is set to FALSE, so the command draws numbers without replacing them (meaning that all the numbers in the sample are unique). In the second command replace is set to TRUE, so the numbers that were selected can be chosen again. In both cases, repeatedly running the command results in a different set of randomly chosen numbers, which you should investigate by copying the commands into R and running them yourself.\n\nx <- sample(1:20,10)\nprint(x)\n\n [1]  7  3  5 20 10 11  9  1 19 18\n\ny <- sample(1:20,10,replace=TRUE)\nprint(y)\n\n [1] 11  5  7 13  1 10 14 10  1  5\n\n\nIf you need to generate a random number from the binomial distribution, R has you covered. The command is rbinom(s, n, p) and it requires three input values: s is the number of observations (sample size), n is the number of binary trials in one observation, and p is the probability of success in one binary trial. The following two commands generate a single random number, the number of successes out of 20 trials with probability of success 0.2 and 0.6:\n\nx <- rbinom(1,20,0.2)\nprint(x)\n\n[1] 2\n\ny <- rbinom(1,20,0.6)\nprint(y)\n\n[1] 11\n\n\nTo generate an entire sample of random numbers, change the first input parameter to 10. As you’d expect, the samples of 10 observations are (most likely) noticeably different: when the probability p is 0.2, the number of successes tend to be less than 6, while for probability 0.6, the numbers are usually greater than 10.\n\nx <- rbinom(10,20,0.2)\nprint(x)\n\n [1] 2 6 5 3 4 1 3 3 4 3\n\ny <- rbinom(10,20,0.6)\nprint(y)\n\n [1] 14 14 13 11 14 12 13  8  9 14\n\n\nNotice that the range of possible values of this random variable is between 0 and 20, but unlike the uniform random numbers produced with the sample() function, the probability of obtaining different numbers are different, and depend on the parameter p. Calculation and plotting of the binomial distribution function can be accomplished with the command dbinom(x,n,p), where \\(x\\) is the value of the random variable (between 0 and n), \\(n\\) is the number of trials, and p is the probability of success. For instance, the following script calculate the probability of obtaining 1 success out of 20 with probability \\(p=0.2\\):\n\nn <- 20\np <- 0.2\nprint(dbinom(1,n,p))\n\n[1] 0.05764608\n\n\nThe script above calculates the probabilities of all of the possible values of the random variable by substituting the vector of these values (e.g. 0 to 20) instead of the number 1, generating the probability distribution vector. This vector is plotted vs. the values of the random variable using the barplot() function, producing an aesthetically pleasing plot of the binomial distribution. The script plots two binomial probability distributions, both with \\(n=20\\), the first with \\(p=0.2\\) and the second with \\(p=0.6\\). Notice also the use of the axis labels in barplot() using the same options xlab and ylab as in plot() and use the main option to produce a title above each plot.\n\nvalues.vec <- 0:n\nprob.dist <- dbinom(values.vec,n,p)\nbarplot(prob.dist,names.arg=values.vec,xlab='binomial RV',ylab='probability',\nmain='binom dist with n=20 and p=0.2')\np<-0.6\nprob.dist <- dbinom(values.vec,n,p)\nbarplot(prob.dist,names.arg=values.vec,xlab='binomial RV',ylab='probability',\nmain='binom dist with n=20 and p=0.6')\n\n\n\n\nThe binomial distribution for two different values of n and p produced using dbinom() function.\n\n\n\n\n\n\n\nThe binomial distribution for two different values of n and p produced using dbinom() function."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "linreg.html#linear-relationship-between-two-variables",
    "href": "linreg.html#linear-relationship-between-two-variables",
    "title": "5  Linear regression",
    "section": "5.1 Linear relationship between two variables",
    "text": "5.1 Linear relationship between two variables\n\nAlthough there is always error in any real data, there may be a relationship between the two variables that is not random: for example, when one goes up, the other one tends to go up as well. These relationships may be complicated, but in this chapter we will focus on the the simplest and most common type of relationship: linear, where a change in one variable is associated with a proportional change in the other, plus an added constant. This is expressed mathematically using the familiar equation for a linear function, with parameters slope (\\(a\\)) and intercept (\\(b\\)):\n\\[ y = ax + b\\]\nLet us say you have measured some data for two variables, which we will call, unimaginatively, \\(x\\) and \\(y\\). This data set consists of pairs of numbers: one for \\(x\\), one for \\(y\\), for example, the heart rate and body temperature of a person go together. They cannot be mixed up between different people, as the data will lose all meaning. We can denote this a list of \\(n\\) pairs of numbers: \\((x_i, y_i)\\) (where \\(i\\) is an integer between 1 and \\(n\\)). Since this is a list of pairs of numbers, we can plot them as separate points in the plane using each \\(x_i\\) as the x-coordinate and each \\(y_i\\) as the y-coordinate. This is called a scatterplot of a two-variable data set. For example, two scatterplots of a data set of heart rate and body temperature are shown in figure \\(\\ref{fig:HRTemp_scatterplot}\\). In the first one, the body temperature is on the x-axis, which makes it the explanatory variable; in the second one, the body temperature is on the y-axis, which makes it the response variable.\n\ndata <- read.table(\"data/HR_temp.txt\", header = TRUE)\nplot(data$Temp, data$HR, main = \"heart rates vs. body temps\",\n    cex = 1.5, cex.axis = 1.5, cex.lab = 1.5)\nplot(data$HR, data$Temp, main = \"body temps vs. heart rates\",\n    cex = 1.5, cex.axis = 1.5, cex.lab = 1.5)\n\n\n\n\nScatterplot of heart rates and body temperatures: a) with heart rate as the explanatory variable; b) with body temperature as the explanatory variable.\n\n\n\n\n\n\n\nScatterplot of heart rates and body temperatures: a) with heart rate as the explanatory variable; b) with body temperature as the explanatory variable."
  },
  {
    "objectID": "linreg.html#linear-least-squares-fitting",
    "href": "linreg.html#linear-least-squares-fitting",
    "title": "5  Linear regression",
    "section": "5.2 Linear least-squares fitting",
    "text": "5.2 Linear least-squares fitting\n\n\n5.2.1 sum of squared errors\nIt is easy to find the best-fit line for a data set with only two points: its slope and intercept can be found by solving the two simultaneous linear equations, e.g. if the data set consists of \\((3,2.3), (6, 1.7)\\), then finding the best fit values of \\(a\\) and \\(b\\) means solving the following two equations: \\[\\begin{eqnarray*}\n3a + b &=&  2.3 \\\\\n6a + b &=& 1.7\n\\end{eqnarray*}\\] These equations have a unique solution for each unknown: \\(a=-0.2\\) and \\(b=2.9\\) (you can solve it using basic algebra).\nHowever, a data set with two points is very small and cannot serve as a reasonable guide for finding a relationship between two variables. Let us add one more data point, to increase our sample size to three: \\((3,2.3), (6, 1.7), (9, 1.3)\\). How do you find the best fit slope and intercept? take two points and find a line, that is the slope and the intercept, that passes through the two. It should be clear why this is a bad idea: we are arbitrarily ignoring some of the data, while perfectly fitting two points. So how do we use all the data? Let us write down the equations that a line with slope \\(a\\) and intercept \\(b\\) have to satisfy in order to fit our data points: \\[\\begin{eqnarray}\n3a + b &=&  2.3 \\\\\n6a + b &=& 1.7 \\\\\n9a + b &=& 1.3\n\\end{eqnarray}\\]\nThis system has no exact solution, since there are three equations and only two unknowns. We need to find \\(a\\) and \\(b\\) such that they are a best fit to the data, not the perfect solution. To do that, we need to define what we mean by the goodness of fit.\nOne simple way to asses how close the fit is to the data is to subtract the predicted values of \\(y\\) from the data, as follows: \\(e_i = y_i - (ax_i + b)\\). The values \\(e_i\\) are called the errors or residuals of the linear fit. If the values predicted by the linear model (\\(ax_i+b\\)) are close to the actual data \\(y_i\\), then the error will be small. However, if we add it all up, the errors with opposite signs will cancel each other, giving the impression of a good fit simply if the deviations are symmetric.\nA more reasonable approach is to take absolute values of the deviations before adding them up. This is called the total deviation, for \\(n\\) data points with a line fit: \\[ TD = \\sum_{i=1}^n |  y_i - a x_i - b | \\]\nMathematically, a better measure of total error is a sum of squared errors, which also has the advantage of adding up non-negative values, but is known as a better measure of the distance between the fit and the data (think of Euclidean distance, which is also a sum of squares) :\n\\[ SSE = \\sum_{i=1}^n ( y_i -  a x_i - b )^2 \\]\nThus we have formulated the goal of fitting the best line to a two-variable data set, also known as linear regression: find the values of slope and intercept that result in the lowest possible sum of squared errors. There is a mathematical recipe which produces these values, which will be described in the next section. Any model begins with assumptions and in order for linear regression to be a faithful representation of a data set, the following must be true:\n\nthe variables have a linear relationship\nall of the measurements are independent of each other\nthere is no noise in the measurements of the explanatory variable\nthe noise in the measurements of the response variable is normally distributed with mean 0 and identical standard deviation\n\nThe reasons why these assumptions are necessary for linear regression to work are beyond the scope of the text, and they are elucidated very well in the book Numerical Recipes . However, it is important to be aware of them because if they are violated, the resulting linear fit may be meaningless. It’s fairly clear that if the first assumption is violated, you are trying to impose a linear relationship on something that is actually curvy. The second assumption of independence is very important and often overlooked. The mathematical reasons for it have to do with properly measuring the goodness of fit, but intuitively it is because measurements that are linked can introduce a new relationship that has to do with the measurements, rather than the relationship between the variables. Violation of this assumption can seriously damage the reliability of the linear regression. The third assumption is often ignored, since usually the explanatory variable is also measured and thus has some noise. The reason for it is that the measure of goodness of fit is based only on the response variable, and there is no consideration of the noise in the explanatory variable. However, a reasonable amount of noise in the explanatory variable is not catastrophic for linear regression. Finally, the last assumption is due to the statistics of maximum-likelihood estimation of the slope and intercept, but again some deviation from perfect normality (bell-shaped distribution) of the noise, or slightly different variation in the noise is to be expected.\n\n\n5.2.2 best-fit slope and intercept\n\n\n\n\n\n\nDefinition\n\n\n\nThe covariance of a data set of pairs of values \\((X,Y)\\) is the sum of the products of the corresponding deviations from their respective means:\n\n\n\\[ Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar X) (y_i - \\bar Y)\n\\]\nIntuitively, this means that if two variable tend to deviate in the same direction from their respective means, they have a positive covariance, and if they tend to deviate in opposite directions from their means, they have a negative covariance. In the intermediate case, if sometimes they deviate together and other times they deviate in opposition, the covariance is small or zero. For instance, the covariance between two independent random variables is zero, as we saw in section \\(\\ref{sec:math4_2}\\).\nIt should come as no surprise that the slope of the linear regression depends on the covariance, that is, the degree to which the two variables deviate together from their means. If the covariance is positive, then for larger values of \\(x\\) the corresponding \\(y\\) values tend to be larger, which means the slope of the line is positive. Conversely, if the covariance is negative, so is the slope of the line. And if the two variables are independent, the slope has to be close to zero. The actual formula for the slope of the linear regression is :\n\\[\\begin{equation}\nm = \\frac{Cov(X,Y)}{Var(X)}\n\\end{equation}\\]\nI will not provide a proof that this slope generates the minimal sum of squared errors, but that is indeed the case. To find the intercept of the linear regression, we make use of one other property of the best fit line: in order for it to minimize the SSE, it must pass through the point \\((\\bar X, \\bar Y)\\). Again, I will not prove this, but note that the point of the two mean values is the central point of the “cloud” of points in the scatterplot, and if the line missed that central point, the deviations will be larger. Assuming that is the case, we have the following equation for the line: \\(\\bar Y = a\\bar X + b\\), which we can solve for the intercept \\(b\\):\n\\[\\begin{equation}\nb = \\bar Y - \\frac{Cov(X,Y) \\bar X}{Var(X)}\n\\end{equation}\\]\n\n\n5.2.3 Execises\n\nBody leanness (B) and heat loss rate (H) in boys; partial data set from \n\n\nB(\\(m^2/kg\\))\nH(\\(^\\circ C /min)\\)\n\n\n\n\n7.0\n0.103\n\n\n5.0\n0.091\n\n\n3.6\n0.014\n\n\n3.3\n0.024\n\n\n2.4\n0.031\n\n\n2.1\n0.006\n\n\n\n\nUse the data set in table \\(\\ref{tab:ch8_bh}\\) to answer the following questions:\n\nCompute the means and standard deviations of each variable.\nCompute the covariance between the two variables.\nCalculate the slope and intercept of the linear regression for the data with \\(B\\) as the explanatory variable.\nMake a scatterplot of the data set with \\(B\\) as the explanatory variable and sketch the linear regression line with the parameters you computed.\nCalculate the slope and intercept of the linear regression the data with \\(H\\) as the explanatory variable.\nMake a scatterplot of the data set, with \\(H\\) as the explanatory variable and sketch the linear regression line with the parameters you computed.\n\n\n\n5.2.4 correlation and goodness of fit\nThe correlation between two random variables is a measure of how much variation in one corresponds to variation in the other. If this sounds very similar to the description of covariance, it’s because they are closely related. Essentially, correlation is a normalized covariance, restricted to lie between -1 and 1. Here is the definition:\n\n\n\n\n\n\nDefinition\n\n\n\nThe (linear) correlation of a dataset of pairs of data values (X,Y) is:\n\n\n\\[ r = \\frac{Cov(X,Y)}{\\sqrt{{Var(X)}{Var(Y)}}} =  \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}\n\\]\nIf the two variables are identical, \\(X=Y\\), then the covariance becomes its variance \\(Cov(X,Y) = Var(X)\\) and the denominator also becomes the variance, and the correlation is 1. This is also true if \\(X\\) and \\(Y\\) are scalar multiples of each other, as you can see by plugging in \\(X= cY\\) into the covariance formula. The opposite case if \\(X\\) and \\(Y\\) are diametrically opposite, \\(X = -cY\\), which has the correlation coefficient of -1. All other cases fall in the middle, neither perfect correlation nor perfect anti-correlation. The special case if the two variables are independent, and thus their covariance is zero, has the correlation coefficient of 0.\n \nThis gives a connection between correlation and slope of linear regression:\n\\[\\begin{equation}\na = r \\frac{\\sigma_Y}{\\sigma_X}\n\\label{eq:slope_corr}\n\\end{equation}\\]\nWhenever linear regression is reported, one always sees the values of correlation \\(r\\) and squared correlation \\(r^2\\) displayed. The reason for this is that \\(r^2\\) has a very clear meaning of the the fraction of the variance of the dependent variable \\(Y\\) explained by the linear regression \\(Y=aX+b\\). Let us unpack what this means.\nAccording to the stated assumptions of linear regression, the response variable \\(Y\\) is assumed to be linear relationship with the explanatory variable \\(X\\), but with independent additive noise (also normally distributed, but it doesn’t play a role for this argument). Linear regression captures the linear relationship, and the remaining error (residuals) represent the noise. Thus, each value of \\(Y\\) can be written as \\(Y = R + \\hat Y\\) where \\(R\\) is the residual (noise) and the value predicted by the linear regression is \\(\\hat Y =aX+b\\). The assumption that \\(R\\) is independent of \\(Y\\) means that \\(Var(Y) = Var (\\hat Y) + Var (R)\\) because variance is additive for independent random variables, as we discussed in section \\(\\ref{sec:math4}\\). By the same reasoning \\(Cov(X,\\hat Y + R) = Cov(X,\\hat Y) + Cov(X,R)\\). These two covariances can be simplified further: \\(Cov(X,R) = 0\\) because \\(R\\) is independent random noise. \\(X\\) and the predicted \\(\\hat Y\\) are perfectly correlated, so \\(Cov(X,\\hat Y) = Cov(X,mX+b) = Var(X) = Var(\\hat Y)\\). This leads to the derivation of the meaning of \\(r^2\\):\n\\[\\begin{equation}\n\\begin{aligned}\n  r^2 = \\frac{Cov(X,Y)^2}{Var(X) Var(Y)} &=   \\frac{(Cov(X,\\hat Y) + Cov(X,R) )^2}{Var(X) Var(Y)}   = \\\\\n  =\\frac{Var(X)Var(\\hat Y)}{Var(X) Var(Y)} &=  \\frac{Var(\\hat Y)}{Var(Y)}\n  \\end{aligned}\n\\label{eq:ch8_frac_var}\n\\end{equation}\\]\nOne should be cautious when interpreting results of a linear regression. First, just because there is no linear relationship does not mean that there is no other relationship. Figure \\(\\ref{fig:ch8_corr_examples}\\) shows some examples of scatterplots and their corresponding correlation coefficients. What it shows is that while a formless blob of a scatterplot will certainly have zero correlation, so will other scatterplots in which there is a definite relationship (e.g. a circle, or a X-shape). The point is that correlation is always a measure of the linear relationship between variables.\nThe second caution is well known, as that is the danger of equating correlation with a causal relationship. There are numerous examples of scientists misinterpreting a coincidental correlation as meaningful, or deeming two variables that have a common source as causing one another. For example, one can look at the increase in automobile ownership in the last century and the concurrent improvement in longevity and conclude that automobiles are good for human health. It is well-documented, however, that a sedentary lifestyle and automobile exhaust do not make a person healthy. Instead, increased prosperity has increased both the purchasing power of individuals and enabled advances in medicine that have increase our lifespans. To summarize, one must be careful when interpreting correlation: a weak one does not mean there is no relationship, and a strong one does not mean that one variable causes the changes in the other.\nThere is another important measure of the quality of linear regression: the residual plot. The residuals are the differences between the predicted values of the response variable and the actual value from the data. As stated above, linear regression assumes that there is a linear relationship between the two variables, plus some uncorrelated noise added to the values of the response variable. If that were true, then the plot of the residuals would look like a vaguely spherical blob, with a mean value of 0 and no discernible trend (e.g. no increase of residual for larger \\(x\\) values). Visually assessing residual plots is an essential check on whether linear regression is a reasonable fit to the data in addition to the \\(r^2\\) value.\n\n\n5.2.5 Exercises\nFigure \\(\\ref{fig:ch8_penguins}\\) shows scatterplots of the rate of oxygen consumption (VO) and heart rate (HR) measured in two macaroni penguins running on a treadmill (really). The authors performed linear regression on the data and found the following parameters: \\(VO =0.23HR - 11.62\\) (penguin A) and \\(VO =0.25HR - 20.93\\) (penguin B). The datasets have the standard deviations: \\(\\sigma_{VO} = 6.77\\) and \\(\\sigma_{HR} = 28.8\\) (penguin A) and \\(\\sigma_{VO} = 8.49\\) and \\(\\sigma_{HR} = 30.6\\) (penguin B).\n \n\nFind the dimensions and units of the slope and the intercept of the linear regression for this data (the units of HR and VO are on the plot).\nData set B has a larger slope than data set A. Does this mean the correlation is higher in data set B than in A? Explain.\nCalculate the correlation coefficients for the linear regressions of the two penguins; explain how much variance is explained in each case.\nRe-calculate the slopes of the two linear regressions if the explanatory and response variables were reversed. Does changing the order of variable affect the correlation?"
  },
  {
    "objectID": "linreg.html#linear-regression-using-r",
    "href": "linreg.html#linear-regression-using-r",
    "title": "5  Linear regression",
    "section": "5.3 Linear regression using R",
    "text": "5.3 Linear regression using R\n\nWe now have the tools to compute the parameters of the best-fit line, provided we can calculate the means, variances, and covariance of the two variable data set. Of course, the best way to do all this is to let a computer handle it. The function for calculating linear regression in R is lm(), which outputs a bunch of information to a variable called myfit in the script below. The slope, intercept, and other parameters can be printed out using the summary() function. In the script below you see a bunch of information, but we are concerned with the ones in the first column correspond to the best fit intercept (-166.2847) and the slope (2.4432). You can check that they correspond to our formulas by computing the covariance, the variances, and the means of the two variables:\n\nmy_data <- read.table(\"data/HR_temp.txt\", header = TRUE)\nmyfit <- lm(HR ~ Temp, my_data)\nsummary(myfit)\n\n\nCall:\nlm(formula = HR ~ Temp, data = my_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.6413  -4.6356   0.3247   4.8304  15.8474 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)   \n(Intercept) -166.2847    80.9123  -2.055  0.04190 * \nTemp           2.4432     0.8235   2.967  0.00359 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.858 on 128 degrees of freedom\nMultiple R-squared:  0.06434,   Adjusted R-squared:  0.05703 \nF-statistic: 8.802 on 1 and 128 DF,  p-value: 0.003591\n\na <- cov(my_data$HR, my_data$Temp)/var(my_data$Temp)\nprint(a)\n\n[1] 2.443238\n\nb <- mean(my_data$HR) - a * mean(my_data$Temp)\nprint(b)\n\n[1] -166.2847\n\n\nHere Temp and HR are the explanatory and response variables, respectively, and my_data is the name of the data frame they are stored in. The best fit parameters are stored in myfit, and the line can be plotted using abline(myfit). The script below shows how to calculate a linear regression line and then plot it over a scatterplot in R, and the result is shown in figure \\(\\ref{fig:linreg_HRTemp}\\)a.\n\nplot(my_data$Temp, my_data$HR, main = \"scatterplot and linear regression line\",\n    cex = 1.5, cex.axis = 1.5, cex.lab = 1.5)\nabline(myfit)\nHRresiduals <- resid(myfit)\nplot(data$Temp, HRresiduals, main = \"residuals plot\",\n    cex = 1.5, cex.axis = 1.5, cex.lab = 1.5)\nabline(0, 0)\n\n\n\n\nLinear regression for a data set of heart rates and body temperatures (a); and the residuals (b).\n\n\n\n\n\n\n\nLinear regression for a data set of heart rates and body temperatures (a); and the residuals (b).\n\n\n\n\nHowever, what does this mean about the quality of the fit? Just because we found a line to draw through a scatterplot does not mean that this line is meaningful. In fact, looking at the plot, there does not seem to be much of a relationship between the two variables. There are various statistical measures for the significance of linear regression, the most important one relies on the correlation between the two data sets. Look again at the summary statistics for the data set of heart rates and temperatures. There are several different statistics here, and the one that we care about is the \\(r^2\\), which is reported here as ‘Multiple R-squared’. This number tells us that the linear regression accounts for only about 6% of the total variance of the heart rate. In other words, there is no significant linear relationship in this data set.\nAs mentioned in section \\(\\ref{sec:math8}\\), the other important check is plotting the residuals of the data set, after the linear fit is subtracted. You see the result in figure \\(\\ref{fig:linreg_HRTemp}\\)b, showing that the residuals do not have any pronounced pattern. So it is reasonable to conclude that linear regression was a reasonable model to which to fit the data. The low correlation is because data seem to have little to no relationship, not because there is some complicated nonlinear relationship.\nHere is an example of a linear regression performed and the line plotted over the basic R plot. Note that lm() uses the following syntax to indicate which variable is which: lm(Y ~ X) (where Y is the response variable and X is the explanatory variable.)\n\nlibrary(HistData)\nmyfit <- lm(child ~ parent, Galton) \nsummary(myfit)\n\n\nCall:\nlm(formula = child ~ parent, data = Galton)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.8050 -1.3661  0.0487  1.6339  5.9264 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 23.94153    2.81088   8.517   <2e-16 ***\nparent       0.64629    0.04114  15.711   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.239 on 926 degrees of freedom\nMultiple R-squared:  0.2105,    Adjusted R-squared:  0.2096 \nF-statistic: 246.8 on 1 and 926 DF,  p-value: < 2.2e-16\n\nprint(paste(\"The best-fit slope is: \", myfit$coefficients[2]))\n\n[1] \"The best-fit slope is:  0.646290581993716\"\n\nprint(paste(\"The best-fit intercept is: \", myfit$coefficients[1]))      \n\n[1] \"The best-fit intercept is:  23.9415301804085\"\n\n\nThe summary outputs a whole bunch of information that is returned by the lm() function, as the object myfit. The most important are the intercept and slope, which may be printed out as shown above, and the R-squared parameter, also called the coefficient of determination. The value of R-squared is not accessible directly in myfit, but it is printed out in the summary (use multiple R-squared for our assignments.)\nThe actual best-fit line can be plotted as follows over a scatterplot of the data; notice that abline can take myfit as an input and use the slope and intercept:\n\n#Overlay the best-fit line on the base R plot\nplot(Galton$parent, Galton$child, xlab='mid-parent height (inches)', ylab='child height (inches)')\nabline(myfit)\n\n\n\n\nAfter performing linear regression it is essential to check that the residuals obey the assumptions of linear regression. The residuals are the difference between the predicted response variable values and the actual values of the response variable, in this case the child height. The residuals are contained in the object myfit as variable residuals:\n\nplot(Galton$parent, myfit$residuals, xlab='mid-parent height (inches)', ylab='residuals (inches)')\nabline(0,0)\n\n\n\n\nIt appears that the residuals meet the assumptions of being independent of measurement (shapeless scatterplot), are centered at zero, and look roughly normally distributed, although that can be checked more carefully using other tools.\n\n5.3.1 Exercises:\n\nCalculate descriptive statistics (mean and standard deviation) of the residuals from the linear regression above. What do you expect them to be, and how do they differ from the expectation? Using this calculation, check that the coefficient of determination really captures the fraction of total variance explained by linear regression\n\n\n\n\n\nPerform linear regression on the Galton data set with the response and explanatory variables switched, and report which parameters changed and how.\n\n\n\n\n\nPlot the residuals from your new linear regression and calculate and report their descriptive statistics. What do you expect them to be, and how do they differ from the expectation? Using this calculation, check that the coefficient of determination really captures the fraction of total variance explained by linear regression."
  },
  {
    "objectID": "linreg.html#regression-to-the-mean",
    "href": "linreg.html#regression-to-the-mean",
    "title": "5  Linear regression",
    "section": "5.4 Regression to the mean",
    "text": "5.4 Regression to the mean\n The phenomenon called regression to the mean is initially surprising. Francis Galton first discovered this by comparing the heights of parents and their offspring. Galton took a subset of parents who are taller than average and observed that their children were, on average, shorter than their parents. He also compared the heights of parents who are shorter than average, and found that their children were on average taller than their parents. This suggests the conclusion that in long run everyone will converge closer to the average height - hence “regression to mediocrity”, as Galton called it .\n\nlibrary(\"HistData\")\nmyfit <- lm(child ~ parent, Galton)\nplot(Galton$parent, Galton$child, xlab = \"mid-parent height (inches)\",\n    ylab = \"child height (inches)\", cex = 1.5, cex.axis = 1.5,\n    cex.lab = 1.5)\nabline(myfit, lwd = 3, lty = 1)\nabline(0, 1, lwd = 3, lty = 2, col = \"red\")\nmyfit <- lm(parent ~ child, Galton)\nplot(Galton$child, Galton$parent, xlab = \"child height (inches)\",\n    ylab = \"mid-parent height (inches)\", cex = 1.5,\n    cex.axis = 1.5, cex.lab = 1.5)\nabline(myfit, lwd = 3)\nabline(0, 1, lwd = 3, lty = 2, col = \"red\")\n\n\n\n\nGalton data on heights of parents and of children as scatterplots (two versions with explanatory and response variables switched). The dotted red lines show the identity line y=x and the solid black line is the linear regression.\n\n\n\n\n\n\n\nGalton data on heights of parents and of children as scatterplots (two versions with explanatory and response variables switched). The dotted red lines show the identity line y=x and the solid black line is the linear regression.\n\n\n\n\nBut that is not the case! The parents and children in Galton’s experiment had a very similar mean and standard deviation. This appears to be a paradox, but it is easily explained using linear regression. Consider two identically distributed random variables \\((X,Y)\\) with a positive correlation \\(r\\). The slope of the linear regression is \\(m = r \\sigma_Y/\\sigma_X\\) and since \\(\\sigma_Y=\\sigma_X\\), the slope is simply \\(r\\). Select a subset with values of \\(X\\) higher than \\(\\bar X\\), and consider the mean value of \\(Y\\) for that subset. If the slope \\(m<1\\) (the correlation is not perfect), then the mean value of \\(Y\\) for that subset is less than the mean value of \\(X\\). Similarly, for a subset with values of \\(X\\) lower than \\(\\bar X\\), the mean value of \\(Y\\) for that subset is greater than the mean value of \\(X\\), again as long as the slope is less than 1.\nFigure \\(\\ref{fig:regression2mean}\\) shows Galton’s data set (available in R by installing the package ‘HistData’) along with the linear regression line and the identity like (\\(y=x\\)). If each child had exactly the same height as the parents, the scatterplot would lie on the identity line. Instead, the linear regression lines have slope less than 1 for both the plot with the parental heights as the explanatory variable and for the plot with the variables reversed. The correlation coefficient \\(r\\) does not depend on the order of the variables; so using the equation \\(\\ref{eq:slope_corr}\\) we can see the difference in slopes is explained by the two data sets having different standard deviations, and reversing the explanatory and response variables results in reciprocation of the ratio of standard deviations. The children’s heights have a higher standard deviation, which is likely an artifact of the experiment. In the data set the heights of the two parents were averaged to take them both into account, which substantially reduces the spread between male and female heights. To summarize, although the children of taller parents are shorter on average than their parents, and the children of shorter parents are taller than their parents, the overall standard deviation does not decrease from generation to generation.\n\n5.4.1 Discussion questions\nPlease read the paper on measuring the rate of de novo mutations in humans and its relationship to paternal age .\n\nWhat types of mutations were observed in the data set? What were the most and the least common?\nThe paper shows that both maternal and paternal age are positively correlated with offspring inheriting new mutations. What biological mechanism explains why paternal age is the dominant factor? What could explain the substantial correlation with maternal age?\nIs linear regression the best representation of the relationship between paternal age and number of mutations? What other model did the authors use to fit the data, and how did it perform?\nWhat do you make of the historical data of paternal ages the authors present at the end of the paper? Can you postulate a testable hypothesis based on this observation?"
  },
  {
    "objectID": "independence.html#contingency-tables-to-summarize-data",
    "href": "independence.html#contingency-tables-to-summarize-data",
    "title": "6  Independence",
    "section": "6.1 Contingency tables to summarize data",
    "text": "6.1 Contingency tables to summarize data\nWhat kind of relationship can there be between categorical variables? It cannot be expressed in algebraic form, because without numeric values we cannot talk about a variable increasing or decreasing. Instead, the question is, does one variable being in a particular category have an effect on which category the second variable falls into? Let us say you want to know whether the age of the mother has an effect on the child having trisomy 21 (a.k.a. Down’s syndrome), a genetic condition in which an embryo receives three chromosomes 21 instead of the normal two. The age of the mother is a numerical variable, but it can be classified into two categories: less than 35 and 35 or more years of age. The trisomy status of a fetus is clearly a binary, categorical variable: the fetus either has two chromosomes 21 or three.\nThe data are presented in a two-way or contingency table, which is a common way of presenting a data set with two categorical variables. The rows in such tables represent different categories of one variable and the columns represent the categories of the other, and the cells contain the data measurements of their overlaps. Table \\(\\ref{tab:data_table_DS_age}\\) shows a contingency table for the data set on Down’s syndrome and maternal age, in which the rows represent the two categories of maternal age and the columns represent the presence or absence of the syndrome. Each internal cell (as opposed to the total counts on the margins) corresponds to the number of measurement where both variables fall into the specified category, for instance the number of fetuses with the syndrome and a mother under 35 is 28.\n\n\n\nMaternal age\nNo DS\nDS\nTotal\n\n\n\n\n< 35\n29,806\n28\n29,834\n\n\n>= 35\n8,135\n64\n8,199\n\n\nTotal\n37,941\n92\n38,033\n\n\n\nContingency table for maternal age and incidence of Down’s syndrome. Numbers represent counts of patients belonging to both categories in the row and the column. DS = Down’s syndrome. From .\nOnce the data are organized into a contingency table, we can address the main question stated above: does the age of the mother have an effect on whether a fetus inherits three chromosomes 21? Perhaps the first approach that suggests itself is to compare the fraction of mothers carrying a fetus with DS for the two age categories. In this case, the fraction for the under-35 category is \\(28/29834 \\approx 0.00094\\), while for the 35-and-over category the fraction is \\(64/8199 \\approx 0.0078\\). The two fractions are different by almost a factor of 10, which suggests a real difference between the two categories. However, all data contain an element of randomness and a pinch of error, thus there needs to be quantifiable way of deciding what constitutes a real effect. But to determine if there is a relationship, we first have to define what it means to not have one."
  },
  {
    "objectID": "independence.html#conditional-probability",
    "href": "independence.html#conditional-probability",
    "title": "6  Independence",
    "section": "6.2 Conditional probability",
    "text": "6.2 Conditional probability\n\nLet us return to the abstract description of probability introduced in section 8.1. There we used the notion of sample space and its subsets, called events, to describe collections of experimental outcomes. Suppose that you have some information about a random experiment that restricts the possible outcomes to a particular subset (event). In other words, you have ruled out some outcomes, so the only possible outcomes are those in the complementary set. This will affect the probability of other events in the sample space, because your information may have ruled out some of the outcomes in that event as well.\n\n\n\n\n\n\nDefinition\n\n\n\nFor two events \\(A\\) and \\(B\\) in a sample space \\(\\Omega\\) with a probability measure \\(P\\), the probability of \\(A\\) given \\(B\\), called the conditional probability is defined as: \\[P(A|B) = \\frac{P(A\\& B)}{P(B)}\\]\n\n\n\\(A \\& B\\) represents the intersection of events \\(A\\) and \\(B\\), also known as \\(A\\) and \\(B\\), the event that consists of all outcomes that are in both \\(A\\) and \\(B\\). In words, given the knowledge that an event \\(B\\) occurs, the sample space is restricted to the subset \\(B\\), which is why the denominator in the definition is \\(P(B)\\). The num`erator is all the outcomes we are interested in, which is \\(A\\), but since we are now restricted to \\(B\\), the numerator consists of all the elements of \\(A\\) which are also in \\(B\\), or \\(A \\& B\\). The definition makes sense in two extreme cases: if \\(A = B\\) and if \\(A\\) and \\(B\\) are mutually exclusive:\n\n\\(P(B|B) = P(B \\& B) /P(B) = P(B)/P(B) = 1\\) (probability of \\(B\\) given \\(B\\) is 1)\nif \\(P(A\\& B) =0\\), then \\(P(A|B) = 0/P(B) = 0\\) (if \\(A\\) and \\(B\\) are mutually exclusive, then probability of \\(A\\) given \\(B\\) is 0)\n\n\n\n\nA Venn diagram of the sample space of all people with two events: tall people (\\(A\\)) and those who like tea (\\(B\\)) with probabilities of \\(A\\), \\(B\\) and their intersection indicated.\n\n\nThere are some common misunderstandings about conditional probability, which are usually the result of discrepancies between everyday word usage and precise mathematical terminology. First, the probability of \\(A\\) given \\(B\\) is not the same as probability of \\(A\\) and \\(B\\). These concepts seem interchangeable because the statement “what are the odds of finding a tall person who likes tea?” is hard to distinguish from ‘’what are the odds that a person who is tall likes tea?’’ The difference in these concepts can be illustrated using a Venn diagram, shown in figure \\(\\ref{fig:ch6_cond_prob}\\). Based on the probabilities indicated there, the probability of randomly selecting a person who is both tall and likes tea is \\(P(A \\& B) = 0.1\\), while the probability that a tea drinker is tall is \\(P(A | B) = 0.1/0.3 = 1/3\\), which are different values.\nA similar misconception is to be cavalier about the order of conditionality. In general, \\(P(A | B) \\neq P(B |A)\\), except in special cases. Going back to the illustration in figure \\(\\ref{fig:ch6_cond_prob}\\), the probability that a tea drinker is tall \\(P(A | B) = 1/3\\) is the different than the probability that a tall person is a tea drinker \\(P(B|A) = 0.1/0.5 = 0.2\\). One must take care when interpreting written statements to carefully distinguish what is known and what remains under investigation. In the statement \\(P(A | B)\\), \\(B\\) represents what is known, and \\(A\\) represents what is still to be investigated.\nExample. Let us return to the data set in the previous section. Data table \\(\\ref{tab:data_table_DS_age}\\) describes a sample space with four outcomes and several different events. One can calculate the probability of a fetus having Down’s syndrome (event) based on the entire data set of 38,033 mothers, and 92 total cases of DS, so the probability is \\(92/38,033 \\approx 0.0024\\). Similarly, we can calculate the probability of a mother being above 35 as \\(8,199/ 38,033 \\approx 0.256\\).\nNow we can calculate the conditional probability of a mother over 35 having a DS fetus, but first we have to be clear about what information is known and what is not. If the age of the mother is known to be over 35 (mature age or MA), then we calculate \\(P(DS | MA) = 64/8,199 \\approx 0.008\\). Notice that the denominator is restricted by the information that the mother is over 35, and thus only women in that category need to be considered for the calculation.\nOn the other hand, if we have the information that the fetus has DS, we can calculate the reversed conditional probability, what is the probability that a fetus with DS has a mother above age 35? \\(P(MA | DS) = 64/92 \\approx 0.7\\). Notice that is both calculations the numerators are the same, since they both are the intersection between the two events, but the denominators are different, because they depend on which event is given.\n\n\n\nPunnet square of a cross of two heterozygous pea plants showing the possible genotypes and phenotypes of offspring (figure by Madprime in public domain via Wikimedia Commons.)\n\n\n\n6.2.1 Exercises\nIn figure \\(\\ref{fig:mendel_flowers}\\) there is a table of genotypes from the classic Mendelian experiment with genetics and color of pea flowers. The parents are both heterozygous, meaning each has a copy of the dominant (purple) allele B and the recessive (white) allele b. The possible genotypes of offspring are shown inside the square, and all four outcomes have equal probabilities. Based on this information, answer the following questions.\n\nWhat is the probability of an offspring having purple flowers? white flowers?\nWhat is the probability of an offspring having genotype \\(BB\\)? genotype \\(Bb\\)? genotype \\(bb\\)?\nWhat is the probability of an offspring having genotype \\(BB\\), given that its flowers are purple?\nWhat is the probability of an offspring having genotype \\(Bb\\), given that its flowers are purple?\nWhat is the probability of an offspring having genotype \\(BB\\), given that its flowers are white?\nWhat is the probability of an offspring having genotype \\(Bb\\), given that its flowers are white?}\nWhat is the probability of an offspring having purple flowers, given that its genotype is \\(BB\\)?"
  },
  {
    "objectID": "independence.html#independence-of-events",
    "href": "independence.html#independence-of-events",
    "title": "6  Independence",
    "section": "6.3 Independence of events",
    "text": "6.3 Independence of events\nWe first encountered the notion of independence in chapter 3, where two events were said to be independent if they did not affect each other. The mathematical definition uses the language of conditional probability to make this notion precise. It says that \\(A\\) and \\(B\\) are independent if given the knowledge of \\(A\\), the probability of \\(B\\) remains the same, and vice versa.\n\n\n\n\n\n\nDefinition\n\n\n\nTwo events \\(A\\) and \\(B\\) are independent if \\(P(A|B) = P(A)\\), or equivalently if \\(P(B|A) = P(B)\\).\n\n\nIndependence is not a straightforward concept. It may be confused with mutual exclusivity, as one might surmise that if \\(A\\) and \\(B\\) have no overlap, then they are independent. That however, is false by definition, since \\(P(A|B)\\) is 0 for two mutually exclusive events. The confusion stems from thinking that if \\(A\\) and \\(B\\) are non-overlapping, then they do not influence each other. But the notion of influence in this definition is about information; so of course if \\(A\\) and \\(B\\) are mutually exclusive, the knowledge that one of them occurs has an influence of the probability of the other one occurring.\nA useful way to think about independence is in terms of fractions of outcomes. The probability of \\(A\\) is the fraction of outcomes out of the entire sample space which is in \\(A\\), while the probability of \\(A\\) given \\(B\\) is the fraction of outcomes in \\(B\\) which are also in \\(A\\). The definition of independence equates the two fractions, therefore, if \\(A\\) occupies 1/2 of sample space, in order for \\(A\\) and \\(B\\) to be independent, events in \\(A\\) must constitute 1/2 of the event \\(B\\). In the illustration in figure \\(\\ref{fig:ch6_cond_prob}\\), the fraction of tall people is 0.5 of the sample space, but the fraction of tea-drinkers who are tall is \\(0.1/0.3=1/3\\). Since the two fractions are different, \\(A\\) and \\(B\\) are not independent.\n \n\n\n\nIllustration of two events inside a sample space where one is entirely contained in the other\n\n\n\n6.3.1 Exercises\nConsider three examples of events and their intersections in figure \\(\\ref{fig:ch6_indep_ex}\\).\n\nBased on the two non-overlapping (mutually exclusive) events, calculate the conditional probability \\(P(A|B)\\) and compare it with \\(P(A)\\). Are \\(A\\) and \\(B\\) independent?\nBased on the two partially overlapping events, calculate the conditional probability \\(P(A|B)\\) and compare it with \\(P(A)\\). Are \\(A\\) and \\(B\\) independent?\nBased on the two completely overlapping events, calculate the conditional probability \\(P(A|B)\\) and compare it with \\(P(A)\\). Are \\(A\\) and \\(B\\) independent?\n\n\n\n6.3.2 product rule\nThe definition of independence is abstract, but it has a direct consequence of great computational value. From the definition of conditional probability, \\(P(A|B) = P(A\\cap B)/P(B)\\), and if \\(A\\) and \\(B\\) are independent then \\(P(A|B)\\) can be replaced with \\(P(A)\\), leading to the expression \\(P(A) = P(A\\& B)/P(B)\\). Multiplying both sides by \\(P(B\\)) gives us the formula called the product rule, which states that for two independent events the probability of both of them occuring is the product of their separate probabilities:\n\\[\nP(A \\& B) = P(B)P(A)\n\\]\nThe product rule is extremely useful for computing probability distributions of complicated random variables. Recall that the binomial distribution, which we saw in section \\(\\ref{sec:math4_2}\\) is based on a string of \\(n\\) Bernoulli trials which are independent of each other, which allows the calculation of the probability of a string of successes and failures, or heads/tails, etc. In practice, independence between processes is rarely true in the idealized mathematical sense. However, computing the probability of two random variables without independence is extremely difficult, so it is useful to make the independence assumption and then test it against the data. If it stands up, you have a good predictive model, and if it does not, you have learned that two processes are somehow linked, which is very useful."
  },
  {
    "objectID": "independence.html#independence-of-variables",
    "href": "independence.html#independence-of-variables",
    "title": "6  Independence",
    "section": "6.4 Independence of variables",
    "text": "6.4 Independence of variables\nThe product rule enables us to extend the notion of independence from events to variables. The concepts of independence is the same in both contexts, since the probability of a value \\(x\\) of a random variable \\(X\\) corresponds to the probability of the event that gets mapped to \\(x\\) by the variable. In order to make independence applicable to variables, the condition must hold true for all possible values of both random variables. That way, knowing the value of one variable has no effect on the probability of the other. In order to make it simpler to calculate, we will use the product rule as the equivalent condition for independence:\n\n\n\n\n\n\nDefinition\n\n\n\nTwo random variables \\(X\\) and \\(Y\\) are independent if for all possible values of \\(X\\) and \\(Y\\) it is true that \\[ P(X=a \\& Y=b) = P(X=a)P(Y=b)\\]\n\n\nThis allows us to address the question posed at the beginning of the chapter: how can one determine whether a data set has independent variables? The definition allows us to calculate what we would expect if the variables were independent. Given a data set in the form of a contingency table, such as table \\(\\ref{tab:data_table_DS_age}\\), we can first calculate the probabilities of the two variables separately, and then from that predict the probabilities of the two variables together.\nExample. Let us calculate the expected probabilities and frequencies of Down’s syndrome in pregnant women in the two age categories. First, compute the probabilities of having Down’s syndrome (and not having it), based on all the pregnancies in the data set: \\(P(DS) = 92/38033 \\approx 0.002419\\); the complementary probability is \\(P(no \\ DS) = 1 - P(DS)\\). Similarly, we can calculate the probability that a pregnant woman is 35 or over, based on the entire data set (let’s denote this event \\(MA\\) for mature age). \\(P(MA) = 8199/38033 \\approx 0.21558\\); the complementary probability is \\(P(YA) = 1 - P(MA)\\) (\\(YA\\) stands for young age).\nThese separate probabilities were calculated from the data, and now we can use them to calculate the predicted probabilities of different outcome, based on the assumption of independence. The probability of a mature-age woman having a pregnancy with Down’s syndrome, based on the product rule is \\(P(MA \\& DS) \\approx 0.0024 \\times 0.216 = 0.000518\\). Similarly, we can calculate the probabilities of the other three outcomes: $P(YA & DS) $; \\(P(MA \\& no \\ DS) \\approx 0.2156\\); \\(P(YA \\& no \\ DS) \\approx 0.782\\).\nThese probabilities are the predictions based on the assumption that the two variables are independent. To compare the predictions with the data, we need to take one more step: convert the probabilities into counts, or frequencies of each occurrence. Since the probability is a fraction out of all outcomes, to generate the predicted frequency we need to multiply the probability by the total number of data points, in this case pregnant patients. The results of this calculation are seen in table \\(\\ref{tab:exp_table_DS_age}\\) with expected frequencies shown instead of experimental observations.\n\n\n\nMaternal age\nNo DS\nDS\nTotal\n\n\n\n\n< 35\n29,761.8\n72.2\n29,834\n\n\n>= 35\n8,179.2\n19.8\n8,199\n\n\nTotal\n37,941\n92\n38,033\n\n\n\nExpected frequencies of Down’s syndrome for two different age groups of mothers, assuming that age and Down’s syndrome are independent.\nNotice that expected frequencies do not need to be integers, because they are the result of prediction and not a data measurement. Now that we have a prediction, we can compare it with the measurements in the data table \\(\\ref{tab:data_table_DS_age}\\). The numbers are substantially different, and we can see that the predicted frequency of Down’s syndrome for women under 35 is larger than the frequencies for women at or above 35, due to the larger fraction of patients in the younger age group. We can calculate the differences between the observed and expected contingency tables to measure how much reality differs from the assumption of independence:\n\n\n\nMaternal age\nNo DS\nDS\nTotal\n\n\n\n\n< 35\n44.2\n-44.2\n29,834\n\n\n>= 35\n-44.2\n44.2\n8,199\n\n\nTotal\n37,941\n92\n38,033\n\n\n\nDifferences between the observed frequencies of Down’s syndrome for different maternal ages and the expected frequencies based on the assumption of independence.\nThe table of differences shows that the observed frequency of DS in the data set are higher than expected by 44.2 for women above 35 years of age and is lower than expected by the same number for women below age 35. This demonstrates that mathematically speaking, the two variables of age and DS are not independent.\nHowever, real data is messy and subject to randomness of various provenance. First, there is sampling error that we explored in chapter 9, which means that samples from two perfectly independent variables can and will differ from expected frequencies. Second, measurement errors or environmental noise can contribute more randomness to the data. Thus, simply checking that observed frequencies are different from expected is not enough to conclude that the variables are not independent. We need a method to decide what scale of differences is enough to declare that there is an effect e.g. of maternal age on the likelihood of DS. To do this, we leave the cozy theoretical confines of probability and venture into the wild and treacherous world of statistics."
  },
  {
    "objectID": "bayes.html#prior-knowledge",
    "href": "bayes.html#prior-knowledge",
    "title": "7  Prior knowledge and Bayesian thinking",
    "section": "7.1 Prior knowledge",
    "text": "7.1 Prior knowledge\n\nSuppose that a patient walks into a doctor’s office, the doctor orders a pregnancy test, and the results indicate that the patient is pregnant. The doctor consults the published sensitivity and specificity values (that we defined in the last chapter) to discover, for instance, that 99% of positive pregnancy tests are correct. The doctor goes back to congratulate the patient with impending motherhood. Sound very reasonable, doesn’t it? Would it still sound reasonable if the doctor knew that the patient does not have a uterus (whatever their gender may be)?\nThis is a slightly absurd example, of course, but it neatly illustrates the central point of this chapter: prior knowledge has an effect on the inference from a test, no matter how small or large the p-value and the power of the test. For a patient with no uterus, their prior probability of being pregnant is 0, and that is not changed by a test, no matter how accurate (of course, no test is 100% accurate). In this case, the positive pregnancy test must have been a false positive, even though it’s unlikely, since the other possibility - that of a true positive - is impossible.\nWe all consider prior knowledge before coming to a conclusion. For instance, the credibility of a statement from a person very much depends on past performance: if the person is a habitual liar, you probably wouldn’t put much stock in his or her words. On the other hand, if a person is known to be trustworthy, you might take their statement seriously even if it surprising. If your significant other has always been transparent and honest, even if you discover a suspiciously sexy message from someone else on his/her phone, you will listen to their explanation and consider alternative explanations, in other words, that this was a false positive. If they had abused your trust in the past, it’s much more likely that this sexy text is actual evidence of cheating, and maybe it’s time to cut them loose!\nIn the context of science, the accumulation of knowledge is the basis of building scientific theories. Nothing in science is ever proven, unlike in mathematics, instead different statements have different degrees of certainty based on past experience. A theory that has been tested for years, is considered to have a very high likelihood and may even be called a Law of nature, like Newton’s laws in physics. If experimental data came along that challenged Newton’s Law of gravitational attraction (as Einstein’s relativity did) scientists would rightfully treat it much more skeptically than an experiment that agrees with prior experience. Carl Sagan summarized the effect of prior knowledge of evaluating evidence with the pithy phrase “extraordinary claims require extraordinary evidence” - that is, a claim that is highly unlikely based on past knowledge must be backed up by very strong data.\n\n\n\nA cartoon about interpretation of results of an experiment with a known error rate https://xkcd.com/1132/\n\n\nThe perils of ignoring prior knowledge is illustrated in the xkcd cartoon shown in figure \\(\\ref{fig:xkcd_bayes}\\). In this case, the “solar detector” lies (makes an error) with probability 1/36, so when it tells you that the sun exploded, it has only 1/36 probability that it made a false positive error. However, based on our prior knowledge, the sun is extremely unlikely to blow up or disappear, so the alternative that the sun exploded and the detector is correct is even less likely. Although the cartoon portrays this as a disagreement between frequentists and Bayesians, it is more properly understood as a disagreement between mindless application of frequentist thought and everyone else."
  },
  {
    "objectID": "bayes.html#bayes-formula",
    "href": "bayes.html#bayes-formula",
    "title": "7  Prior knowledge and Bayesian thinking",
    "section": "7.2 Bayes’ formula",
    "text": "7.2 Bayes’ formula\n\nIn this section we will formalize the process of incorporation of prior knowledge into probabilistic inference by going back to the notion of conditional probability in section \\(\\ref{sec:math6_1}\\). First, if you multiply both sides of the definition by \\(P(B)\\), then we obtain the probability of the intersection of events \\(A\\) and \\(B\\): \\[P(A \\& B) = P(A|B) P(B); \\;  P(A \\& B) = P(B|A) P(A) \\] Second, we can partition a sample space into two complementary sets, \\(A\\) and \\(-A\\), and then the set of \\(B\\) can be partitioned into two parts, that intersect with \\(A\\) and \\(-A\\), respectively, so that the probability of \\(B\\) is \\[P(B) = P(A \\& B) + P(-A\\& B)\\]\nThe two formulas together lead to a very important result called the law of total probability \\[\nP(B) =  P(B|A) P(A) + P(B|-A)P(-A)\n\\]\nIt may not be clear at first glance why this is useful: after all, we replaced something simple (\\(P(B)\\)) with something much more complex on the right hand side. You will see how this formula enables us to calculate quantities that are not otherwise accessible.\nExample: probability of a negative test result. Suppose we know that the probability of a patient having a disease is 1% (called the prevalence of the disease in a population), and the sensitivity and specificity of the test are both 80%. What is the probability of obtaining a negative test result for a randomly selected patient? Let us call \\(P(H) = 0.99\\) the probability of a healthy patient and \\(P(D) = 0.01\\) the probability of a diseased patient. Then:\n\\[ P(Neg) =  P(Neg | H) P(H) + P(Neg | D)P(D)  = \\] \\[ = 0.8 \\times 0.99 + 0.2 \\times 0.01 = 0.794\\]\nThere is still more gold in the hills of conditional probability! Take the first formula in this section, which expresses the probability \\(P(A \\& B)\\) in two different ways. Since the expressions are equal, we can combine them into one equation, and by dividing both sides by \\(P(B)\\), we obtain what’s known as Bayes’ formula: \\[ P(A|B) = \\frac{P(B|A) P(A)}{P(B) }\\]\nWe can rewrite the denominator in Bayes’ using the Law of total probability so that it can calculated from conditional probabilities:\n\\[\nP(A|B) = \\frac{P(B|A)P(A)}{P(B|A) P(A) + P(B|-A)P(-A)}\n\\]\nBayes’ formula gives us the probability of \\(A\\) given \\(B\\) from probabilities of \\(B\\) given \\(A\\) and given \\(-A\\), and the prior (baseline) probability of \\(P(A)\\). This is enormously useful when it is easy to calculate the conditionals one way and not the other. Among its many applications, it computes the effect of a test result with given sensitivity and specificity (conditional probabilities) on the probability of the hypothesis being true.\n\n7.2.1 positive and negative predictive values\nIn reality, a doctor doesn’t have the true information about the patient’s health, but rather the information from the test and hopefully some information about the population where she is working. Let us assume we know the rate of false positives \\(P(Pos | H\\)) and the rate of false negatives \\(P(Neg | D)\\), as well as the prevalence of the disease in the whole population \\(P(D)\\). Then we can use Bayes’ formula to answer the practical question, if the test result is positive, what is the probability the patient is actually sick? This is called the positive predictive value of a test. The deep Bayesian fact is that one cannot make inferences about the health of the patient after the test without some prior knowledge, specifically the prevalence of the disease in the population:\n\\[ P(D | Pos) =  \\frac{P(Pos|D)P(D)}{P(Pos|D) P(D) + P(Pos | H)P(H)}\\]\nExample. Suppose the test has a 0.01 probability of both false positive and false negatives, and the overall prevalence of the disease in the population 0.02. You may be surprised that from an epidemiological perspective, a positive result is far from definitive:\n\\[ P(D | Pos)  = \\frac{0.99 \\times 0.02}{0.99 \\times 0.02 + 0.01 \\times 0.98} = 0.67 \\]\nThis is because the disease is so rare, that even though the test is quite accurate, there are going to be a lot of false positives (about 1/3 of the time) since 98% of the patients are healthy.\nWe can also calculate the probability of a patient who tests negative of actually being healthy, which is called the negative predictive value. In this example, it is far more definitive:\n\\[ P(H | Neg)  = \\frac{P(Neg|H)P(H)}{P(Neg|H) P(H) + P(Neg | D)P(D)} = \\] \\[ = \\frac{0.99 \\times 0.98}{0.99 \\times 0.98 + 0.01 \\times 0.02} =  0.9998\\]\nThis is again because this disease is quite rare in this population, so a negative test result is almost guaranteed to be correct. In another population, where disease is more prevalent, this may not be the case.\nFigure \\(\\ref{fig:ch7_testing_tree}\\) illustrates all of the possibilities of a binary medical test: positive (P) or negative (N) for a patient who is either healthy (H) or diseased (D). The four outcomes correspond to the four outcomes of tests we saw in section \\(\\ref{sec:bio6}\\): true positives are D&P, false positives are H&P, true negatives are H&N and false negatives are D&N. This allows us to calculate the positive predictive value, which is the probability that a positive result is correct. For the patient with disease prevalence of 0.1, \\(PPV = TP/(TP+FP) = 0.098/(0.098+0.045) \\approx 0.685\\). For the patient with disease prevalence of 0.01, \\(PPV = TP/(TP+FP) = 0.0098/(0.0098+0.0495) \\approx 0.165\\). The exact same test has a higher PPV for a patient who has a higher prior probability of having a disease.\nThe negative predictive value can be calculated in a similar manner for the patient with disease prevalence of 0.1: \\(NPV = TN/(TN+FN) = 0.855/(0.855+0.002) \\approx 0.998\\). For the patient with disease prevalence of 0.01, \\(NPV = TN/(TN+FN) = 0.9405/(0.9405+0.0002) \\approx 0.9998\\). The exact same test has a higher NPV for a patient who has a lower prior probability of having a disease.\n\n\n\nProbabilities of the four possible outcomes for patients with different disease prevalence using the same medical test with sensitivity (rate of true positives) of 0.98 and specificity (rate of true negatives) of 0.95: above for disease prevalence of 10%.\n\n\n\n\n\nProbabilities of the four possible outcomes for patients with different disease prevalence using the same medical test with sensitivity (rate of true positives) of 0.98 and specificity (rate of true negatives) of 0.95: above for disease prevalence of 1%\n\n\n\n\n7.2.2 Exercises\nThe table below shows the results of using X-ray imaging as a diagnostic test for tuberculosis in patients with known TB status. Use it to answer the questions below.\n\n\n\nTest for TB\nTB absent\nTB present\n\n\n\n\nNegative\n1739\n8\n\n\nPositive\n51\n22\n\n\n\nUse this table to calculate the sensitivity and specificity of the test. Suppose that you have the knowledge that the prevalence of TB in a population is P(D) = 0.001, use the previously calculated sensitivity and specificity to answer the following questions about testing a patient from the population (not those used in the study in the table.)\n\nUsing the law of total probability, calculate P(Pos), the probability that a randomly chosen person from the population tests positive for the disease and P(Neg), the probability that a randomly chosen person tests negative for the disease.\nUsing Bayes’ formula, find the probability that a patient who tested positive has the disease P(D | Pos) and the probability that a patient who tested negative is healthy P(H | Neg).\nIf the disease prevalence were P(D) =0.5, repeat the calculations to find the new P(D | Pos) and P(H | Neg).\n\nDating apps allow us to look a person’s profile (or picture) and decide whether we’d like to date them (swipe right) or not (swipe left). Let us treat this like a hypothesis test, with the null hypothesis being that you don’t want to date them. Then the swipe right decision is a positive result (rejecting the null) and the swipe left decision is a negative result (not rejecting the null).\nSuppose you think you’re pretty good at deciding who you want to date, and you think that your sensitivity is 80% and your specificity is 66%.\n\nIf you go through the profiles of 200 people in a population where you expect 25% of the population to be dateable, how many times can you expect to swipe right? Hint: multiply the probability by the number of people to find out the expected number of swipes.\nIf instead the population had only 5% dateable individuals, how many times can you expect to swipe right?\nSuppose you swipe right on a person from the 25% dateable population and go on a date. What’s the probability that it’s a good one (this is a person you actually want to date)?\nSuppose you swipe right on a person from the 5% dateable population and go on a date. What’s the probability that it’s a good one (this is a person you actually want to date)?"
  },
  {
    "objectID": "bayes.html#applications-of-bayesian-thinking",
    "href": "bayes.html#applications-of-bayesian-thinking",
    "title": "7  Prior knowledge and Bayesian thinking",
    "section": "7.3 Applications of Bayesian thinking",
    "text": "7.3 Applications of Bayesian thinking\n\nThe essence of the Bayesian approach to statistics is that everything comes with a prior probability, or odds, as Bayesians like to express it. There is usually some prior knowledge one has to assess the odds that a hypothesis is true before doing an experiment, which is called the prior. If you don’t explicitly assume the prior, then you’ve assumed it implicitly. For example, the naive answer for the positive predictive value that ignores the prior prevalence for a test with 99% specificity and sensitivity is that it is also 99%. This assumes that the patient has equal prior probability of disease and health, as you can verify using Bayes’ formula. Even in the absence of any data for a particular population, this is an unlikely assumption for most diseases. So the Bayesian advice is: assign odds to everything to the best of your knowledge so you don’t get played for a sucker. An excellent summary of the misuses of p-value and the Bayesian approach to interpretation of medical data, see .\n\n7.3.1 when too much testing is bad\nFor many decades, doctors recommended early cancer screening in a major public health effort to help reduce the mortality rate from cancer. This makes sense because the prognosis is generally much better for cancer when it is detected early, since the tumor is small and has not yet metastasized. This approach has taken hold in the public imagination in the US, and given us pink-ribbon campaigns aimed at breast cancer awareness and celebrities advising everyone to get tested early and often.\nMore recently, large-scale studies have shown that that preventative screenings do not necessarily improve the survival rate of cancer patients. One study from Canada assigned almost 90,000 women randomly into two equal-size groups, by a randomization process illustrated in figure \\(\\ref{fig:mammography_screening}\\). One of the groups received yearly mammography screenings for 5 years and one did not. The women were between the ages of 40 and 59, and then study then tracked the participants for 25 years to see whether there was a difference in cancer mortality rates between the two groups.\n\n\n\nThe study design for the large randomized screening trial of effectiveness of mammography screening; figure from used by permission\n\n\nThe results may be surprising: the mortality rates were very similar, and in fact, slightly more women died of breast cancer in the mammography group than in the control group (180 vs 171). At the same time, more cases of invasive breast cancers were diagnosed in the mammography group, which may mean either that early treatment did not make a difference or that many of those cases were false positives.\nThis may seem counterintuitive: isn’t more information, however imperfect, better? Viewed from a Bayesian perspective, the results should be less than surprising. Since the prior probability of developing breast cancer in any given year is small, the positive predictive value of the test is likely low, and most of the positive results end up being false positives. A false positive result for breast cancer has a major negative impact on a person’s life: it means more invasive testing, a lot of worrying, and sometimes unnecessary treatment with serious side effects. This does not mean, of course, that cancer screening is never useful, and I am not trying to offer medical advice. For patient populations with a higher prior probability such screening tests may in fact provide a substantial benefit. But this once again underscores the importance of taking into account prior knowledge.\n\n\n\nIllustration of the different results of mammography screening on 10000 women\n\n\n\n\n7.3.2 reliability of scientific studies\nIn 2005 John Ioannidis published a paper entitled “Why most published research findings are wrong” . The paper, as you can see by its title, was intended to be provocative, but it is based solidly on the classic formula of Bayes. The motivation for the paper came from the observation that too often in modern science, big, splashy studies that were published could not be reproduced or verified by other researchers. What could be behind this epidemic of questionable scientific work?\n\n\n\nThe dependence of post-study probability (positive predictive value) on the pre-study odds, for different power of the study, and with different levels of bias; (figure from )\n\n\nThe problem as described by Ioannidis and many others, in a nutshell, is that unthinking use of traditional hypothesis testing leads to a high probability of false positive results being published. The paper outlines several ways in which this can occur.\nFirst, there is the problem of prior knowledge. Too often, a hypothesis is tested and if the resultant p-value is less than some arbitrary threshold (very often 0.05, an absurdly high number), then the results are published. However, if one is testing a hypothesis with low prior probability, a positive hypothesis test result is very likely a false positive. Very often, modern biomedical research involves digging through a large amount of information, like an entire human genome, in search for associations between different genes and a phenotype, like a disease. It is a priori unlikely that any specific gene is linked to a given phenotype, because most genes have very specific functions, and are expressed quite selectively, only at specific times or in specific types of cells. However, publishing such studies results in splashy headlines (’’Scientists find a gene linked to autism!“) and so a lot of false positive results are reported, only to be refuted later, in much less publicized studies.\nThe second problem compounds the first one: multiple research groups studying the same phenomenon. This should be a good thing, but it can lead to a higher volume of false positive results. Suppose that 20 groups are all testing the same hypothesis, and are using the same p-value cutoff of 0.05 to decide whether their results is “significant”. Even if their null hypothesis is true, and there is no effect, 1 out 20 groups is likely to obtain a p-value less than 0.05, simply by random variation. What do you think that group will do? Yes, they should compare its results with the other groups, or try to repeat the experiment multiple times. But repeating experiments is costly and boring, and telling your competitors about your results can lead to your getting scooped. Better publish fast!\nThe third problem is even more insidious: bias in the experimental work, either conscious or non. Some of it may be due to experimental design, like biased sampling, or defective instrumentation - no experiment is perfect. One big violation of good experimental design is known as p-value fishing: repeating the experiment, or increasing the sample size, until the p-value is below the desired threshold, and then stopping the experiment. Using such defective design dramatically lowers the likelihood that the result is a true positive. And of course there is actual fraud, or fudging of data, which contributes to some bogus results.\nIoannidis performed basic calculations of the probability that a published study is true (that is, that a positive reported result is a true positive), and how it is affected by pre-study (prior) probability, number of conducted studies on the same hypothesis, and the level of bias. His prediction is that for fairly typical scenario (e.g. pre-study probability of 10%, ten groups working simultaneously, and a reasonable amount of bias) the probability that a published result is correct is less than 50%. This effect is shown in figure \\(\\ref{fig:ioannidis_bayes}\\), taken from his paper. He then followed up with another paper that investigated 49 top-cited medical research publications over a decade, and looked at whether follow-up studies could replicate the results, and found that a very significant fraction of their findings could not be replicated by subsequent investigations.\nThis might leave you with a rather bleak view of scientific research. Indeed, many in the community have been sounding the alarm about the lack of replicability of published results, and have proposed some basic remedies. Perhaps the most important is the issue that only positive results are deemed worthy of publication. If all of the 20 groups in the scenario above published their results, 19 would report no effect, and 1 would report an effect, and the picture would be clear. There are some journals (e.g. PLOS One) which accept any methodologically sound submission, regardless of whether the result is positive or negative. Another remedy is to provide funding for research labs to repeat other groups’ studies to test them. These steps are being implemented, and hopefully will eventually lead to an improvement in the reliability of published data. Even more importantly, educating scientists about basic probability ideas, such as Bayes’ formula and the notion of prior knowledge, should improve the quality of inference and decrease the amount of questionable science.\n\n\n7.3.3 discussion questions\nThe following questions refer to the paper “Why most published research findings are wrong” .\n\nWhat are some of the examples of studies with low prior odds that Ioannidis uses as examples?\nDue to human imperfection, there will always be some bias in conducting and reporting scientific results. What do you expect to be the typical level of bias (u in the paper)?\nWhat does Ioannidis propose to remedy the problem of lack of reproducibility of studies? Will you take them into account when reading scientific publications or doing your own research?"
  },
  {
    "objectID": "graph_odes.html#building-differential-equations",
    "href": "graph_odes.html#building-differential-equations",
    "title": "10  Graphical analysis of ordinary differential equations",
    "section": "10.1 Building differential equations",
    "text": "10.1 Building differential equations\n\n\n10.1.1 from discrete time to continuous\nIn this chapter we investigate continuous time dynamical systems, for which it does not make sense to break time up into equal intervals. Instead of equations describing the increments in the dependent variable from one time step to the next, we will see equations with the instantaneous rate of the change (derivative) of the variable. Let us see the connection between the discrete and continuous dynamic models by reducing the step size of the bacteria-division population model.\nFirst, suppose that instead of dividing every hour, the population of bacteria divide every half-hour, but only half of the population does. That half is chosen randomly, so we don’t have to keep track of whether each bacterium divided the last time around or not. Therefore, each half-hour exactly half of the population is added to the current population: \\[ N(t+0.5) = N(t) + 0.5N(t) = 1.5N(t)\\] The solution for this model can be figured out from the linear difference equation solution we derived in section \\(\\ref{sec:math14}\\) Every half-hour, the population is multiplied by 1.5, so we can write: \\[ N(t) = 1.5^{2t} N(0) = (1.5^2)^t N(0)\\] Compare this solution with the one for the every-hour model, \\(N(t) = 2^t N(0)\\) by plugging in a few numbers for \\(t\\). The half-hour model grows faster, because it has the base of 2.25 instead of 2.\nNow, suppose that the bacteria can divide four times an hour, but only a quarter of the population reproduces at any given time. The model can be written similarly: \\[N(t+0.25) = N(t) + 0.25N(t) = 1.25N(t)\\] The solution for this model is once again exponential, with the difference that each half contains 4 division events: \\[N(t) = 1.25^{4t}N(0) = (1.25^4)^t N(0)\\] This solution has the exponential base is \\(1.25^4\\), which is larger than \\(1.5^2\\). So what happens when we take this further?\nSuppose the bacteria divide \\(m\\) times an hour, with time step \\(1/m\\). Then extending our models above, we can write down the model and the solution: \\[ N(t + 1/m) = N(t) + 1/m N(t) = (1+1/m) N(t) \\] \\[ N(t) = (1+1/m)^{mt} N(0) = [(1+1/m)^m]^t N(0)\\]\nNow we can do what mathematicians enjoy the most: take things to the limit. What if \\(m\\) were 100? A million? A gazillion? Let us re-write the model equation: \\[ N(t+1/m) - N(t) = 1/m N(t) \\Rightarrow \\frac{N(t+1/m) - N(t) }{1/m} = N(t)\\]\nThe expression on the left is known as Newton’s quotient that you encounter in the definition of a derivative. It measures the rate of change of the population \\(N\\) from some time \\(t\\) to the next time step \\(t+1/m\\). If \\(m\\) is increased to make the time step smaller, this makes both the numerator and the denominator smaller, and the quotient approaches the instantaneous rate of change of \\(N(t)\\). So, if bacteria divide at any point in time, with the , the model becomes a differential equation: \\[ \\frac{dN}{dt} = N(t)\\]\nWe can do a similar procedure to the formula of the solution of the model. The dependence on \\(m\\) is all on the left-hand side, in the expression \\((1+1/m)^m\\), which is the base of the exponential function. What happens to this number as \\(m\\) becomes larger? Does it increase without bound? You can investigate this numerically by plugging in progressively larger numbers \\(m\\), and see that the number approaches a specific value: 2.71828… This is the special constant \\(e\\), called the base of the natural logarithm. So, if bacteria divide at any point in time, with the average rate of 1 per hour, the solution of the model becomes: \\[ N(t) = e^t N(0)\\]\n\n\n10.1.2 Exercises\nHere we will explore the effect of changing the step size on the solution of a discrete time dynamic model. We will use a very simple model of bacterial population growth, in which we assume that bacteria divide once an hour and there are no deaths.\n\nCalculate the solution for this population, assuming that all bacteria divide exactly once an hour - in other words, a birth rate of one per individual. Starting with one bacterium use a for loop to calculate the solution for 10 hours and print out the last value.\n\n\n# YOUR CODE HERE\n\n\nSuppose that these bacteria can divide twice an hour, but only half of the population divides each time - in other words, a per capita birth rate of 0.5 per half an hour. Change your model so it calculates a solution vector with the time step of 30 minutes over 10 hours, print out the number of bacteria after 10 hours and compare it with the previous value.\n\n\n# YOUR CODE HERE\n\n\nSuppose that these bacteria divide every 15 minutes, but only one quarter of the population divides each time - in other words, a per capita birth rate of 0.25 per quarter hour. Change your model so it calculates a solution vector with the time step of 15 minutes over 10 hours, print out the number of bacteria after 10 hours and compare it with the previous value.\n\n\n# YOUR CODE HERE\n\n\nSuppose that these bacteria divide every 1 minute, but only 1/60 of the population divides each time - in other words, a per capita birth rate of 1/60 per minute. Change your model so it calculates a solution vector with the time step of 1 minute over 10 hours, print out the number of bacteria after 10 hours and compare it with the previous value.\n\n\n# YOUR CODE HERE\n\n\nSuppose that these bacteria divide every second, but only 1/3600 of the population divides each time - in other words, a per capita birth rate of 1/3600 per second. Change your model so it calculates a solution vector with the time step of 1 second over 10 hours, print out the number of bacteria after 10 hours and compare it with the previous value.\n\n\n# YOUR CODE HERE\n\n\nProduce a plot of the five solutions of bacterial population dividing with different time steps. Take the five code chunks from above, and copy them all into the chunk below. For each calculation add a time vector that corresponds to each time step (e.g. one for every hour for the first one, one for every second for the last one) and make a plot of each of the solutions as function of time on the same plot - use plot() for the first one and lines() for all the rest, with different colors and add a legend indicating different time steps.\n\n\n# YOUR CODE HERE\n\nWhat behaviors do you see for the solutions with different time steps? What effect does shrinking the time step have on the solution? What do you expect would happen if the time step were a millisecond, or a microsecond?\n\n\n10.1.3 growth proportional to population size\nWe will now build some common differential equations models. First, a simple population growth model with a constant growth rate. Suppose that in a population each individual reproduces with the average reproductive rate \\(r\\). This is reflected in the following differential equation: \\[\\begin{equation}\n\\frac{d x} {dt} = \\dot x = r x\n\\label{eq:linear_ode}\n\\end{equation}\\] This expression states that the rate of change of \\(x\\), which we take to be population size, is proportional to \\(x\\) with multiplicative constant \\(r\\). We will sometimes use the notation \\(\\dot x\\) for the time derivative of \\(x\\) (which was invented by Newton) for aesthetic reasons.\nFirst, we apply dimensional analysis to this model. The units of the derivative are population per time, as can be deduced from the Newton’s quotient definition. Thus, the units in the equation have the following relationship: \\[ \\frac{[population]}{[time]} = [r] [population] = \\frac{1}{[time]}[population] \\] This shows that as in the discrete time models, the dimension of the population growth rate \\(r\\) is inverse time, or frequency. The difference with the discrete time population models lies in the time scope of the rate. In the case of the difference equation, \\(r\\) is the rate of change per one time step of the model. In the differential equation, \\(r\\) is the instantaneous rate of population growth. It is less intuitive than the growth rate per single reproductive cycle, just like the slope of a curve is less intuitive than the slope of a line. The population growth happens continuously, so the growth rate of \\(r\\) individuals per year does not mean that if we start with one individual, there will be \\(r\\) after one year. In order to make quantitative predictions, we need to find the solution of the equation, which we will see in the next section.\n\n\n10.1.4 chemical kinetics\nReactions between molecules in cells occur continuously, driven by molecular collisions and physical forces. In order to model this complex behavior, it is generally assumed that reactions occur with a particular speed, known as the kinetic rate constant. As mentioned in chapter 2, a simple reaction of conversion from one type of molecule (\\(A\\)) to another (\\(B\\)) can be written as follows: \\[ A \\xrightarrow{k} B \\] In this equation the parameter \\(k\\) is the kinetic rate rate constant, describing the speed of conversion of \\(A\\) into \\(B\\), per concentration of \\(A\\).\nChemists and biochemists use differential equations to describe the change in molecular concentration during a reaction. These equations are known as the laws of mass action. For the reaction above, the concentration of molecule \\(A\\) decreases continuously proportionally to itself, and the concentration of molecule \\(B\\) increases continuously proportionally to the concentration of \\(A\\). This is expressed by the following two differential equations: \\[\\begin{eqnarray}\n\\label{eq:lin_chem_kin}\n\\dot A &=& - k A \\\\\n\\dot B &=& kA\n\\end{eqnarray}\\]\nSeveral conclusions are apparent by inspection of the equations. First, the dynamics depend only on the concentration of \\(A\\), so keeping track of the concentration of \\(B\\) is superfluous. The second observation reinforces the first: the sum of the concentrations of \\(A\\) and \\(B\\) is constant. This is mathematically demonstrated by adding the two equations together to obtain the following: \\[ \\dot A + \\dot B = -kA + kA = 0\\] One of the basic properties of the derivative is that the sum of derivatives is the same as the derivative of the sum: \\[\\dot A + \\dot B = \\frac{d(A+B)}{dt} = 0\\]\nThis means that the sum of the concentrations of \\(A\\) and \\(B\\) is a constant. This is a mathematical expression of the law of conservation in chemistry: molecules can change from one type to another, but they cannot appear or disappear in other ways. In this case, a single molecule of \\(A\\) becomes a single molecule of \\(B\\), so it follows that the sum of the two has to remain the same. If the reaction were instead two molecules of \\(A\\) converting to a molecule of \\(B\\), then the conserved quantity is \\(2A + B\\). The concept of conserved quantity is very useful for the analysis of differential equations. We will see in later chapters how it can help us find solutions, and explain the behavior of complex dynamical systems.\n\n\n10.1.5 building nonlinear ODEs\n\nThe simple, linear population growth models we have seen in the last two chapters assume that the per capita birth and death rates are constant, that is, they stay the same regardless of population size. The solutions for these models either grow or decay exponentially, but in reality, populations do not grow without bounds. It is generally true that the larger a population grows, the more scarce the resources, and survival becomes more difficult. For larger populations, this could lead to higher death rates, or lower birth rates, or both.\nHow can we incorporate this effect into a quantitative model? We will assume there are separate birth and death rates, and that the birth rate declines as the population grows, while the death rate increases. Suppose there are inherent birth rates \\(b\\) and \\(d\\), and the overall birth and death rates \\(B\\) and \\(D\\) depend linearly on population size \\(P\\): \\(B = b - aP\\) and \\(D = d + cP\\).\nTo model the rate of change of the population, we need to multiply the rates \\(B\\) and \\(D\\) by the population size \\(P\\), since each individual can reproduce or die. Also, since the death rate \\(D\\) decreases the population, we need to put a negative sign on it. The resulting model is: \\[ \\dot P = BP - DP = [(b-d)-(a+c)P]P \\]\nThe parameters of the model, the constants \\(a,b,c,d\\), have different meanings. Performing dimensional analysis, we find that \\(b\\) and \\(d\\) have the dimensions of \\(1/[t]\\), the same as the rate \\(r\\) in the exponential growth model. However, the dimensions of \\(a\\) (and \\(c\\)) must obey the relation: \\([P]/[t] = [a][P]^2\\), and thus,\n\\[[a]=[c] = \\frac{1}{[t][P]}\\]\nThis shows that the constants \\(a\\) and \\(c\\) have to be treated differently than \\(b\\) and \\(d\\). Let us define the inherent growth rate of the population, to be \\(r_0=b-d\\) (if the death rate is greater than the birth rate, the population will inherently decline). Then let us introduce another constant \\(K\\), such that \\((a+c)=r_0/K\\). It should be clear from the dimensional analysis that \\(K\\) has units of \\(P\\), population size. Now we can write down the logistic equation in the canonical form: \\[\\begin{equation}\n\\dot P = r\\left(1-\\frac{P}{K}\\right)P\n\\label{eq:log_cont_model}\n\\end{equation}\\] This model can be re-written as \\(\\dot P = aP -bP^2\\), so it is clear that there is a linear term (\\(aP\\)) and a nonlinear term (\\(-bP^2\\)). When \\(P\\) is sufficiently small (and positive) the linear term is greater, and the population grows. When \\(P\\) is large enough, the nonlinear term wins and the population declines. \nIt should be apparent that there are two fixed points, at \\(P=0\\) and at \\(P=K\\). The first one corresponds to a population with no individuals. On the other hand, \\(K\\) signifies the population at which the negative effect of population size balances out the inherent population growth rate, and is called the carrying capacity of a population in its environment . We will analyze the qualitative behavior of the solution, without writing it down, in the next section of this chapter."
  },
  {
    "objectID": "graph_odes.html#qualitative-analysis-of-odes",
    "href": "graph_odes.html#qualitative-analysis-of-odes",
    "title": "10  Graphical analysis of ordinary differential equations",
    "section": "10.2 Qualitative analysis of ODEs",
    "text": "10.2 Qualitative analysis of ODEs\n\nIn this section we will analyze the behavior of solutions of an autonomous ODE without solving it on paper. Generally, ODE models for realistic biological systems are nonlinear, and most nonlinear differential equations cannot be solved analytically. We can make predictions about the behavior, or dynamics of solutions by considering the properties of the defining function, which is the function on the right-hand-side of a general autonomous ODE: \\[ \\frac{dx}{dt} = f(x)\\]\n\n10.2.1 graphical analysis of the defining function\nThe defining function relates the value of the solution variable \\(x\\) to its rate of change \\(dx/dt\\). For different values of \\(x\\), the rate of change of \\(x(t)\\) is different, and it is defined by the function \\(f(x)\\). There are only three options:\n\nif \\(f(x) > 0\\), \\(x(t)\\) is increasing at that value of \\(x\\)\nif \\(f(x) < 0\\), \\(x(t)\\) is decreasing at that value of \\(x\\)\nif \\(f(x) = 0\\), \\(x(t)\\) is not changing that value of \\(x\\)\n\nTo determine for which values of \\(x\\) the solution \\(x(t)\\) increases and decreases, it enough to look at the plot of \\(f(x)\\). On the intervals where the graph of \\(f(x)\\) is above the \\(x\\)-axis \\(x(t)\\) increases, on the intervals where the graph of \\(f(x)\\) is below the \\(x\\)-axis, \\(x(t)\\) decreases. The roots (zeros) of \\(f(x)\\) are special cases, they separate the range of \\(x\\) into the intervals where the solution grows and and where it decreases. This seems exceedingly simple, and it is, but it provides specific information about \\(x(t)\\), without knowing how to write down its formula.\nFor an autonomous ODE with one dependent variable, the direction of the rate of change prescribed by the differential equation can be graphically represented by sketching the flow on the line of the dependent variable. The flow stands for the direction of change at every point, specifically increasing, decreasing, or not changing. The flow is plotted on the horizontal x-axis, so if \\(x\\) is increasing, the flow will be indicated by a rightward arrow, and if it is decreasing, the flow will point to the left. The fixed points separate the regions of increasing (rightward) flow and decreasing (leftward) flow.\n\n\n\n\n\na) plot of the defining function of the ODE dx/dt = 4x-100 with direction of flow x(t) indicated with arrows on the x-axis; b) plot of solutions x(t) of the ODE staring with four initial values.\n\n\n\n\n\n\n\na) plot of the defining function of the ODE dx/dt = 4x-100 with direction of flow x(t) indicated with arrows on the x-axis; b) plot of solutions x(t) of the ODE staring with four initial values.\n\n\n\n\nExample. Consider a linear ODE the likes of which we have solved in section \\(\\ref{sec:math15}\\): \\[\\frac{dx}{dt} = 4x -100\\] The defining function is a straight line vs. \\(x\\), its graph is shown in figure \\(\\ref{fig:ch16_flow_linear}\\)a. Based on this graph, we conclude that the solution decreases when \\(x<25\\) and increases when \\(x>25\\). Thus we can sketch the solution \\(x(t)\\) over time, without knowing its functional form. The dynamics depends on the initial value: if \\(x(0)<25\\), the solution will keep decreasing without bound, and go off to negative infinity; if \\(x(0)>25\\), the solution will keep decreasing without bound, and go off to positive infinity. This is shown by plotting numeric solutions of this ODE for several initial values in figure \\(\\ref{fig:ch16_flow_linear}\\)b. The dotted line shows the location of the special value of 25 which separates the interval of growth from the interval of decline.\nExample. Now let us analyze a nonlinear ODE, specifically the logistic model with the following parameters: \\[\\frac{dP}{dt} =0.3P\\left(1-\\frac{P}{40}\\right)\\]\nThe defining function is a downward-facing parabola with two roots at \\(P=0\\) and \\(P=40\\), as shown in figure \\(\\ref{fig:ch16_flow_logistic}\\)a. Between the two roots, the defining function is positive, which means the derivative \\(dP/dt\\) is positive too, so the solution grows on that interval. For \\(P<0\\) and \\(P>40\\), the solution decreases. Therefore, we can sketch the graphs of the solution \\(P(t)\\) starting with different initial conditions, as show in figure \\(\\ref{fig:ch16_flow_logistic}\\)b.\nTo summarize, the defining function of the ODE determines the rate of change of the solution \\(x(t)\\) depending on the value of \\(x\\). The graphical approach to finding areas of right and left flow is based on graphing the function \\(f(x)\\), and dividing the x-axis based on the sign of \\(f(x)\\). In the areas where \\(f(x) > 0\\), its graph is above the x-axis, and the flow is to the right; conversely, when \\(f(x) < 0\\), its graph is below the x-axis, and the flow is to the left. The next subsection puts this approach in a more analytic framework.\n\n\n\n\n\na) plot of the defining function of the ODE \\(dP/dt = 0.3P(1-P/40)\\) with direction of flow of P(t) indicated with arrows on the P-axis; b) plot of solutions P(t) of the ODE staring with three initial values\n\n\n\n\n\n\n\na) plot of the defining function of the ODE \\(dP/dt = 0.3P(1-P/40)\\) with direction of flow of P(t) indicated with arrows on the P-axis; b) plot of solutions P(t) of the ODE staring with three initial values\n\n\n\n\n\n\n10.2.2 fixed points and stability\nWe have seen that the dynamics of solutions of differential equations depend on the initial value of the dependent variable: for some values the solution increases, for others it decreases, and for intermediate values it remains the same. Those special values separating intervals of increase and decrease are called fixed points (or equilibria), and the first step to understanding the dynamics of an ODE is finding its fixed points. A fixed point is a value of the solution at which the dynamical system stays constant, thus, the derivative of the solution must be zero. Here is the formal definition:\n\n\n\n\n\n\nDefinition\n\n\n\nFor an ordinary differential equation \\(\\dot x = f(x)\\), a point \\(x^*\\) which satisfies \\(f(x^*)=0\\) is called a fixed point or equilibrium, and the solution with the initial condition \\(x(0)=x^*\\) is constant over time \\(x(t)=x^*\\).\n\n\nExample. The linear equation \\(\\dot x = rx\\) has a single fixed point at \\(x^* = 0\\). For a more interesting example, consider a logistic equation: \\(\\dot x = x - x^2\\). Its fixed points are the solutions of \\(x - x^2 = 0\\), therefore there two fixed points: \\(x^* = 0, 1\\). We know that if the solution has either of the fixed points as the initial condition, it will remain at that value for all time.\nLocating the fixed points is not sufficient to predict the global behavior of the dynamical system, however. What happens to the solution of a dynamical system if the initial condition is very close to an equilibrium, but not precisely at it? Put another way, what happens if the equilibrium is perturbed? The solution may be attracted to the equilibrium value, that is, it approaches it ever-closer, or else it is not. In the first case, this is called a stable equilibrium, because a small perturbation does not dramatically change the long-term behavior of the solution. In the latter case, the equilibrium is called unstable, and the solution perturbed from the equilibrium never returns. These concepts are formalized in the following definition\n\n\n\n\n\n\nDefinition\n\n\n\nA fixed point \\(x^*\\) of an ODE \\(\\dot x = f(x)\\) is called a stable fixed point (or sink) if for a sufficiently small number \\(\\epsilon\\), the solution \\(x(t)\\) with the initial condition \\(x_0 = x^* + \\epsilon\\) approaches the fixed point \\(x^*\\) as \\(t \\rightarrow \\infty\\). If the solution \\(x(t)\\) does not approach \\(x^*\\) for all nonzero \\(\\epsilon\\), the fixed point is called an unstable fixed point (or source).\n\n\nTo determine whether a fixed point is stable analytically we use the approach called linearization, which involves replacing the function \\(f(x)\\) with a linear approximation. Let us define \\(\\epsilon(t)\\) to be the deviation of the solution \\(x(t)\\) from the fixed point \\(x^*\\), so we can write \\(x(t) = x^* + \\epsilon(t)\\). Assuming that \\(\\epsilon(t)\\) is small, we can write the function \\(f(x)\\) using Taylor’s formula: \\[ f(x^*+\\epsilon(t))= f(x^*)+f'(x^*) \\epsilon(t) + ... = f'(x^*) \\epsilon(t) + ... \\]\nThe term \\(f(x^*)\\) vanished because it is zero by definition \\(\\ref{def:ch16_fixedpt}\\) of a fixed point. The ellipsis indicates all the terms of order \\(\\epsilon(t)^2\\) and higher, which are very small if \\(\\epsilon(t)\\) is small, and thus can be neglected. Thus, we can write the following approximation to the ODE \\(\\dot x = f(x)\\) near a fixed point:\n\\[ \\dot x =  \\frac{d(x^* + \\epsilon(t))}{dt} = \\dot \\epsilon(t) =  f'(x^*) \\epsilon(t)\\]\nThus we replaced the complicated nonlinear ODE near a fixed point with a linear equation, which approximates the dynamics of the deviation \\(\\epsilon(t)\\) near the fixed point \\(x^*\\); note that the derivative \\(f'(x^*)\\) is a constant for any given fixed point. In section \\(\\ref{sec:math15}\\) we classified the behavior of solutions for the general linear ODE \\(\\dot x = rx\\), and now we apply this classification to the behavior of the deviation \\(\\epsilon(t)\\). If the multiple \\(f'(x^*)\\) is positive, the deviation \\(\\epsilon(t)\\) is growing, the solution is diverging away from the fixed point, and thus the fixed point is unstable. If the multiple \\(f'(x^*)\\) is negative, the deviation \\(\\epsilon(t)\\) is decaying, the solution is converging to the fixed point, and thus the fixed point is stable. Finally, there is the borderline case of \\(f'(x^*) = 0\\) which is inconclusive, and the fixed point may be either stable or unstable. The derivative stability analysis is summarized in the following:\n\n\\(f'(x^*) > 0\\): the slope of \\(f(x)\\) at the fixed point is positive, then the fixed point is .\n\\(f'(x^*) < 0\\): the slope of \\(f(x)\\) at the fixed point is negative, then the fixed point is .\n\\(f'(x^*) = 0\\): stability cannot be determined from the derivative.\n\nTherefore, knowing the derivative or the slope of the defining function at the fixed point is enough to know its stability. If the derivative has the discourtesy of being zero, the situation is tricky, because then higher order terms that we neglected make the difference. We will mostly avoid such borderline cases, but they are important in some applications .\nA word of caution: The derivative of the defining function \\(f'(x)\\) is not the second derivative of the solution \\(x(t)\\). This is a common mistake, because the function \\(f(x)\\) is equal to the time derivative of \\(x(t)\\). However, the derivative \\(f'(x)\\) is not with respect to time, it is with respect to x, the dependent variable. In other words, it reflects the slope of the graph of the defining function \\(f(x)\\), not the curvature of the graph of the solution \\(x(t)\\).\nTo summarize, here is an outline of the steps for analyzing the behavior of solutions of an autonomous one-variable ODE. These tasks can be accomplished either by plotting the defining function \\(f(x)\\) and finding the fixed points and their stability based on the plot, or by solving for the fixed points on paper, then finding the derivative \\(f'(x)\\) and plugging in the values of the fixed points to determine their stability. Either approach is valid, but the analytic methods are necessary when dealing with models that have unknown parameter values, which makes it impossible to represent the defining function in a plot.\n\n\n10.2.3 Outline of qualitative analysis of an ODE\n\nfind the fixed points by setting the defining function \\(f(x)=0\\) and solving for values of \\(x^*\\)\ndivide the domain of \\(x\\) into intervals separated by fixed points \\(x^*\\)\ndetermine on which interval(s) the solution \\(x(t)\\) is increasing and on which it is decreasing\nuse derivative stability analysis (graphically or analytically) to determine which fixed points are stable\nsketch the solutions \\(x(t)\\) starting at different initial values, based on the stability analysis and whether the solution is increasing or decreasing in a particular interval\n\nExample: linear model. Consider the linear ODE that we analyzed above \\(dx/dt = 4x -100\\). Let us go through the steps of qualitative analysis:\n\nfind the fixed points by setting the defining function to 0: \\(0 = 4x -100\\), so there is only one fixed point \\(x^* = 25\\)\ndivide the domain of \\(x\\) into intervals separated by fixed points \\(x^*\\): the intervals are \\(x<25\\) and \\(x>25\\)\nthe solution is decreasing on the interval \\(x<25\\) because \\(f(x)<0\\) there, and the solution is increasing on the interval \\(x>25\\) because \\(f(x)>0\\)\nthe derivative \\(f'(x)\\) at the fixed point is 4, so the fixed point is unstable\nsolutions \\(x(t)\\) starting at different initial values are shown in figure \\(\\ref{fig:ch16_flow_linear}\\)b and they behave as follows: solutions with initial values below \\(x^*=25\\) decreasing, and those with initial values above \\(x^*=25\\) increasing.\n\n** Example: logistic model.** Consider the logistic model from the previous subsection, \\(dP/dt =0.3P(1-P/40)\\). We have analyzed the stability of the two fixed points using the plot in figure \\(\\ref{fig:ch16_flow_logistic}\\), and saw that the flow takes the solution away from \\(P=0\\), and toward \\(P=K\\), thus the first fixed point is unstable, while the second is stable. Let us repeat the analysis using analytic tools:\n\nfind the fixed points by setting the defining function to 0: \\(0 = 0.3P(1-P/40)\\). The two solutions are \\(P^*=0\\) and \\(P^*=40\\).\ndivide the domain of \\(P\\) into intervals separated by fixed points \\(P^*\\): the intervals are \\(P<0\\); \\(0<P<40\\); and \\(P>40\\)\nthe solution is decreasing on the interval \\(P<0\\) because \\(f(P)<0\\) there, the solution is increasing on the interval \\(0<P<40\\) because \\(f(P)>0\\), and the solution is decreasing for \\(P>40\\) because \\(f(P)<0\\) there\nthe derivative is \\(f'(P)=0.3-0.3P/20\\); since \\(f'(0)=0.3 > 0\\), the fixed point is unstable; since \\(P'(40)=-0.3<0\\), the fixed point is stable\nsolutions \\(P(t)\\) starting at different initial values are shown in figure \\(\\ref{fig:ch16_flow_logistic}\\)b and they behave as follows: solutions with initial values below \\(P^*=0\\) decreasing, those with initial values between 0 and 40 are increasing and asymptotically approaching 40, and those with initial values above 40 decreasing and asymptotically approaching 40.\n\nThis can be done more generally using the derivative test: taking the derivative of the function on the right-hand-side (with respect to \\(P\\)), we get \\(f'(P) = r(1-2\\frac{P}{K})\\). Assuming \\(r>0\\) (the population is viable), \\(f'(0)= r\\) is positive, and the fixed point is therefore unstable. This makes biological sense, since we assumed positive inherent population growth, so given a few individuals, it will increase in size. On the other hand, \\(P'(K) = r(1-2) = -r\\), so this fixed point is stable. Thus, according to the logistic model, a population with a positive inherent growth rate will not grow unchecked, like in the exponential model, but will increase until it reaches its carrying capacity, at which it will stay (if all parameters remain constant).\nExample: semi-stable fixed point. Consider the ODE \\(dx/dt = -x^3 + x^2\\), whose defining function is plotted in figure \\(\\ref{fig:ch16_flow_semi}\\)a, showing two fixed points at \\(x = 0, 1\\).\n\nfind the fixed points by setting the defining function to 0: \\(0 = -x^3 + x^2\\). The two fixed points are \\(x^*=0\\) and \\(x^*=1\\).\ndivide the domain of \\(x\\) into intervals separated by fixed points \\(x^*\\): the intervals are \\(x<0\\); \\(0<x<1\\); and \\(x>1\\)\nthe solution is increasing on the interval \\(x<0\\) because \\(f(x)>0\\) there, the solution is increasing on the interval \\(0<x<1\\) because \\(f(x)>0\\), and the solution is decreasing for \\(x>1\\) because \\(f(x)<0\\) there\nthe derivative is \\(f'(x)=-3x^2+2x\\); since \\(f'(0)=0\\), the fixed point is undetermined; since \\(f'(1)=-1<0\\), the fixed point is stable.\nthe solutions \\(x(t)\\) starting at different initial values are shown in figure \\(\\ref{fig:ch16_flow_semi}\\)b, and they behave as follows: solutions with initial values below 0 are increasing and asymptotically approaching 0, those with initial values between 0 and 1 are increasing and asymptotically approaching 1, and those with initial values above 1 are decreasing and asymptotically approaching 1.\n\nThis example shows how graphical analysis can help when derivative analysis is undetermined. The red arrows on the x-axis of figure \\(\\ref{fig:ch16_flow_semi}\\) show the direction of the flow in the three different regions separated by the fixed points. Flow is to the right for \\(x<1\\), to the left for for \\(x>1\\); it is clear that the arrows approach the fixed point from both sides, and thus the fixed point is stable, as the negative slope of \\(f(x)\\) at \\(x=1\\) indicates. One the other hand, the fixed point at \\(x=0\\) presents a more complicated situation: the slope of \\(f(x)\\) is zero, and the flow is rightward on both sides of the fixed point. This type of fixed point is sometimes called semi-stable, because it is stable when approached from one side, and unstable when approached from the other.\n\n\n\n\n\na) plot of the defining function of the ODE \\(dx/dt = -x^3 + x^2\\) with direction of flow of x(t) indicated with arrows on the x-axis; b) plot of solutions x(t) of the ODE staring with three initial values\n\n\n\n\n\n\n\na) plot of the defining function of the ODE \\(dx/dt = -x^3 + x^2\\) with direction of flow of x(t) indicated with arrows on the x-axis; b) plot of solutions x(t) of the ODE staring with three initial values\n\n\n\n\n\n\n10.2.4 Exercises\nFor the following differential equations: a) plot the defining function over the indicated range (use any computational tools you wish) to determine the intervals on which the dependent variable is increasing and decreasing; b) find the equilibria c) determine the stability of each equilibrium; d) based on your analysis in parts a-c, sketch (by hand) plots of the solutions with the specified initial values.\n\n\\[ \\frac{dC}{dt} = -0.2C + 60; \\; C \\in (0,500); \\; C(0) = 200; \\; C(0) = 400 \\]\n\\[ \\frac{dP}{dt} = 0.01P(800-P) - 0.5P; \\; P \\in (-1, 1000); \\; P(0) = 100; \\; P(0) = 800\\]\n\\[ \\frac{dR}{dt} = R(80-R) - 1200; \\; R \\in (-1, 100); \\; R(0) = 10; \\; R(0) = 80\\]\n\\[ \\frac{dI}{dt} = 0.1I(1-I) - 0.03I; \\;  I \\in (-0.1, 1.1); \\; I(0) = 0.2; \\; I(0) = 0.9 \\]\n\\[  \\frac{dR}{dt} = \\frac{R}{1+R}-0.1R; \\; R \\in (-0.1, 10); \\; R(0) = 20; \\; R(0) = 0 \\]\n\\[  \\frac{dP}{dt} =  0.02P(P-100)(1200-P) \\; P \\in (-0.1, 1200); \\; P(0) = 20; \\; P(0) = 1000 \\]\n\\[  \\frac{dY}{dt} =  0.01Y(Y-100)(Y-200) \\; Y \\in (-0.1, 300); \\; Y(0) = 20; \\; Y(0) = 250 \\]\n(harder) The logistic function was defined in chapter 2, equation 2.4. Verify that the logistic function with independent variable \\(t\\) solves the logistic ODE in equation \\(\\ref{eq:log_cont_model}\\) and relate the parameters in the function to the parameters \\(r\\) and \\(K\\) in the ODE."
  },
  {
    "objectID": "graph_odes.html#functions-in-r",
    "href": "graph_odes.html#functions-in-r",
    "title": "10  Graphical analysis of ordinary differential equations",
    "section": "10.3 Functions in R",
    "text": "10.3 Functions in R\nLike most programming languages, R allows one to define and use structures called functions. Some are already written and loaded into the R distribution, for example, the function mean() we use to compute the mean of a vector variable, while others can be defined by users. Functions are discrete chunks of code that can be called from the outside to perform some task. The function receives inputs from the call and returns the result back. Here is the general structure of a function in R:\n\nmyfunction <- function(arg1, arg2, ...) {\n    statements\n    return(answer)\n}\n\nA function is a piece of code that is defined separately and can be called by other pieces of code. The main purpose is to create a “black box” that does a specific job and can be used repeatedly just by calling the function (invoking its name), rather than copying the code repeatedly.\nA function generally has input variables (although sometimes there are none) and returns an output using the return() statement. It is important to distinguish between the inside of the function - the code between the curly braces in the function definition - and the outside, that is everything else. The inputs are passed to the function in the call (through the parentheses) and then used inside the function to do its business and produce an output, which is then returned back to the place in the code where the function was called.\n\n10.3.1 defining a function\nHere is an example of a function definition, with input variables N and r. Between the curly braces is the body of the function, which in this case multiplies the two input variables and then returns them.\n\nmy_funk <- function(N,r){ \n  ans <- r*N # updating function f(N)\n  return(ans)\n}\n\nNote that after running the code chunk above, you should see the name my_funk in your environment (under Functions). This means this function is defined in memory and ready to be called.\n\n\n10.3.2 calling a function\nAfter a function is defined, it is ready to be called (executed) by invoking its name and giving the correct number of inputs. Here’s an example of a function call:\n\na <- 30\ny <- 1:10\nprint(my_funk(y, a))\n\n [1]  30  60  90 120 150 180 210 240 270 300\n\n\nNotice that the variable names in the fuction call do not have to be same as what they are called within the function. IMPORTANT: a function uses the order of variables in the function call, called external variables (y, a) to assign their names within the function, called internal variables (N, r). (There is a way to specify which input belongs to which internal variable, e.g. plot(x=time, y=sol) and in that case the order is not important.)\n\n\n10.3.3 using a function to solve a difference equation\nWe have solved discrete-time dynamic models (difference equations) using for loops. You can use a function to calculate the next value of the solution, by passing the current value and any parameters as inputs to the function, as you can see in the code chunk below:\n\nnumsteps<-30 # set number of steps\nsol <- rep(0,numsteps+1) # pre-allocate sol1\nsol[1] <- 100 # set initial value\nr <- 2 # define the multiplicative constant\nfor (i in 1:numsteps) { # repeat for numsteps\n  sol[i+1] <- my_funk(sol[i], r) # calculate the next value\n}\ntime <- 0:numsteps # define time vector\nplot(time,sol,t='b',xlab='time',ylab='solution',lwd=2)\n\n\n\n\n\n\n10.3.4 Exercises\n\nWrite a function that takes the input variable and multiplies it by 1.03, like the mathematical function \\(f(x) = 1.03x\\).\n\n\n# YOUR CODE HERE\n\n\nUse the function to take a variable and multiply it by 1.03, replacing the old value of the variable. If the initial value is 5, the new value should be 5.15.\n\n\n# YOUR CODE HERE\n\n\nWrite a script to take a variable and multiply it by 1.03 one hundred times, replacing the old value of the variable using a for loop and the function you created. Starting with the initial value is 5, the script should return the value 96.093.\n\n\n# YOUR CODE HERE\n\n\nModify the script above to save all the intermediate values into a vector, and plot a graph of this vector vs. the iteration step (from 1 to 101). Hint: this is exactly like the example code above.\n\n\n# YOUR CODE HERE"
  },
  {
    "objectID": "graph_odes.html#modeling-the-spread-of-infectious-disease-spread",
    "href": "graph_odes.html#modeling-the-spread-of-infectious-disease-spread",
    "title": "10  Graphical analysis of ordinary differential equations",
    "section": "10.4 Modeling the spread of infectious disease spread",
    "text": "10.4 Modeling the spread of infectious disease spread\n\nThe field of epidemiology studies the distribution of disease and health states in populations. Epidemiologists describe and model these issues with the goal of helping public health workers devise interventions to improve the overall health outcomes on a large scale. One particular topic of interest is the the spread of infectious disease and how best tor respond to it.. Because epidemiology is concerned with large numbers of people, the models used in the field do not address the details of an individual disease history. One approach to modeling this is to put people into categories, such as susceptible (those who can be infected but are not), infectious (those who are infected and can spread the disease), and recovered (those who cannot be infected or spread disease). This type of models is called a compartment model and they are they commonly used to represent infectious disease on a population level both for deterministic models (e.g. ODEs) and stochastic models (e.g. Markov models). Dividing people into categories involves the assumption that everyone in a particular category behaves in the same manner: for instance, all susceptible people are infected with the same rate and all infected people recover with the same rate.\nLet us construct an ODE to describe a two-compartment epidemiology model. There are two dependent variables to be tracked: the number of susceptible (\\(S\\)) and infected (\\(I\\)) individuals in the population. The susceptible individuals can get infected, while the infected ones can recover and become susceptible again. The implicit assumption is that there is no immunity, and recovered individuals can get infected with the same ease as those who were never infected. There are some human diseases for which this is true, for instance the common cold or gonorrhea. Transitions between the different classes of individuals can be summarized by the following scheme: \\[ S + I \\xrightarrow{\\beta} I \\xrightarrow{\\gamma} S \\] Here \\(\\beta\\) is the individual rate of infection, also known as the transmission rate, and \\(\\gamma\\) is the individual rate of recovery. There is an important distinction between the processes of infection and recovery: the former requires an infected individual and a susceptible individual, while the latter needs only an infected individual. Therefore, it is reasonable to suppose that the rate of growth of infected individuals is the product of the individual transmission rate \\(\\beta\\) and the product of the number of infected and susceptible individuals. The overall rate of recovery is the individual recovery rate \\(\\gamma\\) multiplied by the number of the infected. This leads to the following two differential equations: \\[\\begin{eqnarray*}\n\\dot S &=& -\\beta IS + \\gamma I \\\\\n\\dot I & = &\\beta I S - \\gamma I\n\\end{eqnarray*}\\] Note that, as in the chemical kinetics models, the two equations add up to zero on the right hand side, leading to the conclusion that \\(\\dot S + \\dot I = 0\\). Therefore, the total number of people is a conserved quantity \\(N\\), which does not change. This makes sense since we did not consider any births or deaths in the ODE model, only transitions between susceptible and infected individuals.\nWe can use the conserved quantity \\(N\\) to reduce the two equations to one, by the substitution of \\(S = N -I\\): \\[  \\dot I  =  \\beta I (N - I) - \\gamma I \\] This model may be analyzed using qualitative methods that were developed in this chapter, allowing prediction of the dynamics of the fraction of infected for different transmission and recovery rates. First, let us find the fixed points of the differential equation. Setting the equation to zero, we find: \\[ 0  =  \\beta I (N - I) - \\gamma I \\Rightarrow I^* = 0; \\; I^* =  N - \\gamma/\\beta \\] This means that there are two equilibrium levels of infection: either nobody is infected (\\(I^* = 0\\)) or there is some persistent number of infected individuals ($ I^* = N - /$). Notice that the second fixed point is only biologically relevant if $N > /$.\nUse the derivative test to check for stability. First, find the general expression for derivative of the defining function: $f’(I) = -2 I + N - $. \\begin{figure}[htbp] % figure placement: here, top, bottom, or page\n\n\n\n\n\nGraphical analysis of the SIS model with \\(I\\) representing the fraction of infected individuals (N=1) and beta=0.5 and gamma = 0.2; a) plot showing the flow of the solutions on the I-axis, with a stable equilibrium at 0.6 and an unstable equilibrium at 0; b) three solutions of the model starting at three different initial values all converge to the same fraction of infected.\n\n\n\n\n\n\n\nGraphical analysis of the SIS model with \\(I\\) representing the fraction of infected individuals (N=1) and beta=0.5 and gamma = 0.2; a) plot showing the flow of the solutions on the I-axis, with a stable equilibrium at 0.6 and an unstable equilibrium at 0; b) three solutions of the model starting at three different initial values all converge to the same fraction of infected.\n\n\n\n\n\n\n\n\n\nGraphical analysis of the SIS model with I representing the fraction of infected individuals (N=1) and beta=0.2 and gamma = 0.3; a) plot showing the flow of the solutions on the I-axis, with a stable equilibrium at 0 and an unstable equilibrium at -0.5; b) three solutions of the model starting at three different initial values all converge to 0 infected.\n\n\n\n\n\n\n\nGraphical analysis of the SIS model with I representing the fraction of infected individuals (N=1) and beta=0.2 and gamma = 0.3; a) plot showing the flow of the solutions on the I-axis, with a stable equilibrium at 0 and an unstable equilibrium at -0.5; b) three solutions of the model starting at three different initial values all converge to 0 infected.\n\n\n\n\nThe stability of the fixed point \\(I^* = 0\\) is found by plugging in this value into the derivative formula: $f’(0) = N - $. We learned in section \\(\\ref{sec:math16}\\) that a fixed point is stable if the derivative of the defining function is negative. Therefore, \\(I^* = 0\\) is stable if \\(\\gamma - \\beta N > 0\\), and unstable otherwise. This gives us a stability condition on the values of the biological parameters. If the recovery rate \\(\\gamma\\) is greater than the rate of infection for the population (the transmission rate multiplied by the population size) \\(\\beta N\\), then the no-infection equilibrium is stable. This predicts that the infection dies out if the recovery rate is faster than the rate of infection, which makes biological sense.\nSimilarly, we find the stability of the second fixed point \\(I^* = N - \\gamma/\\beta\\) by substituting its value into the derivative, to obtain \\(f'(N - \\gamma/\\beta) = \\gamma - \\beta N\\). By the same logic, as above, this fixed point is stable if \\(\\gamma - \\beta N < 0\\), or if \\(\\gamma < \\beta N\\). This is a complementary condition for the fixed point at 0, that is, only one fixed point can be stable for any given parameter values. In the biological interpretation, if the transmission rate \\(\\beta N\\) is greater than the recovery rate \\(\\gamma\\), then the epidemic will persist.\nWe can use our graphical analysis skills to illustrate the situation. Consider a situation in which \\(\\gamma < \\beta N\\). As predicted by stability analysis, the zero infection equilibrium should be unstable, and the equilibrium at \\(N - \\gamma/\\beta\\) should be stable. In order to plot the function $f(I) = I (N - I) - I $, we choose the specific parameter values \\(N=1\\), \\(\\gamma = 0.1\\) and \\(\\beta = 0.2\\); setting \\(N=1\\) means \\(S\\) and \\(I\\) represent the fraction of the population in the susceptible and infected categories. Figure \\(\\ref{fig:ch16_flow_sis1}\\)a shows the direction of the flow on the \\(I\\)-axis prescribed by the defining function \\(f(I)\\) with red arrows. It is clear that solutions approach the fixed point at \\(N - \\gamma/\\beta\\) from both directions, which make it a stable fixed point, while diverging from \\(I=0\\), as shown in figure \\(\\ref{fig:ch16_flow_sis1}\\)b.\nOn the other hand, if \\(\\gamma > \\beta N\\), stability analysis predicts that the no-infection equilibrium (\\(I=0\\)) is stable. Figure \\(\\ref{fig:ch16_flow_sis2}\\)a shows the plot of the defining function for the parameter values \\(N=1\\), \\(\\gamma = 0.3\\) and \\(\\beta = 0.2\\). The flow on the \\(I\\)-axis is toward the zero equilibrium, therefore it is stable. Note that the second equilibrium at \\(I^* = N - \\gamma/\\beta\\) is negative, and thus has no biological significance. The solutions, if the initial value is positive, all approach 0, so the infection inevitably dies out.\nMathematical modeling of epidemiology has been a success story in the last few decades. Public health workers routinely estimate the parameter called the basic reproductive number \\(R_0\\) defined to be the average number of new infections caused by a single infected individual in a susceptible population. This number comes out of our analysis above, where we found \\(R_0 = N \\beta/\\gamma\\) to determine whether or not an epidemic persisted . This number is critical in more sophisticated models of epidemiology.\nMathematical models are used to predict the time course of an epidemic, called the epidemic curve and then advise on the public health interventions that can reduce the number of affected individuals. In reality, most epidemic curves have the shape similar to the data from the Ebola virus epidemic in figure \\(\\ref{fig:ch16-ebola}\\). Most such curves show an initial increase in infections, peaking, and the declining to low levels, which is fundamentally different than the solution curves we obtained from the two-compartment model. To describe dynamics of this nature, models with more than two variables are needed, such as classic three-compartment SIR models (susceptible-infected-recovered) models and their modifications . Being able to predict the future of an epidemic based on \\(R_0\\) and other parameters allows public health officials to prepare and deploy interventions (vaccinations, quarantine, etc.) that have the best shot at minimizing the epidemic.\n\n\n\n\n\nNumber of new cases of ebola virus infections per week in Liberia (left) and Sierra Leone (right), time ranging from March 17, 2014 (week 1) until May 20, 2015 (week 61). Data from http://apps.who.int/gho/data/node.ebola-sitrep.\n\n\n\n\n\n\n\nNumber of new cases of ebola virus infections per week in Liberia (left) and Sierra Leone (right), time ranging from March 17, 2014 (week 1) until May 20, 2015 (week 61). Data from http://apps.who.int/gho/data/node.ebola-sitrep.\n\n\n\n\n\n10.4.1 Discussion\nThe following questions encourage you to think critically about modeling of infectious diseases.\n\nWhat effect does changing the infection rate \\(\\beta\\) have on the basic reproductive rate? Explain the biological intuition behind this.}\nWhat effect does changing the recovery rate \\(\\gamma\\) have on the basic reproductive rate? Explain the biological intuition behind this.}\nDiscuss what assumptions are made by using compartment models, and when they might be justified.}\nDiscuss the difference in assumptions in using a Markov model with Susceptible and Infected compartments compared to an ODE model with the same two compartments. Under what circumstances does it make sense to use one or the other?}\nRead the paper and discuss the strengths and limitations of the more complicated compartment model intended to account for human behavior.}"
  },
  {
    "objectID": "ode_sols.html#solutions-of-ordinary-differential-equations",
    "href": "ode_sols.html#solutions-of-ordinary-differential-equations",
    "title": "11  Solutions of ordinary differential equations",
    "section": "11.1 Solutions of ordinary differential equations",
    "text": "11.1 Solutions of ordinary differential equations\n\nIn this section we will investigate how to write down analytic solutions for ordinary differential equations (ODEs). Let us first define the mathematical terms that will be used in this discussion.\n\n\n\n\n\n\nDefinition\n\n\n\nAn ordinary differential equation is an equation that contains derivatives of the dependent variable (e.g. \\(x\\)) with respect to an independent variable (e.g. \\(t\\)). For example: \\[ \\frac{dx^2}{dt^2}+ 0.2 \\frac{dx}{dt} - 25 = 0 \\]\n\n\nFor the time being, we will restrict ourselves to ODEs with the highest derivative being of first order, called first-order ODEs. Second-order ODEs are common in models derived from physics, but can actually be converted to first-order ODEs, though it requires an additional dependent variable. Third and higher order ODEs are very uncommon. To be precise:\n\n\n\n\n\n\nDefinition\n\n\n\nA first-order ODE is one where the derivative \\(dx/dt\\) is equal to a defining function \\(f(x,t)\\), like this: \\[\\frac{dx} {dt} = \\dot x = f(x,t)\\]\n\n\nThe defining function may potentially depend on both the dependent variable \\(x\\) and the independent variable \\(t\\). If it only depends on \\(x\\), it is called an autonomous ODE, for example:\n\\[ \\frac{dx}{dt} = \\dot x = rx \\] or\n\\[\\frac{dx}{dt} = \\dot x = 5x -4\\]\nOn the other hand, if the defining function depends only on the independent variable \\(t\\), it may be called a pure-time ODE, for example:\n\\[\n\\frac{dx}{dt} = \\dot x = 5t\n\\] or\n\\[\n\\frac{dx}{dt} = \\dot x = 20 - 0.3 \\sin(4 \\pi t)\n\\]\nAn ODE is if every term involves either the dependent variable \\(x\\) or its derivative. \\end{mosdef} For instance, \\(\\dot x = x^2 + \\sin(x)\\) is homogeneous, while \\(\\dot x = -x + 5t\\) is not.\nMost simple biological models that we will encounter in the next two chapters are autonomous, homogeneous ODEs. However, nonhomogeneous equations are important in many applications, and we will encounter them at the end of the present section.\n\n11.1.1 separate and integrate method\n\n\n\n\n\n\nDefinition\n\n\n\nThe analytic (or exact) solution of an ordinary differential equation is a function of the independent variable that satisfies the equation. If no initial value is given, then the general solution function will contain an unknown integration constant. If an initial value is specified, the integration constant can be found to obtain a specific solution.\n\n\nThis means that the solution function obeys the relationship between the derivative and the defining function that is specified by the ODE. To verify that a function is a solution of a given ODE, take its derivative and check whether it matches the other side of the equation.\nExample. The function \\(x(t) = 3t^2 +C\\) is a general solution of the ODE \\(\\dot x = 6t\\), which can be verified by taking the derivative: \\(\\dot x (t) = 6t\\). Since this matches the right-hand side of the ODE, the solution is valid.\nExample. The function \\(x(t) = Ce^{5t}\\) is a general solution of the ODE \\(\\dot x = 5x\\). This can be verified by the taking the derivative: \\(\\dot x = 5C e^{5t}\\) and comparing it with the right-hand side of the ODE: \\(5x = 5 Ce^{5t}\\). Since the two sides of the equation agree, the solution is valid.\nIn contrast with algebraic equations, we cannot simply isolate \\(x\\) on one side of the equal sign and find the solutions as one, or a few numbers. Instead, solving ordinary differential equations is very tricky, and no general strategy for solving an arbitrary ODE exists. Moreover, a solution for an ODE is not guaranteed to exist at all, or not for all values of \\(t\\). We will discuss some of the difficulties later, but let us start with equations that we can solve.\nThe most obvious strategy for solving an ODE is integration. Since a differential equation contains derivatives, integrating it can remove the derivative. In the case of the general first order equation, we can integrate both sides to obtain the following: \\[ \\int \\frac{dx}{dt} dt = \\int f(x,t) dt \\Rightarrow x(t) + C = \\int f(x,t) dt\\] The constant of integration \\(C\\) appears as in the standard antiderivative definition. It can be specified by an initial condition for the solution \\(x(t)\\). Unless the function \\(f(x,t)\\) depends only on \\(t\\), it is not possible to evaluate the integral above. Instead, various tricks are used to find the analytic solution. The simplest method of analytic solution of a first-order ODEs, which I call separate-and-integrate consists of the following steps:\n\nuse algebra to place the dependent and independent variables on different sides of the equations, including the differentials (e.g. \\(dx\\) and \\(dt\\))\nintegrate both sides with respect to the different variables, don’t forget the integration constant\nsolve for the dependent variable (e.g. \\(x\\)) to find the general solution\nplug in \\(t=0\\) and use the initial value \\(x(0)\\) to solve for the integration constant and find the the specific solution\n\nExample. Consider a very simple differential equation: \\(\\dot x = a\\), where \\(\\dot x\\) stands for the time derivative of the dependent variable \\(x\\), and \\(a\\) is a constant. It can be solved by integration: \\[ \\int \\frac{dx}{dt} dt  = \\int a dt  \\Rightarrow x(t) + C = at \\]\nThis solution contains an undetermined integration constant; if an initial condition is specified, we can determine the complete solution. Generally speaking, if the initial condition is \\(x(0) = x_0\\), we need to solve an algebraic equation to determine \\(C\\): \\(x_0 = a*0 - C\\), which results in \\(C = -x_0\\). The complete solution is then \\(x(t) = at + x_0\\). To make the example more specific, if \\(a = 5\\) and the initial condition is \\(x(0) = -3\\), the solution is\n\\[x(t) = 5t -3\\]\nExample. Let us solve the linear population growth model in equation \\(\\ref{eq:linear_ode}\\): \\(\\dot x = rx\\). The equation can be solved by first dividing both sides by \\(x\\) and then integrating: \\[ \\int \\frac{1}{x} \\frac{d x}{dt}  dt = \\int \\frac{dx}{x} = \\int r dt \\Longrightarrow \\log |x| = rt + C  \\Longrightarrow  x =  e^{rt+C} = Ae^{rt}\\]\nWe used basic algebra to solve for \\(x\\), exponentiating both sides to get rid of the logarithm on the left side. As a result, the additive constant \\(C\\) gave rise to the multiplicative constant \\(A=e^C\\). Once again, the solution contains a constant which can be determined by specifying an initial condition \\(x(0) = x_0\\). In this case, the relationship is quite straightforward: \\(x(0) = A e^0 = A\\). Thus, the complete solution for equation \\(\\ref{eq:linear_ode}\\) is: \\[ x(t) = x_0e^{rt}\\]\n\n\n11.1.2 behavior of solutions of linear ODEs\nAs in the case of the discrete-time models, population growth with a constant birth rate has exponential form. Once again, please pause and consider this fact, because the exponential solution of linear equations is one of the most basic and powerful tools in applied mathematics. Immediately, it allows us to classify the behavior of linear ODE into three categories:\n\n\\(r > 0\\): \\(x(t)\\) grows without bound\n\\(r < 0\\): \\(x(t)\\) decays to 0\n\\(r = 0\\): \\(x(t)\\) remains constant at the initial value\n\nThe rate \\(r\\) being positive reflects the dominance of birth rate over death rate in the population, leading to unlimited population growth. If the death rate is greater, the population will decline and die out. If the two are exactly matched, the population size will remain unchanged.\nExample. The solution for the biochemical kinetic model in equation \\(\\ref{eq:lin_chem_kin}\\) is identical except for the sign: \\(A(t) = A_0 e^{-kt}\\). When the reaction rate \\(k\\) is positive, as it is in chemistry, the concentration of \\(A\\) decays to 0 over time. This should be obvious from our model, since there is no back reaction, and the only chemical process is conversion of \\(A\\) into \\(B\\). The concentration of \\(B\\) can be found by using the fact that the total concentration of molecules in the model is conserved. Let us call it \\(C\\). Then \\(B(t) = C - A(t) = C- A_0e^{-kt}\\). The concentration of \\(B\\) increases to the asymptotic limit of \\(C\\), meaning that all molecules of \\(A\\) have been converted to \\(B\\).\n\n\n11.1.3 solutions of nonhomogeneous ODEs\nODEs that contain at least one term without the dependent variable are a bit more complicated. If the defining function is \\(f(x,t)\\) is linear in the dependent variable \\(x\\), they can be solved on paper using the same separate-and-integrate method, modified slightly to handle the constant term. Here are the steps to solve the generic linear ODE with a constant term \\(\\dot x = ax +b\\):\n\nseparate the dependent and independent variables on different sides of the equations, by dividing both sides by the right hand side \\(ax+b\\), and multiplying both sides by the differential \\(dt\\)\nintegrate both sides with respect to the different variables, don’t forget the integration constant!\nsolve for the dependent variable (e.g. \\(x\\))\nplug in \\(t=0\\) and use the initial value \\(x(0)\\) to solve for the integration constant\n\nExample. Let us solve the following ODE model using separate and integrate with the given initial value: \\[\\frac{dx}{dt} = 4x -100;  \\; x(0) = 30\\]\n\nseparate the dependent and independent variables: \\[ \\frac{dx}{4x - 100} = dt\\]\nintegrate both sides: \\[  \\int \\frac{dx}{4x -100} =  \\int dt \\Rightarrow \\frac{1}{4} \\int \\frac{du}{u} = \\frac{1}{4} \\ln | 4x- 100 |  = t + C\\] The integration used the substitution of the new variable \\(u=4x -100\\), with the concurrent substitution of \\(dx = du/4\\).\nsolve for the dependent variable: \\[  \\ln | 4x- 100 |  = 4t + C \\Rightarrow 4x-100 = e^{4t} B  \\Rightarrow x = 25  + Be^{4t}\\] Here the first step was to multiply both sides by 4, and the second to use both sides as the exponents of \\(e\\), removing the natural log from the left hand side, and finally simple algebra to solve for \\(x\\) as a function of \\(t\\).\nsolve for the integration constant: \\[ x(0) = 25  + B = 30 \\Rightarrow B = 5\\] Here the exponential ``disappeared’’ because \\(e^0=1\\). \\end{enumerate} Therefore, the complete solution of the ODE with the given initial value is \\[x(t) =  25  + 5e^{4t}\\]\n\nAt this point, you might have noticed something about solutions of linear ODEs: they always involve an exponential term, with time in the exponent. Knowing this, it is possible to bypass the whole process of separate-and-integrate by using the following short-cut.\nImportant fact: Any linear ODE of the form \\(\\dot x= ax +b\\) has an analytic solution of the form: \\[ x(t) = Ce^{at} + D\\]\nThis can be tested by plugging the solution back into the ODE to see if it satisfies the equation. First, take the derivative of the solution to get the left-hand side of the ODE: \\(\\frac{dx}{dt} = Ca e^{at}\\); the plug in \\(x(t)\\) into the right hand side of the ODE: \\(aCe^{at} + aD +b\\). Setting the two sides equal, we get: \\[Ca e^{at} = aCe^{at} + aD +b\\] which is satisfied if \\(aD + b = 0\\), which means \\(D= -b/a\\). This is consistent with the example above, the additive constant in the solution was 25, which is \\(-b/a= -(-100)/4 = 25\\).\nIn short, if you want to solve a linear ODE \\(\\dot x= ax +b\\) , you can bypass the separate-and-integrate process, because the general solution always has the form: \\[\\begin{equation}\nx(t) = Ce^{at} - \\frac{b}{a}\n\\label{eq:ch15_ode_sol}\n\\end{equation}\\]\nThe unknown constant \\(C\\) can be determined from a given initial value. So the upshot is that all linear ODEs have solutions which are exponential in time with exponential constant coming from the slope constant \\(a\\) in the ODE. The dynamics of the solution are determined by the sign of the constant \\(a\\): if \\(a>0\\), the solution grows (or declines) without bound; and if \\(a<0\\), the solution approaches an asymptote at \\(-b/a\\) (from above or below, depending on the initial value). Go back and read section \\(\\ref{sec:math2}\\) for a review of exponential functions if this is not clear.\n\n\n11.1.4 Exercises\nSolve the following linear ODEs and use the specified initial values to determine the integration constant. Describe how the solution behaves over a long time (e.g. grows without bound, goes to zero, etc.). Plug the solution back into the ODE to check that it satisfies the equation.\n\n\\[ \\frac{dx}{dt} = 0.1; \\; x(0)= 100 \\]\n\\[ \\frac{dx}{dt} =  2\\sin(4t) -0.4t; \\; x(0)= 5 \\]\n\\[ \\frac{dx}{dt} = 3x; \\; x(0) = 0.4 \\]\n\\[ \\frac{dx}{dt} = -5x; \\;  x(0) = -300 \\]\n\\[ \\frac{dx}{dt} = -0.5x + 100 ; \\; x(0) = 20 \\]\n\\[ \\frac{dx}{dt} =  1 + x; \\; x(0) = 4 \\]\n\\[ \\frac{dx}{dt} =  -10 - 0.2x; \\; x(0) = 10 \\]\n\\[ \\frac{dx}{dt} =  -4 + 0.5x; \\; x(0) = 6 \\]"
  },
  {
    "objectID": "ode_sols.html#numeric-solutions-and-the-forward-euler-method",
    "href": "ode_sols.html#numeric-solutions-and-the-forward-euler-method",
    "title": "11  Solutions of ordinary differential equations",
    "section": "11.2 Numeric solutions and the Forward Euler method",
    "text": "11.2 Numeric solutions and the Forward Euler method\nAnalytic solutions are very useful for a modeler because they allow prediction of the variable of interest at any time in the future. However, for many differential equations they are not easy to find, and for many others they simply cannot be written down in a symbolic form. Instead, one can use a numerical approach, which does not require an exact formula for the solution. The idea is to start at a given initial value (e.g. \\(x(0)\\)) and use the derivative from the ODE (e.g. \\(dx/dt\\)) as the rate of change of the solution (e.g. \\(x(t)\\)) to calculate the change or increment for the solution over a time step. Essentially, this means replacing the continuous change of the derivative with a discrete time step, thus converting the differential equation into a difference equation and then solving it. The solution of the difference equation is not the same as the solution of the ODE, so numeric solutions of ODEs are always approximate. I will use the letter \\(y(t)\\) to denote the numerical solution to distinguish it from the exact solution \\(x(t)\\). The fundamental difference between them is that \\(y(t)\\) is not a formula that can be evaluated at any point in time, but instead is a sequence of numbers calculated every time step, which hopefully are close to the exact solution \\(x(t)\\).\nLet us introduce all the players: first, we need to pick the time step \\(\\Delta t\\), which is the length of time between successive values of \\(y\\). In the difference equation notation one can use \\(y_i\\) to mean \\(y(i\\Delta t)\\), the value of the numerical solution after \\(i\\) time steps. Then we need to calculate the derivative, or the rate of change at a particular point in time. For any first-order ODE of the form \\[ \\frac{d x} {dt} = \\dot x = f(x,t)\\]\nthe rate of change depends (potentially) on the values of \\(x\\) and \\(t\\). This rate of change based on the numerical solution after \\(i\\) time steps is \\(f(y(i\\Delta t), i\\Delta t) = f(y_i, t_i)\\). Finally, to calculate the change of the dependent variable we need to multiply the rate of change by the time step. This should make sense in a practical context: if you drive for two hours (time step) at 60 miles per hour (rate of change), the total distance (increment) is \\(2*60=120\\) miles. By the same token, we can write down how to calculate the next value of the numerical solution \\(y_{i+1}\\) based on the previous one: \\[\\begin{equation}\ny_{i+1} = y_i + \\Delta t f(y_i, t_i)\n\\label{eq:ch15_FE}\n\\end{equation}\\]\nThis method of computing a numerical solution of an ODE is called the Forward Euler method, after the famous mathematician who first came up with it. It is called a forward method because it uses the value of the dependent variable and its derivative at time step \\(i\\) to predict the value at the next time step \\(i+1\\). The method is iterative, so it needs to be repeated in order to calculate a set of values of the approximate solution \\(y(t)\\). Here are a couple of simple examples of computing numerical solution using FE:\n Let us numerically solve the ODE \\(\\dot x = -0.1\\) using the Forward Euler method. This means the defining function in the formulation of FE above is \\(f(x,t)=-0.1\\). We can calculate the numeric solution for a couple of steps and compare the values with the exact solution, since we now know that it is \\(x(t) = x_0 -0.1t\\). Let us pick the time step \\(\\Delta t = 0.2\\) and begin with the initial value \\(x(0)=1\\). Here are the first three steps using the FE method: \\[ y(0.2) = y(0) + \\Delta t f(y(0)) = 1 + 0.2*(-0.1) = 0.98\\] \\[ y(0.4) = y(0.2) + \\Delta t f(y(0.2)) = 0.98+ 0.2*(-0.1) = 0.96\\] \\[ y(0.6) = y(0.4) + \\Delta t f(y(0.4)) = 0.96+ 0.2*(-0.1) = 0.94\\] Since the rate of change in this ODE is constant, the solution declines by the same amount every time step. In this case, the numerical solution is actually exact, and perfectly matches the analytic solution. Table \\(\\ref{tab:ch15_FE}\\) (right) shows the numerical solution for 3 time steps along with the exact solution.\n Let us numerically solve the ODE \\(\\dot x = -0.1x\\) using the Forward Euler method. This means the defining function in the formulation of FE above is \\(f(x,t)=-0.1x\\). We can calculate the numeric solution for a couple of steps and compare the values with the exact solution, since we now know that it is \\(x(t) = x_0 e^{-0.1t}\\). Let us pick the time step \\(\\Delta t = 0.2\\) and begin with the initial value \\(x(0)=100\\). Here are the first three steps using the FE method: \\[ y(0.2) = y(0) + \\Delta t f(y(0)) = 100 + 0.2*(-0.1*100) = 98\\] \\[ y(0.4) = y(0.2) + \\Delta t f(y(0.2)) = 98+ 0.2*(-0.1*98) \\] \\[ = 96.04\\] \\[ y(0.6) = y(0.4) + \\Delta t f(y(0.4)) = 96.04+ 0.2*(-0.1*96.04) \\approx  \\] \\[ \\approx 94.12\\] In this case, the derivative is not constant and the numerical solution is not exact, which is demonstrated in table \\(\\ref{tab:ch15_FE}\\) (left). The error in the numerical solution grows with time, which may be problematic. We will further investigate how to implement the computation of numerical solutions using R in the next section.\n\nNumerical solutions of the ODE \\(\\dot x = -0.1\\) using Forward Euler \\(y\\) calculated for 3 steps of size \\(\\Delta t = 0.2\\) as well as the exact solution \\(x\\), both rounded to two digits after the decimal, and the error of the numerical solution.\n\n\nt\nx\ny\nerror\n\n\n\n\n0\n1\n1\n0\n\n\n0.2\n0.98\n0.98\n0\n\n\n0.4\n0.96\n0.96\n0\n\n\n0.6\n0.94\n0.94\n0\n\n\n\n\nNumerical solution of the ODEs \\(\\dot x = -0.1x\\) (right) using Forward Euler \\(y\\) calculated for 3 steps of size \\(\\Delta t = 0.2\\) as well as the exact solution \\(x\\), both rounded to two digits after the decimal, and the error of the numerical solution.\n\n\nt\nx\ny\nerror\n\n\n\n\n0\n100\n100\n0\n\n\n0.2\n98.02\n98\n0.02\n\n\n0.4\n96.08\n96.04\n0.04\n\n\n0.6\n94.18\n94.12\n0.06\n\n\n\n\n\n11.2.1 Exercises\nUse the Forward Euler method to solve the following differential equations with time step \\(\\Delta t=0.5\\) for 2 steps to compute \\(y(1)\\) (the value of the numerical solution at \\(t=1\\).)\n\n\\[ \\frac{dx}{dt} = 0.1; \\; x(0)= 100 \\]\n\\[ \\frac{dx}{dt} =  2\\sin(4t) -0.4t; \\; x(0)= 5 \\]\n\\[ \\frac{dx}{dt} = 3x; \\; x(0) = 0.4 \\]\n\\[ \\frac{dx}{dt} = -5x; \\;  x(0) = -300 \\]\n\\[ \\frac{dx}{dt} = -0.5x + 100 ; \\; x(0) = 20 \\]\n\\[ \\frac{dx}{dt} =  1 + x; \\; x(0) = 4 \\]\n\\[ \\frac{dx}{dt} =  -10 - 0.2x; \\; x(0) = 10 \\]\n\\[ \\frac{dx}{dt} =  -4 + 0.5x; \\; x(0) = 6 \\]"
  },
  {
    "objectID": "ode_sols.html#forward-euler-method-in-r",
    "href": "ode_sols.html#forward-euler-method-in-r",
    "title": "11  Solutions of ordinary differential equations",
    "section": "11.3 Forward Euler method in R",
    "text": "11.3 Forward Euler method in R\n\n\n11.3.1 implementation\nIn practice, the most common approach to finding solutions for differential equations is using a computer to calculate a numerical solution, for example using the Forward Euler method. This means using a computer program to construct a sequence of values of the dependent variable that approximate the true solution. Below is an outline of the algorithm that can be translated into a programming language, like R, to solve ODEs.\n\nassign the time step dt, length of time Tmax, number of time steps numstep\npre-allocate the vector of numeric solution values y of length numstep+1\nassign the initial value for the ODE to the first element of the solution\nassign the vector of time values t from 0 to Tmax of length numstep+1\nfor loop starting at 1 to numstep\n\nassign the next solution value to be the current solution value plus the time step multiplied by the defining function at the current solution value\n\nplot numeric solution y as a function of time t\n\nTo implement the algorithm, one need to know the defining function \\(f(x,t)\\), the initial value, the time step, and the total time. The output is the solution vector \\(y\\), which contains a sequence of values that approximate the solution of the ODE, along with the vector of time values spaced by the time step. Below is an example implementation of the Forward Euler method for the following linear ODE with initial value 1000:\n\\[\n\\frac{dx}{dt} =  -0.5 x\n\\]\n\nx0 <- 1000\ndt <- 0.01 # set time step\nTmax <- 10 # set length of time\nnumstep <- Tmax/dt # assign number of time steps\npop <- rep(x0, numstep+1) # initialize solution with y0\nfor (i in 1:numstep) { # do the Euler!\n    pop[i+1] <- pop[i]+dt*(-0.5*pop[i])\n}\ntime <- seq(0,Tmax, dt)\nplot(time, pop, type='l')\n\n\n\n\nFigure 11.1: ?(caption)\n\n\n\n\nNotice that it is very similar to the script for numerical solution of a difference equation we saw in \\(\\ref{sec:comp14}\\) with the major difference being the presence of a time step, whereas in difference equations the time step is always 1. There is one more important point for the implementation: usually one needs to solve the ODE for a particular length of time \\(T\\) with a specified time step \\(\\Delta t\\) . This dictates that the required number of iterations be \\(T/\\Delta t\\); in other words, for a given time period the number of time steps is inversely proportional to the time step.\n\n\n11.3.2 Exercises\nConsider a slightly different linear ODE:\n\\[\n\\frac{dx}{dt} =  0.2 x\n\\]\n\nCalculate the numeric solution of the ODE for one time step using Forward Euler, for time step dt=0.1, starting with initial value x(0) = 5. Answer: 5.1\n\n\n# YOUR CODE HERE\n\n\nWrite a script to solve the ODE using the Forward Euler method based on the outline above. Set the time step dt=0.1 and report the solution after 100 time steps. Answer: 36.22323\n\n\n# YOUR CODE HERE\n\n\nChange the time step to be dt=0.01 and report the solution after 1000 time steps. Answer: 36.87156.\n\n\n# YOUR CODE HERE\n\n\n\n11.3.3 error analysis\nNumeric solutions of ODE are always approximate, because they use discrete time steps to approximate continuous change (derivatives). Thus numeric solutions always have error, which is the difference between the exact or analytic solution and the numeric solution. If we know the exact solution of an ODE, we can calculate the error using vector subtraction in R. For the same linear ODE we solved above: \\[\n\\frac{dx}{dt} =  -0.5 x\n\\] The analytic solution is \\(x(t) = x_0 e^{-0.5t}\\), where \\(x_0\\) is the initial value. Here is an example of computing the numeric solution (as we did above) and then calculating the analytic solution and plotting it:\n\nx0 <- 1000\ndt <- 0.5 # set time step\nTmax <- 10 # set length of time\nnumstep <- Tmax/dt # assign number of time steps\npop <- rep(x0, numstep+1) # initialize solution with y0\nfor (i in 1:numstep) { # do the Euler!\n    pop[i+1] <- pop[i]+dt*(-0.5*pop[i])\n}\ntime <- seq(0,Tmax, dt)\nplot(time, pop, type='l', main = \"Numeric and analytic solutions of an ODE\") # plot the numeric solution\nexact <- x0*exp(-0.5*time) # calculate the exact solution\nlines(time, exact, col = 'red') # plot the exact solution\nlegend('topright', col=c('black', 'red'), lty=1, legend = c('numeric', 'analytic'))\n\n\n\n\nNow we can calculate the error of the numeric solution and plot it:\n\nerror <- abs(exact - pop)\nplot(time, error, type = 'l', main='Error of the numeric solution')\n\n\n\n\nWhat is the sources of this error? There are at least two distinct sources of error in numerical solutions: a) and b) . Roundoff error is caused by computers representing real numbers by a finite string of bits on a computer using what is known as a representation. In many programming languages variables storing real numbers can be single or double precision, which typically support 24 and 53 significant binary digits, respectively. Any arithmetic operation involving floating point numbers is only approximate, with an error that depends on the way the numbers are stored in the memory. Truncation error is caused by approximations inherent in numerical algorithms, such as Forward Euler, which represent instantaneous rate of change in an ODE with discrete steps and thus are always a bit off from the true analytic solution.\nIn practice, roundoff error is not a big concern in contemporary computation for most modelers. Truncation error, on the other hand, can cause big problems, but luckily it is within your control. One can decrease the error in the case of finite difference methods by choosing smaller time steps, or by choosing an algorithm with a higher order of accuracy, which we’ll leave for a more advanced discussion.\nReturning specifically to the Forward Euler method, it is called a first-order method because the total error of the solution (after some number of time steps) depends linearly on the time step \\(\\Delta t\\). One can show this by using the Taylor expansion of the solution \\(y(t)\\) to derive the forward Euler method, with \\(\\tau(\\Delta t)\\) representing the truncation error after one time step: \\[y(t+\\Delta t) = y(t) +  \\Delta t \\frac {dy(t) }{dt} + \\tau(\\Delta t)\\] As you might have learned in calculus, the error remaining after the linear term in the Taylor series is proportional to the the square of the small deviation \\(\\Delta t\\). This only describes the error after 1 time step, but since the errors accumulate every time step, the total error after \\(N\\) time steps accumulates \\(N \\tau(\\Delta t)\\). As we saw in the implementation above, for a given length of time, \\(N\\) is inversely proportional to \\(\\Delta t\\). Therefore, the total error is proportional to the \\(\\Delta t\\) and so FE is a first-order method.\nThe exercise above shows that new errors in FE method accumulate in proportion with the time step. The next question is, what happens to these errors over time? Do they grow or dissipate with more iterations? This is known as the stability of a numerical method, and unlike the above question about the order of accuracy, the answer depends on the particular ODE that one needs to solve. Below I show an example of error analysis for a linear ODE:\nExample. To numerically solve the equation \\(\\dot x = ax\\), we substitute the function \\(ax\\) for the function \\(f(x,t)\\), and obtain the FE approximation for this particular ODE: \\[y_{i+1} = y_i + \\Delta t a y_i = (1+a\\Delta t) y_i\\] The big question is what happens to the truncation error: does it grow or decay? To investigate this question, let us denote the error at time \\(t_i\\) , that is the difference between the true solution \\(x(t_i)\\) and the approximate solution \\(y(t_i)\\), by \\(\\epsilon_i\\). It follows that \\(y_i = x_i + \\epsilon_i\\). Then we can wrote the following difference equations involving the error:\n\\[y_{i+1} = x_{i+1} + \\epsilon_{i+1} = (x_i + \\epsilon_i) (1+a\\Delta t)  = x_i (1+a\\Delta t) + \\epsilon_i(1+a\\Delta t)\\] Let us set aside the terns in the equation that involve \\(x\\) (since it is just the equation for forward Euler). The remaining difference equation for \\(\\epsilon\\) describes the change in the error: \\[\\epsilon_{i+1} = \\epsilon_i(1+a\\Delta t) \\]\nThis states that the error in this numerical solution is repeatedly multiplied by the constant \\((1+a\\Delta t)\\). As we saw in section \\(\\ref{sec:math14}\\), this linear difference equation has an exponential solution \\(\\epsilon_n = (1+a\\Delta t)^n \\epsilon_0\\), which decays to 0 if \\(|1+a\\Delta t| < 1\\) or grows without bound if \\(|1+a\\Delta t| > 1\\). The first inequality is called the stability condition for the FE scheme, since it guarantees that the old errors decay over time. Since \\(\\Delta t >0\\), the only way that the left hand side can be less than 1 is if \\(a<0\\). Therefore, the condition for stability of the FE method for a linear ODE: \\[|1 + a\\Delta t| < 1 \\Rightarrow \\Delta t < -2/a\\]\nThus, if \\(a>0\\), the errors will eventually overwhelm the solution. If \\(a<0\\), if the time step is small enough (less than \\(-2/a\\)) then FE is stable. Generally speaking, however, Forward Euler is about the worst method to use for practical numerical solutions of ODEs, due to its low accuracy and to its lack of stability under certain conditions.\n\n\n11.3.4 Exercises\n\\[\n\\frac{dx}{dt} =  0.2 x\n\\]\n\nCalculate the error of the numeric solution of this ODE after one time step with dt=0.1 and initial value x(0) = 5 by subtracting it from the exact (analytic) solution \\(x(t) = e^{0.2t}x(0)\\), with the same initial value. Answer: about 0.001.\n\n\n# YOUR CODE HERE\n\n\nCompute the error of the two numeric solution over Tmax = 10 by subtracting the numeric solution vector from the analytic solution calculating over the same time vector and report the mean of that error vector. Answers: for dt=0.1 the mean error is 0.722, for dt=0.01 the mean error is 0.0737.\n\n\n# YOUR CODE HERE"
  },
  {
    "objectID": "ode_sols.html#applications-of-linear-ode-models",
    "href": "ode_sols.html#applications-of-linear-ode-models",
    "title": "11  Solutions of ordinary differential equations",
    "section": "11.4 Applications of linear ODE models",
    "text": "11.4 Applications of linear ODE models\n\n\n11.4.1 model of pharmacokinetics\nDescribing and predicting the dynamics of drug concentration in the body is the goal of pharmacokinetics. Any drug that humans take goes through several stages: first it is administered (put into the body), then absorbed, metabolized (transformed), and excreted (removed from the body) . Almost any drug has a dose at which it has a toxic effect, and most can kill a human if the dose is high enough. Drugs which are used for medical purposes have a therapeutic range, which lies between the lowest possible concentration (usually measured in the blood plasma) that achieves the therapeutic effect and the concentration which is toxic. One of the basic questions that medical practitioners need to know is how much and how frequently to administer a drug to maintain drug concentration in the therapeutic range.\nThe concentration of a drug is a dynamic variable which depends on the rates of several processes, most directly on the rate of administration and the rate of metabolism. Drugs can be administered through various means (e.g. orally or intravenously) which influences their rate of absorption and thus how the concentration increases. Once in the blood plasma, drugs are metabolized primarily by enzymes in the liver, converting drug molecules into compounds that can be excreted through the kidneys or the large intestine. The process of *metabolism proceeds at a rate that depends on both the concentration of the drug and on the enzyme that catalyzes the reaction. For some drugs the metabolic rate may be constant, or independent of the drug concentration, since the enzymes are already working at full capacity and can’t turn over any more reactions, for example alcohol is metabolized at a constant rate of about 1 drink per hours for most humans. Figure \\(\\ref{fig:ch15_drug_conc}\\)a shows the time plots of the blood alcohol concentration for 4 males who ingested different amounts of alcohol, and the curves are essentially linear with the same slope after the peak. For other drugs, if the plasma concentration is low enough, the enzymes are not occupied all the time and increasing the drug concentration leads to an increase in the rate of metabolism. One can see this behavior in the metabolism of the anti-depressant drug bupropion in figure \\(\\ref{fig:ch15_drug_conc}\\)b, where the concentration curve shows a faster decay rate for higher concentration of the drug than for lower concentration. In the simplest case, the rate of metabolism is linear, or proportional to the concentration of the drug, with proportionality constant called the first-order metabolic rate.\n\n\n\nBlood alcohol content after ingesting different numbers of drinks, from 4 in the top curve to 1 in the bottom (figure from the National Institute on Alcohol Abuse and Alcoholism in public domain)\n\n\n\n\n\nBlood concentration of bupropion for two different drugs in clinical trials (image by CMBJ based on FDA data under CC-BY 3.0 via Wikimedia Commons)\n\n\nLet us build an ODE model for a simplified pharmacokinetics situation. Suppose that a drug is administered at a constant rate of \\(M\\) (concentration units per time unit) and that it is metabolized at a rate proportional to its plasma concentration \\(C\\) with metabolic rate constant \\(k\\). Then the ODE model of the concentration of the drug over time \\(C(t)\\) is: \\[ \\frac{dC}{dt} = M - kC\\] The two rate constants \\(M\\) and \\(k\\) have different dimensions, which you should be able to determine yourself. The ODE can be solved using the separate-and-integrate method:\n\nDivide both sides by the right hand side \\(M-kC\\), and multiply both sides by the differential \\(dt\\) \\[ \\frac{dC}{M-kC} = dt\\]\nintegrate both sides with respect to the different variables, don’t forget the integration constant! \\[ \\int \\frac{dC}{M-kC} = \\int dt \\Rightarrow\\] \\[ -\\frac{1}{k} \\log |M-kC| = t + A\\]\nsolve for the dependent variable \\(C(t)\\) \\[ \\exp(\\log |M-kC| ) = -\\exp(kt +A) \\Rightarrow \\] \\[  M - kC = B e^{-kt} \\Rightarrow \\] \\[ C(t) = \\frac{M}{k}- Be^{-kt}\\] Notice that I changed the values of integration constants \\(A\\) and \\(B\\) during the derivation, which shouldn’t matter because they have not been determined yet.\nplug in \\(t=0\\) and use the initial value \\(x(0)\\) to solve for the integration constant If we know the initial value \\(C(0) = C_0\\), then we can plug it in and get the following algebraic expression: \\[ C_0 =  \\frac{M}{k} - B \\Rightarrow \\] \\[ B = C_0 -  \\frac{M}{k}\\] Then the complete solution is: \\[ C(t) =  \\frac{M}{k} - (C_0- \\frac{M}{k})e^{-kt}\\]\n\nThe solution predicts that after a long time the plasma concentration will approach the value \\(M/k\\), since the exponential term decays to zero. Notice that mathematically this is the same type of solution we obtained in equation \\(\\ref{eq:ch15_ode_sol}\\) for a generic linear ODE with a constant term.\n\n\n11.4.2 Discussion questions\nThe following questions encourage you to think critically about the pharmacokinetic model above.\n\nDescribe in words the dependence of the long-term plasma concentration of the drug on the }parameters. Does this prediction make intuitive sense?\nExplain in practical terms the assumption that the administration of the drug results in a constant rate of growth of the concentration. Under what circumstances does this match reality?\nExplain in practical terms the assumption that the drug metabolism rate is proportional to the plasma concentration. Under what circumstances does this match reality?\nDiscuss how you could modify the ODE model to describe other circumstances, or to add other effects to it."
  }
]